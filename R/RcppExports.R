# Generated by using Rcpp::compileAttributes() -> do not edit by hand
# Generator token: 10BE3573-1514-4C36-9D1C-5A225CD40393

#'Main function to estimate GKw distribution parameters using the method of moments.
#' This implementation is optimized for numerical stability and computational efficiency.
#'
#' @param x Data vector (must be in (0,1))
#' @param n_starts Number of starting points for optimization
#' @return Vector of estimated parameters [alpha, beta, gamma, delta, lambda]
#'
#' @export
gkwgetstartvalues <- function(x, n_starts = 5L) {
    .Call(`_gkwreg_gkwgetstartvalues`, x, n_starts)
}

#' @title Density Function for Generalized Kumaraswamy Distribution
#'
#' @description
#' Calculates the probability density function (PDF) of the Generalized Kumaraswamy
#' distribution GKw(α, β, γ, δ, λ) for values in the open interval (0,1). Returns
#' either f(x; θ) or log(f(x; θ)) depending on the log_prob parameter.
#'
#' @param x Vector of quantiles where the density will be evaluated.
#' @param alpha Shape parameter α > 0 (scalar or vector). Controls the left tail behavior. Default: 1.0.
#' @param beta Shape parameter β > 0 (scalar or vector). Controls the right tail behavior. Default: 1.0.
#' @param gamma Shape parameter γ > 0 (scalar or vector). Affects the central shape. Default: 1.0.
#' @param delta Shape parameter δ ≥ 0 (scalar or vector). Introduces additional flexibility. Default: 0.0.
#' @param lambda Shape parameter λ > 0 (scalar or vector). Controls overall dispersion. Default: 1.0.
#' @param log_prob Logical; if TRUE, probabilities are returned as log(f(x)). Default: FALSE.
#'
#' @return Vector of density values corresponding to each element in x. If x contains
#'         values outside (0,1), those positions will return 0 (or -Inf if log_prob=TRUE).
#'
#' @details
#' The probability density function of the GKw distribution as derived by Carrasco et al. (2010) is:
#'
#' \deqn{
#' f(x; \alpha, \beta, \gamma, \delta, \lambda) =
#'   \frac{\lambda \alpha \beta x^{\alpha-1}(1-x^{\alpha})^{\beta-1}}
#'        {B(\gamma, \delta+1)}
#'   [1-(1-x^{\alpha})^{\beta}]^{\gamma\lambda-1}
#'   [1-[1-(1-x^{\alpha})^{\beta}]^{\lambda}]^{\delta}
#' }
#'
#' for x in (0,1), where B(γ, δ+1) is the beta function.
#'
#' This distribution arises from the construction:
#'
#' \deqn{f(x; \theta) = g_2(G_1(x; \alpha, \beta); \gamma, \delta, \lambda) \cdot g_1(x; \alpha, \beta)}
#'
#' where G_1 is the CDF of the Kumaraswamy distribution, g_1 is its PDF, and g_2 is the
#' generalized beta density of first kind.
#'
#' The function handles several edge cases:
#' \itemize{
#'   \item Returns 0 (or -Inf if log_prob=TRUE) for x outside (0,1)
#'   \item Implements numerical stability precautions for x very close to 0 or 1
#'   \item Returns 0 (or -Inf) for parameter combinations that would cause computational issues
#' }
#'
#' The GKw distribution includes several special cases:
#' \itemize{
#'   \item Kumaraswamy (Kw): γ=1, δ=0, λ=1
#'   \item McDonald distribution: α=1, β=1
#'   \item Beta distribution: α=1, β=1, λ=1
#'   \item Beta-Kumaraswamy (BKw): λ=1
#'   \item Kumaraswamy-Kumaraswamy: γ=1
#'   \item Exponentiated Kumaraswamy (EKw): γ=1, δ=0
#'   \item Beta Power (BP): α=1, β=1
#' }
#'
#' @references
#' Kumaraswamy, P. (1980). A generalized probability density function for double-bounded random processes.
#' Journal of Hydrology, 46(1-2), 79-88.
#'
#' Cordeiro, G. M., & de Castro, M. (2011). A new family of generalized distributions.
#' Journal of Statistical Computation and Simulation, 81(7), 883-898.
#'
#' @examples
#' \dontrun{
#' # Simple density evaluation at a point
#' dgkw(0.5, 2, 3, 1, 0, 1)
#'
#' # Plot the PDF for various parameter sets
#' x <- seq(0.01, 0.99, by = 0.01)
#'
#' # Standard Kumaraswamy (γ=1, δ=0, λ=1)
#' plot(x, dgkw(x, 2, 3, 1, 0, 1), type = "l",
#'      main = "GKw Densities", ylab = "f(x)", col = "blue")
#'
#' # Beta equivalent (α=1, β=1, λ=1)
#' lines(x, dgkw(x, 1, 1, 2, 3, 1), col = "red")
#'
#' # Exponentiated Kumaraswamy (γ=1, δ=0)
#' lines(x, dgkw(x, 2, 3, 1, 0, 2), col = "green")
#'
#' # Vectorized parameter example
#' alphas <- c(0.5, 1.5, 3.0)
#' # Returns 3 density values for the same x
#' dgkw(0.5, alphas, 2, 1, 0, 1)
#' }
#'
#' @export
dgkw <- function(x, alpha = as.numeric( c(1.0)), beta = as.numeric( c(1.0)), gamma = as.numeric( c(1.0)), delta = as.numeric( c(0.0)), lambda = as.numeric( c(1.0)), log_prob = FALSE) {
    .Call(`_gkwreg_dgkw`, x, alpha, beta, gamma, delta, lambda, log_prob)
}

#' @title Cumulative Distribution Function for Generalized Kumaraswamy Distribution
#'
#' @description
#' Calculates the cumulative distribution function (CDF) of the Generalized Kumaraswamy
#' distribution GKw(α, β, γ, δ, λ) for values in the interval (0,1). Returns F(q) = P(X ≤ q)
#' by default, with options for upper tail probability P(X > q) and log transformations.
#'
#' @param q Vector of quantiles where the CDF will be evaluated.
#' @param alpha Shape parameter α > 0 (scalar or vector). Controls the left tail behavior. Default: 1.0.
#' @param beta Shape parameter β > 0 (scalar or vector). Controls the right tail behavior. Default: 1.0.
#' @param gamma Shape parameter γ > 0 (scalar or vector). Affects the central shape. Default: 1.0.
#' @param delta Shape parameter δ ≥ 0 (scalar or vector). Introduces additional flexibility. Default: 0.0.
#' @param lambda Shape parameter λ > 0 (scalar or vector). Controls overall dispersion. Default: 1.0.
#' @param lower_tail Logical; if TRUE (default), probabilities are P(X ≤ q), otherwise P(X > q).
#' @param log_p Logical; if TRUE, probabilities are returned as log(p). Default: FALSE.
#'
#' @return Vector of probabilities corresponding to each element in q.
#'
#' @details
#' The cumulative distribution function for the GKw distribution as derived in
#' Carrasco et al. (2010) is:
#'
#' \deqn{
#' F(q; \alpha, \beta, \gamma, \delta, \lambda) =
#'   I_{[1-(1-q^{\alpha})^{\beta}]^{\lambda}}(\gamma, \delta+1)
#' }
#'
#' where I_x(a,b) is the regularized incomplete beta function defined as:
#'
#' \deqn{
#' I_x(a, b) = \frac{B_x(a, b)}{B(a, b)}
#' }
#'
#' With B_x(a, b) being the incomplete beta function:
#'
#' \deqn{
#' B_x(a, b) = \int_0^x t^{a-1}(1-t)^{b-1} dt
#' }
#'
#' The GKw distribution can be derived from the following construction:
#' Let \eqn{G_1(x; \alpha, \beta)} be the two-parameter Kumaraswamy CDF and \eqn{g_2(x; \gamma, \delta, \lambda)}
#' be the generalized beta density of first kind. Then:
#'
#' \deqn{
#' F(x; \theta) = \int_0^{G_1(x; \alpha, \beta)} g_2(t; \gamma, \delta, \lambda) dt
#' }
#'
#' The function implements specialized numerical techniques for stability from the paper,
#' carefully handling boundary cases and extreme parameter values to ensure proper behavior
#' throughout the parameter space.
#'
#' @references
#' Kumaraswamy, P. (1980). A generalized probability density function for double-bounded random processes.
#' Journal of Hydrology, 46(1-2), 79-88.
#'
#' Cordeiro, G. M., & de Castro, M. (2011). A new family of generalized distributions.
#' Journal of Statistical Computation and Simulation, 81(7), 883-898.
#'
#' @examples
#' \dontrun{
#' # Simple CDF evaluation
#' pgkw(0.5, 2, 3, 1, 0, 1)
#'
#' # Use of vectorized parameters
#' alphas <- c(0.5, 1.0, 2.0)
#' betas <- c(1.0, 2.0, 3.0)
#' pgkw(0.5, alphas, betas)
#'
#' # Comparing special cases
#' x <- seq(0.01, 0.99, by = 0.01)
#' # Standard Kumaraswamy
#' pkw <- pgkw(x, 2, 3, 1, 0, 1)
#' # Beta distribution
#' pbeta_equiv <- pgkw(x, 1, 1, 2, 3, 1)
#' }
#'
#' @export
pgkw <- function(q, alpha = as.numeric( c(1.0)), beta = as.numeric( c(1.0)), gamma = as.numeric( c(1.0)), delta = as.numeric( c(0.0)), lambda = as.numeric( c(1.0)), lower_tail = TRUE, log_p = FALSE) {
    .Call(`_gkwreg_pgkw`, q, alpha, beta, gamma, delta, lambda, lower_tail, log_p)
}

#' @title Quantile Function for Generalized Kumaraswamy Distribution
#'
#' @description
#' Calculates the quantile function (inverse CDF) of the Generalized Kumaraswamy
#' distribution GKw(α, β, γ, δ, λ). For a given probability p, returns the value x
#' such that P(X ≤ x) = p, where X follows a GKw distribution with the specified parameters.
#'
#' @param p Vector of probabilities for which to compute quantiles. Values should be in (0,1),
#'        or in (-Inf,0] if log_p=TRUE.
#' @param alpha Shape parameter α > 0 (scalar or vector). Controls the left tail behavior. Default: 1.0.
#' @param beta Shape parameter β > 0 (scalar or vector). Controls the right tail behavior. Default: 1.0.
#' @param gamma Shape parameter γ > 0 (scalar or vector). Affects the central shape. Default: 1.0.
#' @param delta Shape parameter δ ≥ 0 (scalar or vector). Introduces additional flexibility. Default: 0.0.
#' @param lambda Shape parameter λ > 0 (scalar or vector). Controls overall dispersion. Default: 1.0.
#' @param lower_tail Logical; if TRUE (default), probabilities are P(X ≤ x), otherwise P(X > x).
#' @param log_p Logical; if TRUE, probabilities are provided as log(p). Default: FALSE.
#'
#' @return Vector of quantiles corresponding to each probability in p. Returns:
#'   \itemize{
#'     \item 0 for probabilities ≤ 0 (or when log(p) = -Inf if log_p=TRUE)
#'     \item 1 for probabilities ≥ 1 (or when log(p) = 0 if log_p=TRUE)
#'     \item NA for invalid inputs (including p > 1 when log_p=TRUE, which would be log(p) > 0)
#'     \item NA for invalid parameters (any of α, β, γ ≤ 0, δ < 0, or λ ≤ 0)
#'   }
#'
#' @details
#' According to Carrasco et al. (2010), the quantile function for the GKw distribution is
#' derived by inverting the CDF \deqn{F(x) = I_{(1-(1-x^α)^β)^λ}(γ, δ+1)}:
#'
#' \deqn{
#' Q(p) = \{1 - (1 - (I^{-1}_{p}(\gamma, \delta+1))^{1/\lambda})^{1/\beta}\}^{1/\alpha}
#' }
#'
#' where \eqn{I^{-1}_{p}(a, b)} is the inverse regularized incomplete beta function.
#'
#' The implementation follows these steps to compute the quantile:
#' \enumerate{
#'   \item Find y = qbeta(p, γ, δ+1)
#'   \item Compute \deqn{v = y^(1/λ)}
#'   \item Compute \deqn{tmp = 1 - v}
#'   \item Compute \deqn{tmp2 = tmp^(1/β)}
#'   \item Compute \deqn{q = (1 - tmp2)^(1/α)}
#' }
#'
#' Special care is taken at each step to handle numerical issues:
#' \itemize{
#'   \item Boundary cases (p ≤ 0 or p ≥ 1) are handled directly
#'   \item Intermediate results are checked for validity at each transformation step
#'   \item Special cases where parameters equal 1 are optimized for speed and accuracy
#' }
#'
#' This implementation supports vectorized parameters, allowing any combination of
#' vector and scalar inputs for all distribution parameters, with proper broadcasting
#' for vectors of different lengths.
#'
#' @references
#' Kumaraswamy, P. (1980). A generalized probability density function for double-bounded random processes.
#' Journal of Hydrology, 46(1-2), 79-88.
#'
#' Cordeiro, G. M., & de Castro, M. (2011). A new family of generalized distributions.
#' Journal of Statistical Computation and Simulation, 81(7), 883-898.
#'
#' @examples
#' \dontrun{
#' # Basic quantile calculation
#' qgkw(0.5, 2, 3, 1, 0, 1)  # Median of GKw(2,3,1,0,1)
#'
#' # Computing multiple quantiles
#' probs <- c(0.1, 0.25, 0.5, 0.75, 0.9)
#' qgkw(probs, 2, 3, 1, 0, 1)  # Various percentiles
#'
#' # Upper tail quantiles
#' qgkw(0.1, 2, 3, 1, 0, 1, lower_tail = FALSE)  # 90th percentile
#'
#' # Log probabilities
#' qgkw(log(0.5), 2, 3, 1, 0, 1, log_p = TRUE)
#'
#' # Vectorized parameters
#' alphas <- c(0.5, 1.0, 2.0)
#' betas <- c(1.0, 2.0, 3.0)
#' qgkw(0.5, alphas, betas)  # Will return 3 quantile values
#'
#' # Verify inverse relationship with pgkw
#' p <- 0.75
#' x <- qgkw(p, 2, 3, 1, 0, 1)
#' pgkw(x, 2, 3, 1, 0, 1)  # Should be approximately 0.75
#' }
#'
#' @export
qgkw <- function(p, alpha = as.numeric( c(1.0)), beta = as.numeric( c(1.0)), gamma = as.numeric( c(1.0)), delta = as.numeric( c(0.0)), lambda = as.numeric( c(1.0)), lower_tail = TRUE, log_p = FALSE) {
    .Call(`_gkwreg_qgkw`, p, alpha, beta, gamma, delta, lambda, lower_tail, log_p)
}

#' @title Random Number Generation for Generalized Kumaraswamy Distribution
#'
#' @description
#' Generates random deviates from the Generalized Kumaraswamy distribution GKw(α, β, γ, δ, λ).
#' The implementation uses an efficient transformation method based on the Beta distribution
#' as derived in Carrasco et al. (2010).
#'
#' @param n Number of random values to generate. Must be a positive integer.
#' @param alpha Shape parameter α > 0 (scalar or vector). Controls the left tail behavior. Default: 1.0.
#' @param beta Shape parameter β > 0 (scalar or vector). Controls the right tail behavior. Default: 1.0.
#' @param gamma Shape parameter γ > 0 (scalar or vector). Affects the central shape. Default: 1.0.
#' @param delta Shape parameter δ ≥ 0 (scalar or vector). Introduces additional flexibility. Default: 0.0.
#' @param lambda Shape parameter λ > 0 (scalar or vector). Controls overall dispersion. Default: 1.0.
#'
#' @return Vector of length n containing random values from the GKw distribution.
#'   If any parameters are invalid, the function produces an error.
#'   Returns NA for parameter combinations that are invalid.
#'
#' @details
#' According to Carrasco et al. (2010), if V ~ Beta(γ, δ+1), then:
#'
#' \deqn{
#' X = \{1 - [1 - V^{1/\lambda}]^{1/\beta}\}^{1/\alpha}
#' }
#'
#' follows a GKw(α, β, γ, δ, λ) distribution.
#'
#' The random generation algorithm implements this transformation method:
#' \enumerate{
#'   \item Generate V ~ Beta(γ, δ+1)
#'   \item Compute v = V^(1/λ)
#'   \item Compute tmp = 1 - v
#'   \item Compute tmp2 = tmp^(1/β)
#'   \item Compute x = (1 - tmp2)^(1/α)
#' }
#'
#' This implementation includes several optimizations:
#' \itemize{
#'   \item Special cases for α=1, β=1, or λ=1 are handled directly to improve efficiency
#'   \item Boundary cases are checked at each step to maintain numerical stability
#'   \item Safe power transformations prevent numerical issues with extreme values
#'   \item Full support for vectorized parameters with appropriate broadcasting
#' }
#'
#' @references
#' Kumaraswamy, P. (1980). A generalized probability density function for double-bounded random processes.
#' Journal of Hydrology, 46(1-2), 79-88.
#'
#' Cordeiro, G. M., & de Castro, M. (2011). A new family of generalized distributions.
#' Journal of Statistical Computation and Simulation, 81(7), 883-898.
#'
#' @examples
#' \dontrun{
#' # Generate 1000 random values from a GKw(2,3,1,0,1)
#' x <- rgkw(1000, 2, 3, 1, 0, 1)
#'
#' # Histogram of generated values
#' hist(x, breaks = 30, probability = TRUE,
#'      main = "Histogram of GKw(2,3,1,0,1) Random Values")
#'
#' # Add the theoretical density curve
#' curve(dgkw(x, 2, 3, 1, 0, 1), add = TRUE, col = "red", lwd = 2)
#'
#' # Comparing empirical and theoretical quantiles
#' prob_points <- seq(0.1, 0.9, by = 0.1)
#' theo_quantiles <- qgkw(prob_points, 2, 3, 1, 0, 1)
#' emp_quantiles <- quantile(x, prob_points)
#' plot(theo_quantiles, emp_quantiles,
#'      main = "Q-Q Plot for GKw(2,3,1,0,1)",
#'      xlab = "Theoretical Quantiles",
#'      ylab = "Empirical Quantiles")
#' abline(0, 1, col = "blue")
#'
#' # Using vectorized parameters
#' alphas <- c(0.5, 1.0, 2.0)
#' samples <- rgkw(300, alphas, 2, 1, 0, 1)  # 100 samples from each configuration
#' hist(samples, breaks = 30, probability = TRUE,
#'      main = "Mixed GKw Samples with Different Alpha Values")
#' }
#'
#' @export
rgkw <- function(n, alpha = as.numeric( c(1.0)), beta = as.numeric( c(1.0)), gamma = as.numeric( c(1.0)), delta = as.numeric( c(0.0)), lambda = as.numeric( c(1.0))) {
    .Call(`_gkwreg_rgkw`, n, alpha, beta, gamma, delta, lambda)
}

#' @title Log-Likelihood Function for Generalized Kumaraswamy Distribution
#'
#' @description
#' Calculates the negative log-likelihood for the Generalized Kumaraswamy distribution
#' GKw(α, β, γ, δ, λ) given a vector of observations. This function is primarily used
#' in maximum likelihood estimation and model fitting procedures.
#'
#' @param par NumericVector of length 5 containing parameters (α, β, γ, δ, λ) in that order.
#'        All parameters must be positive.
#' @param data NumericVector of observations, where all values must be in the open interval (0,1).
#'
#' @return The negative log-likelihood value as a double, or -Inf if any parameters or data values
#'         are invalid (parameters ≤ 0 or data outside (0,1)).
#'
#' @details
#' The probability density function of the GKw distribution is:
#'
#' \deqn{
#' f(x; \alpha, \beta, \gamma, \delta, \lambda) =
#'   \frac{\lambda \alpha \beta x^{\alpha-1}(1-x^{\alpha})^{\beta-1}}
#'        {B(\gamma, \delta+1)}
#'   [1-(1-x^{\alpha})^{\beta}]^{\gamma\lambda-1}
#'   [1-[1-(1-x^{\alpha})^{\beta}]^{\lambda}]^{\delta}
#' }
#'
#' The corresponding log-likelihood function is:
#'
#' \deqn{
#' \ell(\theta) = n\ln(\lambda\alpha\beta) - n\ln B(\gamma,\delta+1) +
#'   \sum_{i=1}^{n} [(\alpha-1)\ln(x_i) + (\beta-1)\ln(v_i) + (\gamma\lambda-1)\ln(w_i) + \delta\ln(z_i)]
#' }
#'
#' where:
#' \itemize{
#'   \item \deqn{v_i = 1 - x_i^{\alpha}}
#'   \item \deqn{w_i = 1 - v_i^{\beta} = 1 - (1-x_i^{\alpha})^{\beta}}
#'   \item \deqn{z_i = 1 - w_i^{\lambda} = 1 - (1-(1-x_i^{\alpha})^{\beta})^{\lambda}}
#' }
#'
#' The implementation uses several techniques for numerical stability:
#' \itemize{
#'   \item R's lbeta function for calculating log(B(γ, δ+1))
#'   \item log1p for calculating log(1-x) when x is close to zero
#'   \item Careful handling of intermediate values to avoid underflow/overflow
#' }
#'
#' Note that this function returns the negative log-likelihood (rather than the log-likelihood),
#' making it suitable for minimization in optimization procedures.
#'
#' @examples
#' \dontrun{
#' # Generate sample data from a GKw distribution
#' set.seed(123)
#' x <- rgkw(100, 2, 3, 1.0, 0.5, 0.5)
#' hist(x, breaks = 20, main = "GKw(2, 3, 1.0, 0.5, 0.5) Sample")
#'
#' # Use in optimization with Hessian-based methods
#' result <- optim(c(0.5, 0.5, 0.5, 0.5, 0.5), llgkw, method = "BFGS",
#'                 hessian = TRUE, data = x)
#'
#' # Compare numerical and analytical derivatives
#' num_grad <- numDeriv::grad(llgkw, x = result$par, data = x)
#' num_hess <- numDeriv::hessian(llgkw, x = result$par, data = x)
#'
#' ana_grad <- grgkw(result$par, data = x)
#' ana_hess <- hsgkw(result$par, data = x)
#'
#' # Check differences (should be very small)
#' round(num_grad - ana_grad, 4)
#' round(num_hess - ana_hess, 4)
#'
#' }
#'
#' @seealso
#' \code{\link[gkwreg]{dgkw}} for the GKw density function,
#' \code{\link[gkwreg]{pgkw}} for the GKw cumulative distribution function,
#' \code{\link[gkwreg]{hsgkw}} for the analytic Hessian of the GKw log-likelihood,
#'
#' @references
#' Kumaraswamy, P. (1980). A generalized probability density function for double-bounded random processes.
#' Journal of Hydrology, 46(1-2), 79-88.
#'
#' Cordeiro, G. M., & de Castro, M. (2011). A new family of generalized distributions.
#' Journal of Statistical Computation and Simulation, 81(7), 883-898.
#'
#' @export
llgkw <- function(par, data) {
    .Call(`_gkwreg_llgkw`, par, data)
}

#' @title Gradient Function for Generalized Kumaraswamy Log-Likelihood
#'
#' @description
#' Calculates the gradient vector (partial derivatives) of the negative log-likelihood
#' function for the Generalized Kumaraswamy (GKw) distribution. This function provides
#' the exact gradient needed for efficient optimization in maximum likelihood estimation.
#'
#' @param par NumericVector of length 5 containing parameters (α, β, γ, δ, λ) in that order.
#'        All parameters must be positive.
#' @param data NumericVector of observations, where all values must be in the open interval (0,1).
#'
#' @return NumericVector of length 5 containing the gradient components (partial derivatives)
#'         of the negative log-likelihood with respect to each parameter (α, β, γ, δ, λ).
#'         Returns a vector of NaN values if any parameters or data values are invalid.
#'
#' @details
#' The gradient vector contains the following partial derivatives of the negative log-likelihood:
#'
#' \deqn{
#' \frac{\partial \ell}{\partial \alpha} = \frac{n}{\alpha} + \sum_{i=1}^{n}\log(x_i) -
#' \sum_{i=1}^{n}\left[x_i^{\alpha} \log(x_i) \left(\frac{\beta-1}{v_i} -
#' \frac{(\gamma\lambda-1) \beta v_i^{\beta-1}}{w_i} +
#' \frac{\delta \lambda \beta v_i^{\beta-1} w_i^{\lambda-1}}{z_i}\right)\right]
#' }
#'
#' \deqn{
#' \frac{\partial \ell}{\partial \beta} = \frac{n}{\beta} + \sum_{i=1}^{n}\log(v_i) -
#' \sum_{i=1}^{n}\left[v_i^{\beta} \log(v_i) \left(\frac{\gamma\lambda-1}{w_i} -
#' \frac{\delta \lambda w_i^{\lambda-1}}{z_i}\right)\right]
#' }
#'
#' \deqn{
#' \frac{\partial \ell}{\partial \gamma} = -n[\psi(\gamma) - \psi(\gamma+\delta+1)] +
#' \lambda\sum_{i=1}^{n}\log(w_i)
#' }
#'
#' \deqn{
#' \frac{\partial \ell}{\partial \delta} = -n[\psi(\delta+1) - \psi(\gamma+\delta+1)] +
#' \sum_{i=1}^{n}\log(z_i)
#' }
#'
#' \deqn{
#' \frac{\partial \ell}{\partial \lambda} = \frac{n}{\lambda} +
#' \gamma\sum_{i=1}^{n}\log(w_i) - \delta\sum_{i=1}^{n}\frac{w_i^{\lambda}\log(w_i)}{z_i}
#' }
#'
#' where:
#' \itemize{
#'   \item \deqn{v_i = 1 - x_i^{\alpha}}
#'   \item \deqn{w_i = 1 - v_i^{\beta} = 1 - (1-x_i^{\alpha})^{\beta}}
#'   \item \deqn{z_i = 1 - w_i^{\lambda} = 1 - (1-(1-x_i^{\alpha})^{\beta})^{\lambda}}
#'   \item \deqn{\psi} is the digamma function (derivative of the log-gamma function)
#' }
#'
#' The implementation includes several numerical safeguards:
#' \itemize{
#'   \item Parameter and data validation with appropriate error handling
#'   \item Clamping of intermediate values to avoid numerical underflow/overflow
#'   \item Efficient vector operations using Armadillo C++ library
#' }
#'
#' The returned gradient is negated to align with minimization of negative log-likelihood
#' in optimization routines.
#'
#' @examples
#' \dontrun{
#' # Generate sample data from a GKw distribution
#' set.seed(123)
#' x <- rgkw(100, 2, 3, 1.0, 0.5, 0.5)
#' hist(x, breaks = 20, main = "GKw(2, 3, 1.0, 0.5, 0.5) Sample")
#'
#' # Use in optimization with Hessian-based methods
#' result <- optim(c(0.5, 0.5, 0.5, 0.5, 0.5), llgkw, method = "BFGS",
#'                 hessian = TRUE, data = x)
#'
#' # Compare numerical and analytical derivatives
#' num_grad <- numDeriv::grad(llgkw, x = result$par, data = x)
#' num_hess <- numDeriv::hessian(llgkw, x = result$par, data = x)
#'
#' ana_grad <- grgkw(result$par, data = x)
#' ana_hess <- hsgkw(result$par, data = x)
#'
#' # Check differences (should be very small)
#' round(num_grad - ana_grad, 4)
#' round(num_hess - ana_hess, 4)
#'
#' }
#'
#' @seealso
#' \code{\link[gkwreg]{llgkw}} for the negative log-likelihood function,
#' \code{\link[gkwreg]{hsgkw}} for the Hessian matrix of the GKw log-likelihood,
#' \code{\link[gkwreg]{dgkw}} for the GKw density function,
#'
#' @references
#' Kumaraswamy, P. (1980). A generalized probability density function for double-bounded random processes.
#' Journal of Hydrology, 46(1-2), 79-88.
#'
#' Cordeiro, G. M., & de Castro, M. (2011). A new family of generalized distributions.
#' Journal of Statistical Computation and Simulation, 81(7), 883-898.
#'
#' @export
grgkw <- function(par, data) {
    .Call(`_gkwreg_grgkw`, par, data)
}

#' @title Analytic Hessian Matrix for Generalized Kumaraswamy Distribution
#'
#' @description
#' Computes the analytic Hessian matrix of the log-likelihood function for
#' the Generalized Kumaraswamy (GKw) distribution. This function provides
#' exact second derivatives needed for optimization and inference.
#'
#' @param par Numeric vector of length 5 containing the parameters
#'        (α, β, γ, δ, λ) in that order. All parameters must be positive.
#' @param data Numeric vector of observations, where all values must be
#'        in the open interval (0,1).
#'
#' @return A 5×5 numeric matrix representing the Hessian of the negative
#'         log-likelihood function. If parameters or data are invalid
#'         (parameters ≤ 0 or data outside (0,1)), returns a matrix of
#'         NaN values.
#'
#' @details
#' The log-likelihood for the generalized Kumaraswamy distribution is:
#'
#' \deqn{
#' \ell(\theta) = n \ln(\lambda) + n \ln(\alpha) + n \ln(\beta) - n \ln B(\gamma, \delta+1)
#' + (\alpha-1) \sum \ln(x_i)
#' + (\beta-1) \sum \ln(1 - x_i^\alpha)
#' + (\gamma\lambda - 1) \sum \ln\{1 - (1 - x_i^\alpha)^\beta\}
#' + \delta \sum \ln\{1 - \{1 - (1 - x_i^\alpha)^\beta\}^\lambda\}
#' }
#'
#' where B refers to the Beta function.
#'
#' The implementation computes all second derivatives analytically for each term.
#' For computational efficiency, the following transformations are used:
#' \itemize{
#'   \item \deqn{A = x^α} and derivatives
#'   \item \deqn{v = 1 - A}
#'   \item \deqn{w = 1 - v^β}
#'   \item \deqn{z = 1 - w^λ}
#' }
#'
#' The returned Hessian matrix has the following structure:
#' \itemize{
#'   \item Rows/columns 1-5 correspond to α, β, γ, δ, λ respectively
#'   \item The matrix is symmetric (as expected for a Hessian)
#'   \item The matrix represents second derivatives of the negative log-likelihood
#' }
#'
#' This function is implemented in C++ for computational efficiency.
#'
#' @examples
#' \dontrun{
#' # Generate sample data from a GKw distribution
#' set.seed(123)
#' x <- rgkw(100, 2, 3, 1.0, 0.5, 0.5)
#' hist(x, breaks = 20, main = "GKw(2, 3, 1.0, 0.5, 0.5) Sample")
#'
#' # Use in optimization with Hessian-based methods
#' result <- optim(c(0.5, 0.5, 0.5, 0.5, 0.5), llgkw, method = "BFGS",
#'                 hessian = TRUE, data = x)
#'
#' # Compare numerical and analytical derivatives
#' num_grad <- numDeriv::grad(llgkw, x = result$par, data = x)
#' num_hess <- numDeriv::hessian(llgkw, x = result$par, data = x)
#'
#' ana_grad <- grgkw(result$par, data = x)
#' ana_hess <- hsgkw(result$par, data = x)
#'
#' # Check differences (should be very small)
#' round(num_grad - ana_grad, 4)
#' round(num_hess - ana_hess, 4)
#'
#' }
#'
#' @seealso
#' \code{\link[gkwreg]{dgkw}} for the GKw density function,
#' \code{\link[gkwreg]{gkwreg}} for fitting GKw regression models,
#' \code{\link[gkwreg]{pgkw}} for the GKw cumulative distribution function
#'
#' @references
#' Kumaraswamy, P. (1980). A generalized probability density function for double-bounded random processes.
#' Journal of Hydrology, 46(1-2), 79-88.
#'
#' Cordeiro, G. M., & de Castro, M. (2011). A new family of generalized distributions.
#' Journal of Statistical Computation and Simulation, 81(7), 883-898.
#'
#' @export
hsgkw <- function(par, data) {
    .Call(`_gkwreg_hsgkw`, par, data)
}

#' @title Density of the KwKw Distribution
#'
#' @description
#' Computes the PDF of the KwKw(\eqn{\alpha, \beta, \delta, \lambda}) distribution, which
#' is the GKw distribution restricted to \eqn{\gamma=1}.
#'
#' @param x Vector of quantiles in \eqn{(0,1)}.
#' @param alpha \eqn{\alpha > 0}.
#' @param beta \eqn{\beta > 0}.
#' @param delta \eqn{\delta \ge 0}.
#' @param lambda \eqn{\lambda > 0}.
#' @param log_prob Logical; if \code{TRUE}, returns log-PDF, else PDF.
#'
#' @return Vector of densities (or log-densities) of the same length as the broadcast of inputs.
#'
#' @details
#' The PDF is
#' \deqn{
#'   f(x) = \lambda \,\alpha \,\beta \,(\delta + 1)\; x^{\alpha - 1}\, (1 - x^\alpha)^{\beta - 1}\,
#'          \bigl[1 - (1 - x^\alpha)^\beta\bigr]^{\lambda - 1}\,
#'          \bigl\{1 - \bigl[1 - (1 - x^\alpha)^\beta\bigr]^\lambda\bigr\}^{\delta},
#'   \quad 0 < x < 1.
#' }
#'
#' @export
dkkw <- function(x, alpha, beta, delta, lambda, log_prob = FALSE) {
    .Call(`_gkwreg_dkkw`, x, alpha, beta, delta, lambda, log_prob)
}

#' @title CDF of the KwKw Distribution
#'
#' @description
#' Computes the CDF for KwKw(\eqn{\alpha, \beta, \delta, \lambda}), i.e. P(X≤x).
#'
#' @param q Vector of quantiles in \eqn{(0,1)}.
#' @param alpha, beta, delta, lambda Parameters (see \code{\link{dkkw}}).
#' @param lower_tail Logical; if TRUE (default), returns F(q)=P(X≤q), else 1-F(q).
#' @param log_p Logical; if TRUE, returns log of the probability.
#'
#' @details
#' The CDF is
#' \deqn{
#'   F(x) = 1 - \bigl\{1 - \bigl[1 - (1 - x^\alpha)^\beta\bigr]^\lambda\bigr\}^{\delta + 1}.
#' }
#'
#' @export
pkkw <- function(q, alpha, beta, delta, lambda, lower_tail = TRUE, log_p = FALSE) {
    .Call(`_gkwreg_pkkw`, q, alpha, beta, delta, lambda, lower_tail, log_p)
}

#' @title Quantile Function of the KwKw Distribution
#'
#' @description
#' Computes the quantiles for KwKw(\eqn{\alpha, \beta, \delta, \lambda}).
#'
#' @param p Vector of probabilities in (0,1).
#' @param alpha, beta, delta, lambda Distribution parameters (see \code{\link{dkkw}}).
#' @param lower_tail Logical; if TRUE, p is F(x). If FALSE, p is 1-F(x).
#' @param log_p Logical; if TRUE, p is given as log(p).
#'
#' @details
#' Invert the CDF
#' \eqn{
#'   F(x)= 1 - [1 - (1 - x^α)^β]^λ)^(δ+1).
#' }
#' The resulting formula is
#' \deqn{
#'   Q(p)= \Bigl\{1 - \Bigl[1 - \Bigl(1 - p\Bigr)^{\frac{1}{\delta+1}}\Bigr]^{\frac{1}{\lambda}}\Bigr\}^{\frac{1}{\beta}}\Bigr\}^{\frac{1}{\alpha}}.
#' }
#'
#' @export
qkkw <- function(p, alpha, beta, delta, lambda, lower_tail = TRUE, log_p = FALSE) {
    .Call(`_gkwreg_qkkw`, p, alpha, beta, delta, lambda, lower_tail, log_p)
}

#' @title Random Generation from KwKw Distribution
#'
#' @description
#' Generates \code{n} samples from the KwKw(\eqn{\alpha, \beta, \delta, \lambda}) distribution.
#'
#' @param n Integer number of samples.
#' @param alpha, beta, delta, lambda Distribution parameters.
#'
#' @details
#' The table suggests: if \eqn{V ~ Unif(0,1)}, define
#' \eqn{U = 1 - (1 - V)^{1/(\delta+1)}}, then
#' \eqn{X = \{1 - [1 - U^{1/\lambda}]^{1/\beta}\}^{1/\alpha}}.
#'
#' @export
rkkw <- function(n, alpha, beta, delta, lambda) {
    .Call(`_gkwreg_rkkw`, n, alpha, beta, delta, lambda)
}

#' @title Negative Log-Likelihood of KwKw Distribution
#'
#' @description
#' Computes the negative log-likelihood for \eqn{\mathrm{KwKw}(\alpha,\beta,\delta,\lambda)}
#' given a data vector in (0,1).
#'
#' @param par NumericVector of length 4, \eqn{( \alpha,\beta,\delta,\lambda )}.
#' @param data NumericVector of observations, each in \eqn{(0,1)}.
#'
#' @details
#' The PDF is
#' \deqn{
#'   f(x) = \lambda\,\alpha\,\beta\,(\delta+1)\, x^{\alpha-1}\,(1-x^\alpha)^{\beta-1}\,
#'          [1 - (1 - x^\alpha)^\beta]^{\lambda-1}\,\{1 - [1 - (1-x^\alpha)^\beta]^\lambda\}^\delta.
#' }
#' The log-likelihood is the sum of \eqn{\log(f(x_i))}. This function returns the negative
#' log-likelihood (i.e. \eqn{-\ell(\theta)}).
#'
#' @return A single numeric value. \code{Inf} if invalid data or parameters.
#'
#' @examples
#' \dontrun{
#' # Generate sample data from a KKw distribution
#' set.seed(123)
#' x <- rkkw(100, 2, 3, 1.5, 0.5)
#' hist(x, breaks = 20, main = "KKw(2, 3, 1.5, 0.5) Sample")
#'
#' # Use in optimization with Hessian-based methods
#' result <- optim(c(0.5, 0.5, 0.5, 0.5), llkkw, method = "BFGS",
#'                 hessian = TRUE, data = x)
#'
#' # Compare numerical and analytical derivatives
#' num_grad <- numDeriv::grad(llkkw, x = result$par, data = x)
#' num_hess <- numDeriv::hessian(llkkw, x = result$par, data = x)
#'
#' ana_grad <- grkkw(result$par, data = x)
#' ana_hess <- hskkw(result$par, data = x)
#'
#' # Check differences (should be very small)
#' round(num_grad - ana_grad, 4)
#' round(num_hess - ana_hess, 4)
#'
#' }
#'
#' @export
llkkw <- function(par, data) {
    .Call(`_gkwreg_llkkw`, par, data)
}

#' @title Gradient Function for Kumaraswamy-Kumaraswamy Log-Likelihood
#'
#' @description
#' Calculates the gradient vector (partial derivatives) of the negative log-likelihood
#' function for the Kumaraswamy-Kumaraswamy (KwKw) distribution. This function provides
#' the exact gradient needed for efficient optimization in maximum likelihood estimation.
#' The KwKw is a submodel of GKw with γ = 1 fixed.
#'
#' @param par NumericVector of length 4 containing parameters (α, β, δ, λ) in that order.
#'        All parameters must be positive.
#' @param data NumericVector of observations, where all values must be in the open interval (0,1).
#'
#' @return NumericVector of length 4 containing the gradient components (partial derivatives)
#'         of the negative log-likelihood with respect to each parameter (α, β, δ, λ).
#'         Returns a vector of NaN values if any parameters or data values are invalid.
#'
#' @details
#' The gradient vector contains the following partial derivatives of the negative log-likelihood:
#'
#' \deqn{
#' \frac{\partial \ell}{\partial \alpha} = \frac{n}{\alpha} + \sum_{i=1}^{n}\log(x_i) -
#' (\beta-1)\sum_{i=1}^{n}\frac{x_i^{\alpha}\log(x_i)}{1-x_i^{\alpha}} +
#' (\lambda-1)\sum_{i=1}^{n}\frac{\beta(1-x_i^{\alpha})^{\beta-1}x_i^{\alpha}\log(x_i)}{1-(1-x_i^{\alpha})^{\beta}} -
#' \delta\sum_{i=1}^{n}\frac{\lambda[1-(1-x_i^{\alpha})^{\beta}]^{\lambda-1}\beta(1-x_i^{\alpha})^{\beta-1}x_i^{\alpha}\log(x_i)}{1-[1-(1-x_i^{\alpha})^{\beta}]^{\lambda}}
#' }
#'
#' \deqn{
#' \frac{\partial \ell}{\partial \beta} = \frac{n}{\beta} + \sum_{i=1}^{n}\log(1-x_i^{\alpha}) -
#' (\lambda-1)\sum_{i=1}^{n}\frac{(1-x_i^{\alpha})^{\beta}\log(1-x_i^{\alpha})}{1-(1-x_i^{\alpha})^{\beta}} +
#' \delta\sum_{i=1}^{n}\frac{\lambda[1-(1-x_i^{\alpha})^{\beta}]^{\lambda-1}(1-x_i^{\alpha})^{\beta}\log(1-x_i^{\alpha})}{1-[1-(1-x_i^{\alpha})^{\beta}]^{\lambda}}
#' }
#'
#' \deqn{
#' \frac{\partial \ell}{\partial \delta} = \frac{n}{\delta+1} +
#' \sum_{i=1}^{n}\log(1-[1-(1-x_i^{\alpha})^{\beta}]^{\lambda})
#' }
#'
#' \deqn{
#' \frac{\partial \ell}{\partial \lambda} = \frac{n}{\lambda} +
#' \sum_{i=1}^{n}\log(1-(1-x_i^{\alpha})^{\beta}) -
#' \delta\sum_{i=1}^{n}\frac{[1-(1-x_i^{\alpha})^{\beta}]^{\lambda}\log(1-(1-x_i^{\alpha})^{\beta})}{1-[1-(1-x_i^{\alpha})^{\beta}]^{\lambda}}
#' }
#'
#' where:
#' \itemize{
#'   \item \deqn{v_i = 1 - x_i^{\alpha}}
#'   \item \deqn{w_i = 1 - v_i^{\beta} = 1 - (1-x_i^{\alpha})^{\beta}}
#'   \item \deqn{z_i = 1 - w_i^{\lambda} = 1 - (1-(1-x_i^{\alpha})^{\beta})^{\lambda}}
#' }
#'
#' The implementation includes several numerical safeguards:
#' \itemize{
#'   \item Parameter and data validation with appropriate error handling
#'   \item Clamping of intermediate values to avoid numerical underflow/overflow
#'   \item Efficient vector operations using Armadillo C++ library
#' }
#'
#' The returned gradient is negated to align with minimization of negative log-likelihood
#' in optimization routines.
#'
#' @examples
#' \dontrun{
#' # Generate sample data from a KKw distribution
#' set.seed(123)
#' x <- rkkw(100, 2, 3, 1.5, 0.5)
#' hist(x, breaks = 20, main = "KKw(2, 3, 1.5, 0.5) Sample")
#'
#' # Use in optimization with Hessian-based methods
#' result <- optim(c(0.5, 0.5, 0.5, 0.5), llkkw, method = "BFGS",
#'                 hessian = TRUE, data = x)
#'
#' # Compare numerical and analytical derivatives
#' num_grad <- numDeriv::grad(llkkw, x = result$par, data = x)
#' num_hess <- numDeriv::hessian(llkkw, x = result$par, data = x)
#'
#' ana_grad <- grkkw(result$par, data = x)
#' ana_hess <- hskkw(result$par, data = x)
#'
#' # Check differences (should be very small)
#' round(num_grad - ana_grad, 4)
#' round(num_hess - ana_hess, 4)
#' }
#'
#' @seealso
#' \code{\link[gkwreg]{llkkw}} for the negative log-likelihood function,
#' \code{\link[gkwreg]{hskkw}} for the Hessian matrix of the KwKw log-likelihood,
#' \code{\link[gkwreg]{dkkw}} for the KwKw density function,
#'
#' @references
#' Kumaraswamy, P. (1980). A generalized probability density function for double-bounded random processes.
#' Journal of Hydrology, 46(1-2), 79-88.
#'
#' Cordeiro, G. M., & de Castro, M. (2011). A new family of generalized distributions.
#' Journal of Statistical Computation and Simulation, 81(7), 883-898.
#'
#' @export
grkkw <- function(par, data) {
    .Call(`_gkwreg_grkkw`, par, data)
}

#' @title Analytic Hessian Matrix for Kumaraswamy-Kumaraswamy Distribution
#'
#' @description
#' Computes the analytic Hessian matrix of the log-likelihood function for
#' the Kumaraswamy-Kumaraswamy (KKw) distribution. This function provides
#' exact second derivatives needed for optimization and inference.
#'
#' @param par Numeric vector of length 4 containing the parameters
#'        (α, β, δ, λ) in that order. All parameters must be positive.
#' @param data Numeric vector of observations, where all values must be
#'        in the open interval (0,1).
#'
#' @return A 4×4 numeric matrix representing the Hessian of the negative
#'         log-likelihood function. If parameters or data are invalid
#'         (parameters ≤ 0 or data outside (0,1)), returns a matrix of
#'         NaN values.
#'
#' @details
#' The log-likelihood for the Kumaraswamy-Kumaraswamy distribution is:
#'
#' \deqn{
#' \ell(\theta) = n \ln(\lambda) + n \ln(\alpha) + n \ln(\beta) + n \ln(\delta+1)
#' + (\alpha-1) \sum \ln(x_i)
#' + (\beta-1) \sum \ln(1 - x_i^\alpha)
#' + (\lambda-1) \sum \ln\{1 - (1 - x_i^\alpha)^\beta\}
#' + \delta \sum \ln\{1 - \{1 - (1 - x_i^\alpha)^\beta\}^\lambda\}
#' }
#'
#' where γ is fixed at 1 for this distribution.
#'
#' The implementation computes all second derivatives analytically for each term.
#' For computational efficiency, the following transformations are used:
#' \itemize{
#'   \item \deqn{A = x^α} and derivatives
#'   \item \deqn{v = 1 - A}
#'   \item \deqn{w = 1 - v^β}
#'   \item \deqn{z = 1 - w^λ}
#' }
#'
#' The returned Hessian matrix has the following structure:
#' \itemize{
#'   \item Rows/columns 1-4 correspond to α, β, δ, λ respectively
#'   \item The matrix is symmetric (as expected for a Hessian)
#'   \item The matrix represents second derivatives of the negative log-likelihood
#' }
#'
#' This function is implemented in C++ for computational efficiency.
#'
#' @examples
#' \dontrun{
#' # Generate sample data from a KKw distribution
#' set.seed(123)
#' x <- rkkw(100, 2, 3, 1.5, 0.5)
#' hist(x, breaks = 20, main = "KKw(2, 3, 1.5, 0.5) Sample")
#'
#' # Use in optimization with Hessian-based methods
#' result <- optim(c(0.5, 0.5, 0.5, 0.5), llkkw, method = "BFGS",
#'                 hessian = TRUE, data = x)
#'
#' # Compare numerical and analytical derivatives
#' num_grad <- numDeriv::grad(llkkw, x = result$par, data = x)
#' num_hess <- numDeriv::hessian(llkkw, x = result$par, data = x)
#'
#' ana_grad <- grkkw(result$par, data = x)
#' ana_hess <- hskkw(result$par, data = x)
#'
#' # Check differences (should be very small)
#' round(num_grad - ana_grad, 4)
#' round(num_hess - ana_hess, 4)
#' }
#'
#' @seealso
#' \code{\link[gkwreg]{dkkw}} for the KKw density function,
#' \code{\link[gkwreg]{kkwreg}} for fitting KKw regression models,
#' \code{\link[gkwreg]{pkkw}} for the KKw cumulative distribution function
#'
#' @references
#' Kumaraswamy, P. (1980). A generalized probability density function for double-bounded random processes.
#' Journal of Hydrology, 46(1-2), 79-88.
#'
#' Cordeiro, G. M., & de Castro, M. (2011). A new family of generalized distributions.
#' Journal of Statistical Computation and Simulation, 81(7), 883-898.
#'
#' @export
hskkw <- function(par, data) {
    .Call(`_gkwreg_hskkw`, par, data)
}

#' @title Density Function for Beta-Kumaraswamy Distribution
#'
#' @description
#' Computes the PDF of the Beta-Kumaraswamy distribution BKw(α, β, γ, δ) for x in (0, 1).
#' Optionally returns the log of the PDF.
#'
#' @param x Vector of quantiles in (0,1).
#' @param alpha Shape parameter α > 0.
#' @param beta Shape parameter β > 0.
#' @param gamma Shape parameter γ > 0.
#' @param delta Shape parameter δ ≥ 0.
#' @param log_prob Logical; if TRUE, returns log(f(x)).
#'
#' @return A vector of length max(length(x), lengths of parameters) with computed densities
#'         or log-densities. Values of x outside (0,1) yield 0 or -Inf (log-scale).
#'
#' @details
#' The PDF is given by
#' \deqn{
#'   f(x) = \frac{\alpha \beta}{B(\gamma, \delta+1)} \; x^{\alpha - 1} \; \bigl(1 - x^\alpha\bigr)^{\beta(\delta+1) - 1}\;
#'          \bigl[1 - \bigl(1 - x^\alpha\bigr)^\beta\bigr]^{\gamma - 1}, \quad 0<x<1.
#' }
#'
#' Note that BKw is a special case of the Generalized Kumaraswamy (GKw) with \eqn{\lambda=1}.
#'
#' @export
dbkw <- function(x, alpha, beta, gamma, delta, log_prob = FALSE) {
    .Call(`_gkwreg_dbkw`, x, alpha, beta, gamma, delta, log_prob)
}

#' @title CDF of Beta-Kumaraswamy Distribution
#'
#' @description
#' Computes the cumulative distribution function for BKw(α, β, γ, δ).
#'
#' @param q Vector of quantiles in (0,1).
#' @param alpha Shape parameter α > 0.
#' @param beta Shape parameter β > 0.
#' @param gamma Shape parameter γ > 0.
#' @param delta Shape parameter δ ≥ 0.
#' @param lower_tail Logical; if TRUE (default), returns F(q)=P(X≤q), else 1-F(q).
#' @param log_p Logical; if TRUE, returns log-probabilities.
#'
#' @details
#' CDF: \eqn{F(x) = I_{1 - (1 - x^α)^β}(\gamma, \delta+1)}, where \eqn{I_z(a,b)} is the
#' regularized incomplete beta function.
#'
#' @return A vector of probabilities, matching the length of the broadcast inputs.
#'
#' @export
pbkw <- function(q, alpha, beta, gamma, delta, lower_tail = TRUE, log_p = FALSE) {
    .Call(`_gkwreg_pbkw`, q, alpha, beta, gamma, delta, lower_tail, log_p)
}

#' @title Quantile Function of Beta-Kumaraswamy Distribution
#'
#' @description
#' Computes the quantile function for BKw(α, β, γ, δ). For p in (0,1), returns x such that
#' P(X ≤ x) = p under the BKw distribution.
#'
#' @param p Vector of probabilities in (0,1).
#' @param alpha, beta, gamma, delta Distribution parameters (see dbkw).
#' @param lower_tail Logical; if TRUE (default), p is F(x)=P(X≤x), otherwise p=1-F(x).
#' @param log_p Logical; if TRUE, p is given as log(p).
#'
#' @details
#' Inversion approach using \eqn{Q(p) = \{1 - [1 - qbeta(p, γ, δ+1)]^(1/β)\}^{1/\alpha}}.
#'
#' @return A vector of quantiles of the same length as the broadcast of p and parameters.
#'
#' @export
qbkw <- function(p, alpha, beta, gamma, delta, lower_tail = TRUE, log_p = FALSE) {
    .Call(`_gkwreg_qbkw`, p, alpha, beta, gamma, delta, lower_tail, log_p)
}

#' @title Random Generation from Beta-Kumaraswamy Distribution
#'
#' @description
#' Generates n samples from BKw(α, β, γ, δ) using the transformation:
#'   \eqn{V ~ Beta(γ, δ+1) => X = {1 - (1 - V)^(1/β)}^(1/α)}.
#'
#' @param n Integer number of observations to generate.
#' @param alpha, beta, gamma, delta Distribution parameters (see dbkw).
#'
#' @return A numeric vector of length n with random draws from the BKw distribution.
#'
#' @export
rbkw <- function(n, alpha, beta, gamma, delta) {
    .Call(`_gkwreg_rbkw`, n, alpha, beta, gamma, delta)
}

#' @title Negative Log-Likelihood for Beta-Kumaraswamy Distribution
#'
#' @description
#' Computes the negative log-likelihood of the BKw(α, β, γ, δ) model given data in (0,1).
#'
#' @param par NumericVector of length 4, \eqn{(α, β, γ, δ)}.
#' @param data NumericVector of observations, each in (0,1).
#'
#' @details
#' The PDF is
#' \deqn{
#'   f(x)=\frac{\alpha \beta}{B(\gamma, \delta+1)} x^{\alpha-1} (1-x^\alpha)^{\beta(\delta+1)-1} [1-(1-x^\alpha)^\beta]^{\gamma-1}.
#' }
#' The log-likelihood \eqn{\ell(\theta)} is the sum of log(f(x_i)) for i=1..n. We return
#' the negative log-likelihood for convenience in optimization.
#'
#' @return A single numeric value (the negative log-likelihood). Returns \code{-Inf} if
#'         parameters are invalid or if any data point is outside (0,1).
#'
#' @export
llbkw <- function(par, data) {
    .Call(`_gkwreg_llbkw`, par, data)
}

#' @title Gradient Function for Beta-Kumaraswamy Log-Likelihood
#'
#' @description
#' Calculates the gradient vector (partial derivatives) of the negative log-likelihood
#' function for the Beta-Kumaraswamy (BKw) distribution. This function provides
#' the exact gradient needed for efficient optimization in maximum likelihood estimation.
#' The BKw is a submodel of GKw with λ = 1 fixed.
#'
#' @param par NumericVector of length 4 containing parameters (α, β, γ, δ) in that order.
#'        All parameters must be positive.
#' @param data NumericVector of observations, where all values must be in the open interval (0,1).
#'
#' @return NumericVector of length 4 containing the gradient components (partial derivatives)
#'         of the negative log-likelihood with respect to each parameter (α, β, γ, δ).
#'         Returns a vector of NaN values if any parameters or data values are invalid.
#'
#' @details
#' The gradient vector contains the following partial derivatives of the negative log-likelihood:
#'
#' \deqn{
#' \frac{\partial \ell}{\partial \alpha} = \frac{n}{\alpha} + \sum_{i=1}^{n}\log(x_i) -
#' \sum_{i=1}^{n}\left[x_i^{\alpha} \log(x_i) \left(\frac{\beta(\delta+1)-1}{v_i} -
#' \frac{(\gamma-1) \beta v_i^{\beta-1}}{w_i}\right)\right]
#' }
#'
#' \deqn{
#' \frac{\partial \ell}{\partial \beta} = \frac{n}{\beta} + (\delta+1)\sum_{i=1}^{n}\log(v_i) -
#' \sum_{i=1}^{n}\left[v_i^{\beta} \log(v_i) \frac{\gamma-1}{w_i}\right]
#' }
#'
#' \deqn{
#' \frac{\partial \ell}{\partial \gamma} = -n[\psi(\gamma) - \psi(\gamma+\delta+1)] +
#' \sum_{i=1}^{n}\log(w_i)
#' }
#'
#' \deqn{
#' \frac{\partial \ell}{\partial \delta} = -n[\psi(\delta+1) - \psi(\gamma+\delta+1)] +
#' \beta\sum_{i=1}^{n}\log(v_i)
#' }
#'
#' where:
#' \itemize{
#'   \item \deqn{v_i = 1 - x_i^{\alpha}}
#'   \item \deqn{w_i = 1 - v_i^{\beta} = 1 - (1-x_i^{\alpha})^{\beta}}
#'   \item \deqn{\psi} is the digamma function (derivative of the log-gamma function)
#' }
#'
#' The implementation includes several numerical safeguards:
#' \itemize{
#'   \item Parameter and data validation with appropriate error handling
#'   \item Clamping of intermediate values to avoid numerical underflow/overflow
#'   \item Efficient vector operations using Armadillo C++ library
#' }
#'
#' The returned gradient is negated to align with minimization of negative log-likelihood
#' in optimization routines.
#'
#' @examples
#' \dontrun{
#' # Generate sample data from a BKw distribution
#' set.seed(123)
#' x <- rbkw(100, 2, 3, 1, 0.5)
#' hist(x, breaks = 20, main = "BKw(2, 3, 1, 0.5) Sample")
#'
#' # Use in optimization with Hessian-based methods
#' result <- optim(c(0.5, 0.5, 0.5, 0.5), llbkw, method = "BFGS",
#'                 hessian = TRUE, data = x)
#'
#' # Compare numerical and analytical derivatives
#' num_grad <- numDeriv::grad(llbkw, x = result$par, data = x)
#' num_hess <- numDeriv::hessian(llbkw, x = result$par, data = x)
#'
#' ana_grad <- grbkw(result$par, data = x)
#' ana_hess <- hsbkw(result$par, data = x)
#'
#' # Check differences (should be very small)
#' round(num_grad - ana_grad, 4)
#' round(num_hess - ana_hess, 4)
#'
#' }
#'
#' @seealso
#' \code{\link[gkwreg]{llbkw}} for the negative log-likelihood function,
#' \code{\link[gkwreg]{hsbkw}} for the Hessian matrix of the BKw log-likelihood,
#' \code{\link[gkwreg]{dbkw}} for the BKw density function,
#'
#' @references
#' Kumaraswamy, P. (1980). A generalized probability density function for double-bounded random processes.
#' Journal of Hydrology, 46(1-2), 79-88.
#'
#' Cordeiro, G. M., & de Castro, M. (2011). A new family of generalized distributions.
#' Journal of Statistical Computation and Simulation, 81(7), 883-898.
#'
#' @export
grbkw <- function(par, data) {
    .Call(`_gkwreg_grbkw`, par, data)
}

#' @title Analytic Hessian Matrix for Beta-Kumaraswamy Distribution
#'
#' @description
#' Computes the analytic Hessian matrix of the log-likelihood function for
#' the Beta-Kumaraswamy (BKw) distribution. This function provides
#' exact second derivatives needed for optimization and inference.
#'
#' @param par Numeric vector of length 4 containing the parameters
#'        (α, β, γ, δ) in that order. All parameters must be positive.
#' @param data Numeric vector of observations, where all values must be
#'        in the open interval (0,1).
#'
#' @return A 4×4 numeric matrix representing the Hessian of the negative
#'         log-likelihood function. If parameters or data are invalid
#'         (parameters ≤ 0 or data outside (0,1)), returns a matrix of
#'         NaN values.
#'
#' @details
#' The log-likelihood for the Beta-Kumaraswamy distribution is:
#'
#' \deqn{
#' \ell(\theta) = n \ln(\alpha) + n \ln(\beta) - n \ln B(\gamma, \delta+1)
#' + (\alpha-1) \sum \ln(x_i)
#' + (\beta(\delta+1)-1) \sum \ln(1 - x_i^\alpha)
#' + (\gamma-1) \sum \ln\{1 - (1 - x_i^\alpha)^\beta\}
#' }
#'
#' where λ is fixed at 1 for this distribution.
#'
#' The implementation computes all second derivatives analytically for each term.
#' For computational efficiency, the following transformations are used:
#' \itemize{
#'   \item \deqn{A = x^α} and derivatives
#'   \item \deqn{v = 1 - A}
#'   \item \deqn{w = 1 - v^β}
#' }
#'
#' The returned Hessian matrix has the following structure:
#' \itemize{
#'   \item Rows/columns 1-4 correspond to α, β, γ, δ respectively
#'   \item The matrix is symmetric (as expected for a Hessian)
#'   \item The matrix represents second derivatives of the negative log-likelihood
#' }
#'
#' This function is implemented in C++ for computational efficiency.
#'
#' @examples
#' \dontrun{
#' # Generate sample data from a BKw distribution
#' set.seed(123)
#' x <- rbkw(100, 2, 3, 1, 0.5)
#' hist(x, breaks = 20, main = "BKw(2, 3, 1, 0.5) Sample")
#'
#' # Use in optimization with Hessian-based methods
#' result <- optim(c(0.5, 0.5, 0.5, 0.5), llbkw, method = "BFGS",
#'                 hessian = TRUE, data = x)
#'
#' # Compare numerical and analytical derivatives
#' num_grad <- numDeriv::grad(llbkw, x = result$par, data = x)
#' num_hess <- numDeriv::hessian(llbkw, x = result$par, data = x)
#'
#' ana_grad <- grbkw(result$par, data = x)
#' ana_hess <- hsbkw(result$par, data = x)
#'
#' # Check differences (should be very small)
#' round(num_grad - ana_grad, 4)
#' round(num_hess - ana_hess, 4)
#'
#' }
#'
#' @seealso
#' \code{\link[gkwreg]{dbkw}} for the BKw density function,
#' \code{\link[gkwreg]{bkwreg}} for fitting BKw regression models,
#' \code{\link[gkwreg]{pbkw}} for the BKw cumulative distribution function
#'
#' @references
#' Kumaraswamy, P. (1980). A generalized probability density function for double-bounded random processes.
#' Journal of Hydrology, 46(1-2), 79-88.
#'
#' Cordeiro, G. M., & de Castro, M. (2011). A new family of generalized distributions.
#' Journal of Statistical Computation and Simulation, 81(7), 883-898.
#'
#' @export
hsbkw <- function(par, data) {
    .Call(`_gkwreg_hsbkw`, par, data)
}

#' @title Density for Exponentiated Kumaraswamy Distribution
#'
#' @description
#' Computes the PDF of EKw(α, β, λ), where \eqn{\alpha, β, λ > 0}.
#'
#' @param x Vector of quantiles in (0,1).
#' @param alpha Shape parameter \eqn{\alpha > 0}.
#' @param beta Shape parameter \eqn{\beta > 0}.
#' @param lambda Shape parameter \eqn{\lambda > 0}.
#' @param log_prob Logical; if TRUE, returns log-density, else density.
#'
#' @details
#' The PDF is
#' \deqn{
#'   f(x) = \lambda\,\alpha\,\beta \; x^{\alpha-1} (1 - x^α)^{\beta-1} \;
#'          [1 - (1 - x^α)^\beta ]^{\lambda - 1}, \quad 0<x<1.
#' }
#' This follows from the GKw distribution with \eqn{\gamma=1,\;\delta=0}.
#'
#' @return A vector of the same length as the broadcast of (x, alpha, beta, lambda).
#'
#' @export
dekw <- function(x, alpha, beta, lambda, log_prob = FALSE) {
    .Call(`_gkwreg_dekw`, x, alpha, beta, lambda, log_prob)
}

#' @title CDF for Exponentiated Kumaraswamy Distribution
#'
#' @description
#' Computes F(x)= P(X ≤ x) for EKw(α, β, λ).
#'
#' @param q Vector of quantiles in (0,1).
#' @param alpha, beta, lambda Distribution parameters (see dekw).
#' @param lower_tail Logical; if TRUE, returns F(q); else 1-F(q).
#' @param log_p Logical; if TRUE, returns log(F(q)) or log(1-F(q)).
#'
#' @details
#' The CDF is
#' \deqn{
#'   F(x)= [1 - (1 - x^α)^β ]^λ, \quad 0<x<1.
#' }
#'
#' @return A vector of probabilities of the same length as the broadcast of inputs.
#'
#' @export
pekw <- function(q, alpha, beta, lambda, lower_tail = TRUE, log_p = FALSE) {
    .Call(`_gkwreg_pekw`, q, alpha, beta, lambda, lower_tail, log_p)
}

#' @title Quantile Function for Exponentiated Kumaraswamy
#'
#' @description
#' Computes the quantiles x = Q(p) for EKw(α, β, λ).
#'
#' @param p Vector of probabilities in [0,1].
#' @param alpha, beta, lambda Distribution parameters.
#' @param lower_tail Logical; if TRUE, p is F(x). If FALSE, p=1-F(x).
#' @param log_p Logical; if TRUE, p is given as log(p).
#'
#' @details
#' The inverse of F(x)= [1 - (1 - x^α)^β ]^λ is
#' \deqn{
#'   Q(p)= \Bigl\{1 - \bigl[1 - p^{1/\lambda}\bigr]^{1/\beta}\Bigr\}^{1/\alpha}.
#' }
#' if lower_tail=TRUE. Adjust accordingly if \code{lower_tail=FALSE} or \code{log_p=TRUE}.
#'
#' @export
qekw <- function(p, alpha, beta, lambda, lower_tail = TRUE, log_p = FALSE) {
    .Call(`_gkwreg_qekw`, p, alpha, beta, lambda, lower_tail, log_p)
}

#' @title Random Generation for Exponentiated Kumaraswamy Distribution
#'
#' @description
#' Generates n samples from EKw(α, β, λ).
#'
#' @param n Integer number of observations.
#' @param alpha, beta, lambda Distribution parameters (see dekw).
#'
#' @details
#' Implementation via the quantile method:  X = Q(U),  U ~ Uniform(0,1).
#' The quantile is
#' \deqn{
#'   Q(u)= \Bigl\{1 - \bigl[1 - u^{1/\lambda}\bigr]^{1/\beta}\Bigr\}^{1/\alpha}.
#' }
#'
#' @export
rekw <- function(n, alpha, beta, lambda) {
    .Call(`_gkwreg_rekw`, n, alpha, beta, lambda)
}

#' @title Negative Log-Likelihood for Exponentiated Kumaraswamy
#'
#' @description
#' Computes the negative log-likelihood of EKw(α, β, λ), for data in (0,1).
#'
#' @param par NumericVector of length 3, (α, β, λ).
#' @param data NumericVector of observations, each in (0,1).
#'
#' @details
#' The PDF is
#' \deqn{
#'  f(x)= \lambda\,\alpha\,\beta \, x^{\alpha-1}\,(1-x^\alpha)^{\beta-1}\,[1-(1-x^\alpha)^\beta]^{\lambda-1}.
#' }
#' The log-likelihood is the sum of log(f(x_i)). We return the negative log-likelihood.
#'
#' @return A double value: the negative log-likelihood. \code{Inf} if invalid.
#'
#' @examples
#' \dontrun{
#' # Generate sample data from an EKw distribution
#' set.seed(123)
#' x <- rekw(100, 2, 3, 0.5)
#' hist(x, breaks = 20, main = "EKw(2, 3, 0.5) Sample")
#'
#' # Use in optimization with Hessian-based methods
#' result <- optim(c(0.5, 0.5, 0.5), llekw, method = "BFGS",
#'                 hessian = TRUE, data = x)
#'
#' # Compare numerical and analytical derivatives
#' num_grad <- numDeriv::grad(llekw, x = result$par, data = x)
#' num_hess <- numDeriv::hessian(llekw, x = result$par, data = x)
#'
#' ana_grad <- grekw(result$par, data = x)
#' ana_hess <- hsekw(result$par, data = x)
#'
#' # Check differences (should be very small)
#' round(num_grad - ana_grad, 4)
#' round(num_hess - ana_hess, 4)
#' }
#'
#' @export
llekw <- function(par, data) {
    .Call(`_gkwreg_llekw`, par, data)
}

#' @title Gradient Function for Exponentiated Kumaraswamy Log-Likelihood
#'
#' @description
#' Calculates the gradient vector (partial derivatives) of the negative log-likelihood
#' function for the Exponentiated Kumaraswamy (EKw) distribution. This function provides
#' the exact gradient needed for efficient optimization in maximum likelihood estimation.
#'
#' @param par NumericVector of length 3 containing parameters (α, β, λ) in that order.
#'        All parameters must be positive.
#' @param data NumericVector of observations, where all values must be in the open interval (0,1).
#'
#' @return NumericVector of length 3 containing the gradient components (partial derivatives)
#'         of the negative log-likelihood with respect to each parameter (α, β, λ).
#'         Returns a vector of NaN values if any parameters or data values are invalid.
#'
#' @details
#' The gradient vector contains the following partial derivatives of the negative log-likelihood:
#'
#' \deqn{
#' \frac{\partial \ell}{\partial \alpha} = \frac{n}{\alpha} + \sum_{i=1}^{n}\log(x_i) -
#' \sum_{i=1}^{n}\left[x_i^{\alpha} \log(x_i) \left(\frac{\beta-1}{v_i} -
#' \frac{(\lambda-1) \beta v_i^{\beta-1}}{w_i}\right)\right]
#' }
#'
#' \deqn{
#' \frac{\partial \ell}{\partial \beta} = \frac{n}{\beta} + \sum_{i=1}^{n}\log(v_i) -
#' \sum_{i=1}^{n}\left[v_i^{\beta} \log(v_i) \frac{\lambda-1}{w_i}\right]
#' }
#'
#' \deqn{
#' \frac{\partial \ell}{\partial \lambda} = \frac{n}{\lambda} +
#' \sum_{i=1}^{n}\log(w_i)
#' }
#'
#' where:
#' \itemize{
#'   \item \deqn{v_i = 1 - x_i^{\alpha}}
#'   \item \deqn{w_i = 1 - v_i^{\beta} = 1 - (1-x_i^{\alpha})^{\beta}}
#' }
#' @examples
#' \dontrun{
#' # Generate sample data from an EKw distribution
#' set.seed(123)
#' x <- rekw(100, 2, 3, 0.5)
#' hist(x, breaks = 20, main = "EKw(2, 3, 0.5) Sample")
#'
#' # Use in optimization with Hessian-based methods
#' result <- optim(c(0.5, 0.5, 0.5), llekw, method = "BFGS",
#'                 hessian = TRUE, data = x)
#'
#' # Compare numerical and analytical derivatives
#' num_grad <- numDeriv::grad(llekw, x = result$par, data = x)
#' num_hess <- numDeriv::hessian(llekw, x = result$par, data = x)
#'
#' ana_grad <- grekw(result$par, data = x)
#' ana_hess <- hsekw(result$par, data = x)
#'
#' # Check differences (should be very small)
#' round(num_grad - ana_grad, 4)
#' round(num_hess - ana_hess, 4)
#' }
#'
#' @references
#' Kumaraswamy, P. (1980). A generalized probability density function for double-bounded random processes.
#' Journal of Hydrology, 46(1-2), 79-88.
#'
#' Cordeiro, G. M., & de Castro, M. (2011). A new family of generalized distributions.
#' Journal of Statistical Computation and Simulation, 81(7), 883-898.
#'
#' @export
grekw <- function(par, data) {
    .Call(`_gkwreg_grekw`, par, data)
}

#' @title Analytic Hessian Matrix for Exponentiated Kumaraswamy Distribution
#'
#' @description
#' Computes the analytic Hessian matrix of the log-likelihood function for
#' the Exponentiated Kumaraswamy (EKw) distribution. This function provides
#' exact second derivatives needed for optimization and inference.
#'
#' @param par Numeric vector of length 3 containing the parameters
#'        (α, β, λ) in that order. All parameters must be positive.
#' @param data Numeric vector of observations, where all values must be
#'        in the open interval (0,1).
#'
#' @return A 3×3 numeric matrix representing the Hessian of the negative
#'         log-likelihood function. If parameters or data are invalid
#'         (parameters ≤ 0 or data outside (0,1)), returns a matrix of
#'         NaN values.
#'
#' @details
#' The log-likelihood for the Exponentiated Kumaraswamy distribution is:
#'
#' \deqn{
#' \ell(\theta) = n \ln(\lambda) + n \ln(\alpha) + n \ln(\beta)
#' + (\alpha-1) \sum \ln(x_i)
#' + (\beta-1) \sum \ln(1 - x_i^\alpha)
#' + (\lambda-1) \sum \ln\{1 - (1 - x_i^\alpha)^\beta\}
#' }
#'
#' The implementation computes all second derivatives analytically for each term.
#' For computational efficiency, the following transformations are used:
#' \itemize{
#'   \item \deqn{A = x^α} and derivatives
#'   \item \deqn{v = 1 - A}
#'   \item \deqn{w = 1 - v^β}
#' }
#'
#' The returned Hessian matrix has the following structure:
#' \itemize{
#'   \item Rows/columns 1-3 correspond to α, β, λ respectively
#'   \item The matrix is symmetric (as expected for a Hessian)
#'   \item The matrix represents second derivatives of the negative log-likelihood
#' }
#'
#' This function is implemented in C++ for computational efficiency.
#'
#' @examples
#' \dontrun{
#' # Generate sample data from an EKw distribution
#' set.seed(123)
#' x <- rekw(100, 2, 3, 0.5)
#' hist(x, breaks = 20, main = "EKw(2, 3, 0.5) Sample")
#'
#' # Use in optimization with Hessian-based methods
#' result <- optim(c(0.5, 0.5, 0.5), llekw, method = "BFGS",
#'                 hessian = TRUE, data = x)
#'
#' # Compare numerical and analytical derivatives
#' num_grad <- numDeriv::grad(llekw, x = result$par, data = x)
#' num_hess <- numDeriv::hessian(llekw, x = result$par, data = x)
#'
#' ana_grad <- grekw(result$par, data = x)
#' ana_hess <- hsekw(result$par, data = x)
#'
#' # Check differences (should be very small)
#' round(num_grad - ana_grad, 4)
#' round(num_hess - ana_hess, 4)
#'
#' }
#'
#' @seealso
#' \code{\link[gkwreg]{dekw}} for the EKw density function,
#' \code{\link[gkwreg]{ekwreg}} for fitting EKw regression models,
#' \code{\link[gkwreg]{pekw}} for the EKw cumulative distribution function
#'
#' @references
#' Kumaraswamy, P. (1980). A generalized probability density function for double-bounded random processes.
#' Journal of Hydrology, 46(1-2), 79-88.
#'
#' Cordeiro, G. M., & de Castro, M. (2011). A new family of generalized distributions.
#' Journal of Statistical Computation and Simulation, 81(7), 883-898.
#'
#' @export
hsekw <- function(par, data) {
    .Call(`_gkwreg_hsekw`, par, data)
}

#' @title Density of the Beta Power Distribution
#'
#' @description
#' Computes the PDF of the Beta Power (BP) distribution with parameters \eqn{γ, δ, λ}.
#'
#' @param x Vector of quantiles in (0,1).
#' @param gamma Shape parameter \eqn{γ > 0}.
#' @param delta Shape parameter \eqn{δ \ge 0}.
#' @param lambda Shape parameter \eqn{λ > 0}.
#' @param log_prob Logical; if TRUE, returns log-density.
#'
#' @details
#' The PDF is
#' \deqn{
#'   f(x) = \frac{\lambda}{B(\gamma,\delta+1)} \; x^{\gamma \lambda - 1} \; (1 - x^\lambda)^\delta, \quad 0<x<1.
#' }
#' with \eqn{B(\gamma,\delta+1)} the Beta function. This sub-family arises
#' from the Generalized Kumaraswamy (GKw) by setting \eqn{\alpha=1,\beta=1}.
#'
#' @return A vector of densities or log-densities, the same length as the broadcast of inputs.
#'
#' @export
dbp <- function(x, gamma, delta, lambda, log_prob = FALSE) {
    .Call(`_gkwreg_dbp`, x, gamma, delta, lambda, log_prob)
}

#' @title CDF of the Beta Power Distribution
#'
#' @description
#' Computes F(q)= P(X ≤ q) for BP(γ, δ, λ).
#'
#' @param q Vector of quantiles in (0,1).
#' @param gamma, delta, lambda Distribution parameters.
#' @param lower_tail Logical; if TRUE, returns F(q), else 1-F(q).
#' @param log_p Logical; if TRUE, returns log-probabilities.
#'
#' @details
#' \deqn{
#'   F(x)= I_{x^\lambda}(\gamma, \delta+1) \;=\; \mathrm{pbeta}(x^\lambda,\;\gamma,\;\delta+1).
#' }
#' The incomplete Beta approach is used for stable evaluation.
#'
#' @export
pbp <- function(q, gamma, delta, lambda, lower_tail = TRUE, log_p = FALSE) {
    .Call(`_gkwreg_pbp`, q, gamma, delta, lambda, lower_tail, log_p)
}

#' @title Quantile Function of the Beta Power Distribution
#'
#' @description
#' Computes x = Q(p), the quantile function for BP(γ, δ, λ).
#'
#' @param p Vector of probabilities in [0,1] (or in log scale if log_p=TRUE).
#' @param gamma, delta, lambda Distribution parameters.
#' @param lower_tail Logical; if TRUE, p=F(x). If FALSE, p=1-F(x).
#' @param log_p Logical; if TRUE, p is log(p).
#'
#' @details
#' The quantile function is
#' \deqn{
#'   Q(p) = \Bigl[\mathrm{qbeta}(p,\;\gamma,\;\delta+1)\Bigr]^{1/\lambda}.
#' }
#' if lower_tail=TRUE and log_p=FALSE. Adjust for tails or logs accordingly.
#'
#' @export
qbp <- function(p, gamma, delta, lambda, lower_tail = TRUE, log_p = FALSE) {
    .Call(`_gkwreg_qbp`, p, gamma, delta, lambda, lower_tail, log_p)
}

#' @title Random Generation from Beta Power Distribution
#'
#' @description
#' Generates n samples from BP(γ, δ, λ) by drawing U ~ Beta(γ, δ+1) then X= U^(1/λ).
#'
#' @param n Integer number of observations.
#' @param gamma, delta, lambda Distribution parameters.
#'
#' @return A numeric vector of length n with random draws in (0,1).
#'
#' @details
#' The distribution arises from GKw with \eqn{\alpha=1,\beta=1}. This is sometimes
#' also called the Beta-Power distribution in the literature.
#'
#' @export
rbp <- function(n, gamma, delta, lambda) {
    .Call(`_gkwreg_rbp`, n, gamma, delta, lambda)
}

#' @title Negative Log-Likelihood for Beta Power Distribution
#'
#' @description
#' Computes -log-likelihood for BP(γ, δ, λ) given data in (0,1).
#'
#' @param par NumericVector of length 3: (γ, δ, λ).
#' @param data NumericVector of observations in (0,1).
#'
#' @details
#' The PDF is
#' \deqn{
#'   f(x)= \frac{\lambda}{B(\gamma,\delta+1)} x^{\gamma\lambda -1} (1 - x^\lambda)^\delta.
#' }
#' The log-likelihood is the sum of log(f(x_i)). We return the negative of that sum.
#'
#' @return A single numeric value. \code{+Inf} if invalid parameters or data out of (0,1).
#'
#' @examples
#' \dontrun{
#' # Generate sample data from a BP distribution
#' set.seed(123)
#' x <- rbp(100, 2, 3, 0.5)
#' hist(x, breaks = 20, main = "BP(2, 3, 0.5) Sample")
#'
#' # Use in optimization with Hessian-based methods
#' result <- optim(c(0.5, 0.5, 0.5), llbp, method = "BFGS",
#'                 hessian = TRUE, data = x)
#'
#' # Compare numerical and analytical derivatives
#' num_grad <- numDeriv::grad(llbp, x = result$par, data = x)
#' num_hess <- numDeriv::hessian(llbp, x = result$par, data = x)
#'
#' ana_grad <- grbp(result$par, data = x)
#' ana_hess <- hsbp(result$par, data = x)
#'
#' # Check differences (should be very small)
#' round(num_grad - ana_grad, 4)
#' round(num_hess - ana_hess, 4)
#' }
#'
#' @export
llbp <- function(par, data) {
    .Call(`_gkwreg_llbp`, par, data)
}

#' @title Gradient Function for Beta Power Log-Likelihood
#'
#' @description
#' Calculates the gradient vector (partial derivatives) of the negative log-likelihood
#' function for the Beta Power (BP) distribution, also known as McDonald distribution.
#' This function provides the exact gradient needed for efficient optimization in
#' maximum likelihood estimation. The BP is a submodel of GKw with α = 1 and β = 1 fixed.
#'
#' @param par NumericVector of length 3 containing parameters (γ, δ, λ) in that order.
#'        All parameters must be positive.
#' @param data NumericVector of observations, where all values must be in the open interval (0,1).
#'
#' @return NumericVector of length 3 containing the gradient components (partial derivatives)
#'         of the negative log-likelihood with respect to each parameter (γ, δ, λ).
#'         Returns a vector of NaN values if any parameters or data values are invalid.
#'
#' @details
#' The gradient vector contains the following partial derivatives of the negative log-likelihood:
#'
#' \deqn{
#' \frac{\partial \ell}{\partial \gamma} = -n[\psi(\gamma+\delta+1) - \psi(\gamma)] -
#' \lambda\sum_{i=1}^{n}\log(x_i)
#' }
#'
#' \deqn{
#' \frac{\partial \ell}{\partial \delta} = -n[\psi(\gamma+\delta+1) - \psi(\delta+1)] -
#' \sum_{i=1}^{n}\log(1-x_i^{\lambda})
#' }
#'
#' \deqn{
#' \frac{\partial \ell}{\partial \lambda} = -\frac{n}{\lambda} - \gamma\sum_{i=1}^{n}\log(x_i) +
#' \delta\sum_{i=1}^{n}\frac{x_i^{\lambda}\log(x_i)}{1-x_i^{\lambda}}
#' }
#'
#' where:
#' \itemize{
#'   \item \deqn{\psi} is the digamma function (derivative of the log-gamma function)
#' }
#'
#' The implementation includes several numerical safeguards:
#' \itemize{
#'   \item Parameter and data validation with appropriate error handling
#'   \item Clamping of intermediate values to avoid numerical underflow/overflow
#'   \item Efficient vector operations using Armadillo C++ library
#' }
#'
#' The returned gradient is negated to align with minimization of negative log-likelihood
#' in optimization routines.
#'
#' @examples
#' \dontrun{
#' # Generate sample data from a BP distribution
#' set.seed(123)
#' x <- rbp(100, 2, 3, 0.5)
#' hist(x, breaks = 20, main = "BP(2, 3, 0.5) Sample")
#'
#' # Use in optimization with Hessian-based methods
#' result <- optim(c(0.5, 0.5, 0.5), llbp, method = "BFGS",
#'                 hessian = TRUE, data = x)
#'
#' # Compare numerical and analytical derivatives
#' num_grad <- numDeriv::grad(llbp, x = result$par, data = x)
#' num_hess <- numDeriv::hessian(llbp, x = result$par, data = x)
#'
#' ana_grad <- grbp(result$par, data = x)
#' ana_hess <- hsbp(result$par, data = x)
#'
#' # Check differences (should be very small)
#' round(num_grad - ana_grad, 4)
#' round(num_hess - ana_hess, 4)
#' }
#'
#' @seealso
#' \code{\link[gkwreg]{llbp}} for the negative log-likelihood function,
#' \code{\link[gkwreg]{hsbp}} for the Hessian matrix of the BP log-likelihood,
#' \code{\link[gkwreg]{dbp}} for the BP density function,
#'
#' @references
#' McDonald, J. B. (1984). Some generalized functions for the size distribution of income.
#' Econometrica, 52(3), 647-665.
#'
#' Cordeiro, G. M., & de Castro, M. (2011). A new family of generalized distributions.
#' Journal of Statistical Computation and Simulation, 81(7), 883-898.
#'
#' @export
grbp <- function(par, data) {
    .Call(`_gkwreg_grbp`, par, data)
}

#' @title Hessian Matrix Function for Beta Power (McDonald) Log-Likelihood
#'
#' @description
#' Calculates the Hessian matrix (second-order partial derivatives) of the negative log-likelihood
#' function for the Beta Power (BP) distribution, also known as McDonald distribution.
#' This function provides the exact Hessian needed for efficient optimization in maximum likelihood
#' estimation and for asymptotic inference. The BP is a submodel of GKw with α = 1 and β = 1 fixed.
#'
#' @param par NumericVector of length 3 containing parameters (γ, δ, λ) in that order.
#'        All parameters must be positive.
#' @param data NumericVector of observations, where all values must be in the open interval (0,1).
#'
#' @return NumericMatrix of dimensions 3x3 containing the Hessian components (second derivatives)
#'         of the negative log-likelihood with respect to each parameter pair (γ, δ, λ).
#'         Returns a matrix of NaN values if any parameters or data values are invalid.
#'
#' @details
#' The Hessian matrix contains the following second derivatives of the negative log-likelihood:
#'
#' \deqn{
#' \frac{\partial^2 \ell}{\partial \gamma^2} = -n[\psi'(\gamma+\delta+1) - \psi'(\gamma)]
#' }
#'
#' \deqn{
#' \frac{\partial^2 \ell}{\partial \gamma \partial \delta} = -n\psi'(\gamma+\delta+1)
#' }
#'
#' \deqn{
#' \frac{\partial^2 \ell}{\partial \gamma \partial \lambda} = -\sum_{i=1}^{n}\log(x_i)
#' }
#'
#' \deqn{
#' \frac{\partial^2 \ell}{\partial \delta^2} = -n[\psi'(\gamma+\delta+1) - \psi'(\delta+1)]
#' }
#'
#' \deqn{
#' \frac{\partial^2 \ell}{\partial \delta \partial \lambda} = \sum_{i=1}^{n}\frac{x_i^{\lambda}\log(x_i)}{1-x_i^{\lambda}}
#' }
#'
#' \deqn{
#' \frac{\partial^2 \ell}{\partial \lambda^2} = \frac{n}{\lambda^2} + \gamma^2\sum_{i=1}^{n}[\log(x_i)]^2 +
#' \delta\sum_{i=1}^{n}\frac{x_i^{\lambda}[\log(x_i)]^2}{1-x_i^{\lambda}}\left(1 + \frac{x_i^{\lambda}}{1-x_i^{\lambda}}\right)
#' }
#'
#' where:
#' \itemize{
#'   \item \deqn{\psi'} is the trigamma function (second derivative of the log-gamma function)
#' }
#'
#' The implementation includes several numerical safeguards:
#' \itemize{
#'   \item Parameter and data validation with appropriate error handling
#'   \item Clamping of intermediate values to avoid numerical underflow/overflow
#'   \item Symmetry of the Hessian matrix is guaranteed by construction
#'   \item Efficient vector operations using Armadillo C++ library
#' }
#'
#' The returned Hessian is negated to align with minimization of negative log-likelihood
#' in optimization routines.
#'
#' @examples
#' \dontrun{
#' # Generate sample data from a BP distribution
#' set.seed(123)
#' x <- rbp(100, 2, 3, 0.5)
#' hist(x, breaks = 20, main = "BP(2, 3, 0.5) Sample")
#'
#' # Use in optimization with Hessian-based methods
#' result <- optim(c(0.5, 0.5, 0.5), llbp, method = "BFGS",
#'                 hessian = TRUE, data = x)
#'
#' # Compare numerical and analytical derivatives
#' num_grad <- numDeriv::grad(llbp, x = result$par, data = x)
#' num_hess <- numDeriv::hessian(llbp, x = result$par, data = x)
#'
#' ana_grad <- grbp(result$par, data = x)
#' ana_hess <- hsbp(result$par, data = x)
#'
#' # Check differences (should be very small)
#' round(num_grad - ana_grad, 4)
#' round(num_hess - ana_hess, 4)
#' }
#'
#' @seealso
#' \code{\link[gkwreg]{llbp}} for the negative log-likelihood function,
#' \code{\link[gkwreg]{grbp}} for the gradient of the BP log-likelihood,
#' \code{\link[gkwreg]{dbp}} for the BP density function,
#'
#' @references
#' McDonald, J. B. (1984). Some generalized functions for the size distribution of income.
#' Econometrica, 52(3), 647-665.
#'
#' Cordeiro, G. M., & de Castro, M. (2011). A new family of generalized distributions.
#' Journal of Statistical Computation and Simulation, 81(7), 883-898.
#'
#' @export
hsbp <- function(par, data) {
    .Call(`_gkwreg_hsbp`, par, data)
}

#' @title PDF of the Kumaraswamy Distribution
#'
#' @description
#' Computes the PDF of Kw(\eqn{\alpha,\beta}) at values x in (0,1).
#'
#' @param x Vector of quantiles in (0,1).
#' @param alpha Shape parameter \eqn{\alpha>0}.
#' @param beta Shape parameter \eqn{\beta>0}.
#' @param log_prob If TRUE, returns log of the PDF.
#'
#' @return A vector of (log-)densities, same length as broadcast of x and parameters.
#'
#' @details
#' PDF: \eqn{f(x)= \alpha\,\beta \; x^{\alpha-1}\,(1 - x^\alpha)^{\beta-1}}, for 0<x<1.
#'
#' @export
dkw <- function(x, alpha, beta, log_prob = FALSE) {
    .Call(`_gkwreg_dkw`, x, alpha, beta, log_prob)
}

#' @title CDF of the Kumaraswamy Distribution
#'
#' @description
#' Computes \eqn{F(q)= P(X ≤ q)} for Kw(\eqn{\alpha,\beta}).
#'
#' @param q Vector of quantiles in (0,1).
#' @param alpha, beta Shape parameters >0.
#' @param lower_tail If TRUE (default), returns \eqn{F(q)=P(X≤q)}. If FALSE, 1-F(q).
#' @param log_p If TRUE, returns log probabilities.
#'
#' @return Vector of probabilities or log-probabilities, matching broadcast of q and parameters.
#'
#' @details
#' \eqn{F(x)= 1 - (1 - x^\alpha)^\beta}, for 0<x<1.
#'
#' @export
pkw <- function(q, alpha, beta, lower_tail = TRUE, log_p = FALSE) {
    .Call(`_gkwreg_pkw`, q, alpha, beta, lower_tail, log_p)
}

#' @title Quantile Function of the Kumaraswamy Distribution
#'
#' @description
#' For p in (0,1), returns x=Q(p) such that F(x)=p, where F is Kw(\eqn{\alpha,\beta}).
#'
#' @param p Vector of probabilities in [0,1] (or log scale if log_p=TRUE).
#' @param alpha, beta Shape parameters >0.
#' @param lower_tail If TRUE, p=F(x); if FALSE, p=1-F(x).
#' @param log_p If TRUE, p is log(p).
#'
#' @details
#' \eqn{Q(p)= {1 - [1 - p]^(1/\beta)}^(1/\alpha)}
#'
#' @export
qkw <- function(p, alpha, beta, lower_tail = TRUE, log_p = FALSE) {
    .Call(`_gkwreg_qkw`, p, alpha, beta, lower_tail, log_p)
}

#' @title Random Generation from the Kumaraswamy Distribution
#'
#' @description
#' Generates n samples from Kw(\eqn{\alpha,\beta}), using the transformation from Uniform(0,1).
#'
#' @param n Integer number of observations.
#' @param alpha, beta Shape parameters > 0.
#'
#' @return A vector of length n with samples in (0,1).
#'
#' @details
#' If V ~ Uniform(0,1), then
#' \eqn{X= \{1 - [1 - V]^{1/\beta}\}^{1/\alpha}}.
#'
#' @export
rkw <- function(n, alpha, beta) {
    .Call(`_gkwreg_rkw`, n, alpha, beta)
}

#' @title Negative Log-Likelihood of the Kumaraswamy Distribution
#'
#' @description
#' Computes the negative log-likelihood for Kw(\eqn{\alpha,\beta}) given data in (0,1).
#'
#' @param par NumericVector of length 2: (alpha, beta).
#' @param data NumericVector of observations in (0,1).
#'
#' @return A single numeric value. \code{+Inf} if invalid parameters or data.
#'
#' @details
#' The PDF is
#' \eqn{ f(x)= \alpha\,\beta\,x^{\alpha-1}\,(1 - x^\alpha)^{\beta-1} }.
#' Summation of log gives the log-likelihood; we return the negative of that sum.
#'
#' @examples
#' \dontrun{
#' # Generate sample data from a Kw distribution
#' set.seed(123)
#' x <- rkw(100, 2, 3)
#' hist(x, breaks = 20, main = "Kw(2, 3) Sample")
#'
#' # Use in optimization with Hessian-based methods
#' result <- optim(c(0.5, 0.5), llkw, method = "BFGS",
#'                 hessian = TRUE, data = x)
#'
#' # Compare numerical and analytical derivatives
#' num_grad <- numDeriv::grad(llkw, x = result$par, data = x)
#' num_hess <- numDeriv::hessian(llkw, x = result$par, data = x)
#'
#' ana_grad <- grkw(result$par, data = x)
#' ana_hess <- hskw(result$par, data = x)
#'
#' # Check differences (should be very small)
#' round(num_grad - ana_grad, 4)
#' round(num_hess - ana_hess, 4)
#' }
#'
#' @export
llkw <- function(par, data) {
    .Call(`_gkwreg_llkw`, par, data)
}

#' @title Gradient Function for Kumaraswamy Log-Likelihood
#'
#' @description
#' Calculates the gradient vector (partial derivatives) of the negative log-likelihood
#' function for the Kumaraswamy (Kw) distribution. This function provides the exact
#' gradient needed for efficient optimization in maximum likelihood estimation.
#' The Kw is a submodel of GKw with γ = 1, δ = 0, and λ = 1 fixed.
#'
#' @param par NumericVector of length 2 containing parameters (α, β) in that order.
#'        All parameters must be positive.
#' @param data NumericVector of observations, where all values must be in the open interval (0,1).
#'
#' @return NumericVector of length 2 containing the gradient components (partial derivatives)
#'         of the negative log-likelihood with respect to each parameter (α, β).
#'         Returns a vector of NaN values if any parameters or data values are invalid.
#'
#' @details
#' The gradient vector contains the following partial derivatives of the negative log-likelihood:
#'
#' \deqn{
#' \frac{\partial \ell}{\partial \alpha} = \frac{n}{\alpha} + \sum_{i=1}^{n}\log(x_i) -
#' \sum_{i=1}^{n}\left[\frac{(\beta-1)x_i^{\alpha}\log(x_i)}{1-x_i^{\alpha}}\right]
#' }
#'
#' \deqn{
#' \frac{\partial \ell}{\partial \beta} = \frac{n}{\beta} + \sum_{i=1}^{n}\log(1-x_i^{\alpha})
#' }
#'
#' The implementation includes several numerical safeguards:
#' \itemize{
#'   \item Parameter and data validation with appropriate error handling
#'   \item Clamping of intermediate values to avoid numerical underflow/overflow
#'   \item Efficient vector operations using Armadillo C++ library
#' }
#'
#' The returned gradient is negated to align with minimization of negative log-likelihood
#' in optimization routines.
#'
#' @examples
#' \dontrun{
#' # Generate sample data from a Kw distribution
#' set.seed(123)
#' x <- rkw(100, 2, 3)
#' hist(x, breaks = 20, main = "Kw(2, 3) Sample")
#'
#' # Use in optimization with Hessian-based methods
#' result <- optim(c(0.5, 0.5), llkw, method = "BFGS",
#'                 hessian = TRUE, data = x)
#'
#' # Compare numerical and analytical derivatives
#' num_grad <- numDeriv::grad(llkw, x = result$par, data = x)
#' num_hess <- numDeriv::hessian(llkw, x = result$par, data = x)
#'
#' ana_grad <- grkw(result$par, data = x)
#' ana_hess <- hskw(result$par, data = x)
#'
#' # Check differences (should be very small)
#' round(num_grad - ana_grad, 4)
#' round(num_hess - ana_hess, 4)
#' }
#'
#' @seealso
#' \code{\link[gkwreg]{llkw}} for the negative log-likelihood function,
#' \code{\link[gkwreg]{hskw}} for the Hessian matrix of the Kw log-likelihood,
#' \code{\link[gkwreg]{dkw}} for the Kw density function,
#'
#' @references
#' Kumaraswamy, P. (1980). A generalized probability density function for double-bounded random processes.
#' Journal of Hydrology, 46(1-2), 79-88.
#'
#' Jones, M. C. (2009). Kumaraswamy's distribution: A beta-type distribution with some tractability advantages.
#' Statistical Methodology, 6(1), 70-81.
#'
#' @export
grkw <- function(par, data) {
    .Call(`_gkwreg_grkw`, par, data)
}

#' @title Hessian Matrix Function for Kumaraswamy Log-Likelihood
#'
#' @description
#' Calculates the Hessian matrix (second-order partial derivatives) of the negative log-likelihood
#' function for the Kumaraswamy (Kw) distribution. This function provides the exact Hessian needed
#' for efficient optimization in maximum likelihood estimation and for asymptotic inference.
#' The Kw is a submodel of GKw with γ = 1, δ = 0, and λ = 1 fixed.
#'
#' @param par NumericVector of length 2 containing parameters (α, β) in that order.
#'        All parameters must be positive.
#' @param data NumericVector of observations, where all values must be in the open interval (0,1).
#'
#' @return NumericMatrix of dimensions 2x2 containing the Hessian components (second derivatives)
#'         of the negative log-likelihood with respect to each parameter pair (α, β).
#'         Returns a matrix of NaN values if any parameters or data values are invalid.
#'
#' @details
#' The Hessian matrix contains the following second derivatives of the negative log-likelihood:
#'
#' \deqn{
#' \frac{\partial^2 \ell}{\partial \alpha^2} = -\frac{n}{\alpha^2} -
#' \sum_{i=1}^{n}\left[\frac{(\beta-1)x_i^{\alpha}(\log(x_i))^2}{1-x_i^{\alpha}}\left(1 + \frac{x_i^{\alpha}}{1-x_i^{\alpha}}\right)\right]
#' }
#'
#' \deqn{
#' \frac{\partial^2 \ell}{\partial \alpha \partial \beta} = -
#' \sum_{i=1}^{n}\left[\frac{x_i^{\alpha}\log(x_i)}{1-x_i^{\alpha}}\right]
#' }
#'
#' \deqn{
#' \frac{\partial^2 \ell}{\partial \beta^2} = -\frac{n}{\beta^2}
#' }
#'
#' The implementation includes several numerical safeguards:
#' \itemize{
#'   \item Parameter and data validation with appropriate error handling
#'   \item Clamping of intermediate values to avoid numerical underflow/overflow
#'   \item Symmetry of the Hessian matrix is guaranteed by construction
#'   \item Efficient vector operations using Armadillo C++ library
#' }
#'
#' The returned Hessian is negated to align with minimization of negative log-likelihood
#' in optimization routines.
#'
#' @examples
#' \dontrun{
#' # Generate sample data from a Kw distribution
#' set.seed(123)
#' x <- rkw(100, 2, 3)
#' hist(x, breaks = 20, main = "Kw(2, 3) Sample")
#'
#' # Use in optimization with Hessian-based methods
#' result <- optim(c(0.5, 0.5), llkw, method = "BFGS",
#'                 hessian = TRUE, data = x)
#'
#' # Compare numerical and analytical derivatives
#' num_grad <- numDeriv::grad(llkw, x = result$par, data = x)
#' num_hess <- numDeriv::hessian(llkw, x = result$par, data = x)
#'
#' ana_grad <- grkw(result$par, data = x)
#' ana_hess <- hskw(result$par, data = x)
#'
#' # Check differences (should be very small)
#' round(num_grad - ana_grad, 4)
#' round(num_hess - ana_hess, 4)
#' }
#'
#' @seealso
#' \code{\link[gkwreg]{llkw}} for the negative log-likelihood function,
#' \code{\link[gkwreg]{grkw}} for the gradient of the Kw log-likelihood,
#' \code{\link[gkwreg]{dkw}} for the Kw density function,
#'
#' @references
#' Kumaraswamy, P. (1980). A generalized probability density function for double-bounded random processes.
#' Journal of Hydrology, 46(1-2), 79-88.
#'
#' Jones, M. C. (2009). Kumaraswamy's distribution: A beta-type distribution with some tractability advantages.
#' Statistical Methodology, 6(1), 70-81.
#'
#' @export
hskw <- function(par, data) {
    .Call(`_gkwreg_hskw`, par, data)
}

#' @title Density of the Beta Distribution
#'
#' @description
#' Computes the PDF of Beta(\code{gamma, delta}) for x in (0,1).
#'
#' @param x Vector of quantiles in (0,1).
#' @param gamma First shape parameter > 0.
#' @param delta Second shape parameter > 0.
#' @param log_prob If TRUE, returns log-density.
#'
#' @details
#' The PDF is
#' \deqn{
#'   f(x) = \frac{x^{\gamma-1}\,(1-x)^{\delta}}
#'              {B(\gamma, \delta+1)}, \quad 0<x<1.
#' }
#'
#' @return A vector of densities (or log-densities).
#'
#' @export
dbeta_ <- function(x, gamma, delta, log_prob = FALSE) {
    .Call(`_gkwreg_dbeta_`, x, gamma, delta, log_prob)
}

#' @title CDF of the Beta Distribution
#'
#' @description
#' Computes F(q) = pbeta(q, gamma, delta+1) in (0,1).
#'
#' @param q Vector of quantiles in [0,1].
#' @param gamma First shape parameter > 0.
#' @param delta Second shape parameter > 0.
#' @param lower_tail If TRUE, returns F(q)=P(X≤q). If FALSE, 1-F(q).
#' @param log_p If TRUE, returns log of the probability.
#'
#' @return A vector of probabilities or log-probabilities, matching broadcast.
#'
#' @details
#' This is a wrapper calling R's \code{pbeta} internally with appropriate parameter
#' adjustment for the GKw family's Beta parameterization. We replicate the vectorized
#' approach for consistency with the GKw family style.
#'
#' @export
pbeta_ <- function(q, gamma, delta, lower_tail = TRUE, log_p = FALSE) {
    .Call(`_gkwreg_pbeta_`, q, gamma, delta, lower_tail, log_p)
}

#' @title Quantile Function of the Beta Distribution
#'
#' @description
#' For p in [0,1], returns x = Q(p) = qbeta(p, gamma, delta+1).
#'
#' @param p Vector of probabilities in [0,1] or log scale if log_p=TRUE.
#' @param gamma First shape parameter > 0.
#' @param delta Second shape parameter > 0.
#' @param lower_tail If TRUE, p=F(x). If FALSE, p=1-F(x).
#' @param log_p If TRUE, p is log(p).
#'
#' @return A vector of quantiles, same length as broadcast.
#'
#' @details
#' Wrapper around R's \code{qbeta} with parameter adjustment for GKw-style Beta.
#' Uses vectorized approach for consistency with GKw family style.
#' We handle boundaries (p=0 => Q=0, p=1 => Q=1) manually.
#'
#' @export
qbeta_ <- function(p, gamma, delta, lower_tail = TRUE, log_p = FALSE) {
    .Call(`_gkwreg_qbeta_`, p, gamma, delta, lower_tail, log_p)
}

#' @title Random Generation for the Beta Distribution
#'
#' @description
#' Generates n samples from Beta(\code{gamma, delta}), wrapping R's \code{rbeta} with
#' vectorized style to match GKw family approach.
#'
#' @param n Number of samples.
#' @param gamma First shape parameter > 0.
#' @param delta Second shape parameter > 0.
#'
#' @return A numeric vector of length n, each in (0,1).
#'
#' @details
#' This function generates samples from the GKw family parameterization of the Beta
#' distribution. The parameters are adjusted to call R's rbeta function correctly.
#'
#' @export
rbeta_ <- function(n, gamma, delta) {
    .Call(`_gkwreg_rbeta_`, n, gamma, delta)
}

#' @title Negative Log-Likelihood for the Beta Distribution
#'
#' @description
#' Computes \eqn{-\ell(\theta)} for Beta(\code{gamma, delta}), given data x in (0,1).
#'
#' @param par NumericVector of length 2: (gamma, delta).
#' @param data NumericVector of observations in (0,1).
#'
#' @return A single numeric value. +Inf if invalid parameters or data out of domain.
#'
#' @details
#' If \eqn{f(x)= x^{\gamma-1}(1-x)^{\delta}/B(\gamma,\delta+1)}, the log-likelihood is
#' \eqn{\sum_i [(\gamma-1)\ln x_i + \delta\ln(1-x_i)] - n \ln B(\gamma,\delta+1)}.
#' We return its negative for optimization usage.
#'
#' @examples
#' \dontrun{
#' # Generate sample data from a Beta distribution
#' set.seed(123)
#' x <- rbeta_(100, 2, 3)
#' hist(x, breaks = 20, main = "Beta(2, 3) Sample")
#'
#' # Use in optimization with Hessian-based methods
#' result <- optim(c(0.5, 0.5), llbeta, method = "BFGS",
#'                 hessian = TRUE, data = x)
#'
#' # Compare numerical and analytical derivatives
#' num_grad <- numDeriv::grad(llbeta, x = result$par, data = x)
#' num_hess <- numDeriv::hessian(llbeta, x = result$par, data = x)
#'
#' ana_grad <- grbeta(result$par, data = x)
#' ana_hess <- hsbeta(result$par, data = x)
#'
#' # Check differences (should be very small)
#' round(num_grad - ana_grad, 4)
#' round(num_hess - ana_hess, 4)
#' }
#'
#' @export
llbeta <- function(par, data) {
    .Call(`_gkwreg_llbeta`, par, data)
}

#' @title Gradient Function for Beta Log-Likelihood
#'
#' @description
#' Calculates the gradient vector (partial derivatives) of the negative log-likelihood
#' function for the Beta distribution. This function provides the exact gradient needed
#' for efficient optimization in maximum likelihood estimation.
#' The Beta is a submodel of GKw with α = 1, β = 1, and λ = 1 fixed.
#'
#' @param par NumericVector of length 2 containing parameters (γ, δ) in that order.
#'        All parameters must be positive.
#' @param data NumericVector of observations, where all values must be in the open interval (0,1).
#'
#' @return NumericVector of length 2 containing the gradient components (partial derivatives)
#'         of the negative log-likelihood with respect to each parameter (γ, δ).
#'         Returns a vector of NaN values if any parameters or data values are invalid.
#'
#' @details
#' The gradient vector contains the following partial derivatives of the negative log-likelihood:
#'
#' \deqn{
#' \frac{\partial \ell}{\partial \gamma} = n[\psi(\gamma+\delta+1) - \psi(\gamma)] -
#' \sum_{i=1}^{n}\log(x_i)
#' }
#'
#' \deqn{
#' \frac{\partial \ell}{\partial \delta} = n[\psi(\gamma+\delta+1) - \psi(\delta+1)] -
#' \sum_{i=1}^{n}\log(1-x_i)
#' }
#'
#' where:
#' \itemize{
#'   \item \deqn{\psi} is the digamma function (derivative of the log-gamma function)
#' }
#'
#' Note that this implementation works with the GKw family parameterization of the Beta
#' distribution where shape1=γ and shape2=δ+1 in standard statistical notation.
#'
#' The implementation includes several numerical safeguards:
#' \itemize{
#'   \item Parameter and data validation with appropriate error handling
#'   \item Efficient vector operations using Armadillo C++ library
#' }
#'
#' The returned gradient is for the negative log-likelihood to align with minimization
#' in optimization routines.
#'
#' @examples
#' \dontrun{
#' # Generate sample data from a Beta distribution
#' set.seed(123)
#' x <- rbeta_(100, 2, 3)
#' hist(x, breaks = 20, main = "Beta(2, 3) Sample")
#'
#' # Use in optimization with Hessian-based methods
#' result <- optim(c(0.5, 0.5), llbeta, method = "BFGS",
#'                 hessian = TRUE, data = x)
#'
#' # Compare numerical and analytical derivatives
#' num_grad <- numDeriv::grad(llbeta, x = result$par, data = x)
#' ana_grad <- grbeta(result$par, data = x)
#' round(num_grad - ana_grad, 4)
#' }
#'
#' @export
grbeta <- function(par, data) {
    .Call(`_gkwreg_grbeta`, par, data)
}

#' @title Hessian Matrix Function for Beta Log-Likelihood
#'
#' @description
#' Calculates the Hessian matrix (second-order partial derivatives) of the negative log-likelihood
#' function for the Beta distribution. This function provides the exact Hessian needed for
#' efficient optimization in maximum likelihood estimation and for asymptotic inference.
#' The Beta is a submodel of GKw with α = 1, β = 1, and λ = 1 fixed.
#'
#' @param par NumericVector of length 2 containing parameters (γ, δ) in that order.
#'        All parameters must be positive.
#' @param data NumericVector of observations, where all values must be in the open interval (0,1).
#'
#' @return NumericMatrix of dimensions 2x2 containing the Hessian components (second derivatives)
#'         of the negative log-likelihood with respect to each parameter pair (γ, δ).
#'         Returns a matrix of NaN values if any parameters or data values are invalid.
#'
#' @details
#' The Hessian matrix contains the following second derivatives of the negative log-likelihood:
#'
#' \deqn{
#' \frac{\partial^2 \ell}{\partial \gamma^2} = n[\psi'(\gamma) - \psi'(\gamma+\delta+1)]
#' }
#'
#' \deqn{
#' \frac{\partial^2 \ell}{\partial \gamma \partial \delta} = -n\psi'(\gamma+\delta+1)
#' }
#'
#' \deqn{
#' \frac{\partial^2 \ell}{\partial \delta^2} = n[\psi'(\delta+1) - \psi'(\gamma+\delta+1)]
#' }
#'
#' where:
#' \itemize{
#'   \item \deqn{\psi'} is the trigamma function (second derivative of the log-gamma function)
#' }
#'
#' Note that this implementation works with the GKw family parameterization of the Beta
#' distribution where shape1=γ and shape2=δ+1 in standard statistical notation.
#'
#' The implementation includes several numerical safeguards:
#' \itemize{
#'   \item Parameter and data validation with appropriate error handling
#'   \item Symmetry of the Hessian matrix is guaranteed by construction
#' }
#'
#' The returned Hessian is for the negative log-likelihood to align with minimization
#' in optimization routines.
#'
#' @examples
#' \dontrun{
#' # Generate sample data from a Beta distribution
#' set.seed(123)
#' x <- rbeta_(100, 2, 3)
#' hist(x, breaks = 20, main = "Beta(2, 3) Sample")
#'
#' # Use in optimization with Hessian-based methods
#' result <- optim(c(0.5, 0.5), llbeta, method = "BFGS",
#'                 hessian = TRUE, data = x)
#'
#' # Compare numerical and analytical derivatives
#' num_hess <- numDeriv::hessian(llbeta, x = result$par, data = x)
#' ana_hess <- hsbeta(result$par, data = x)
#' round(num_hess - ana_hess, 4)
#' }
#'
#' @export
hsbeta <- function(par, data) {
    .Call(`_gkwreg_hsbeta`, par, data)
}

#' @title Newton-Raphson Optimization for Kumaraswamy Family Distributions
#'
#' @description
#' Performs maximum likelihood estimation for the parameters of any distribution in the
#' Generalized Kumaraswamy (GKw) family using a robust implementation of the Newton-Raphson
#' algorithm. This function supports all 7 submodels: GKw, BKw, KKw, EKw, Mc (McDonald),
#' Kw, and Beta.
#'
#' @details
#' The Generalized Kumaraswamy family includes the following distributions, all defined on (0,1):
#' \itemize{
#'   \item \strong{GKw} (Generalized Kumaraswamy): 5 parameters (α, β, γ, δ, λ)
#'   \item \strong{BKw} (Beta-Kumaraswamy): 4 parameters (α, β, γ, δ), with λ = 1 fixed
#'   \item \strong{KKw} (Kumaraswamy-Kumaraswamy): 4 parameters (α, β, δ, λ), with γ = 1 fixed
#'   \item \strong{EKw} (Exponentiated Kumaraswamy): 3 parameters (α, β, λ), with γ = 1, δ = 0 fixed
#'   \item \strong{Mc} (McDonald/Beta Power): 3 parameters (γ, δ, λ), with α = 1, β = 1 fixed
#'   \item \strong{Kw} (Kumaraswamy): 2 parameters (α, β), with γ = 1, δ = 0, λ = 1 fixed
#'   \item \strong{Beta}: 2 parameters (γ, δ), with α = 1, β = 1, λ = 1 fixed
#' }
#'
#' This function implements a sophisticated optimization procedure to find the maximum likelihood
#' estimates with multiple fallback strategies to handle numerical challenges:
#' 1. Cholesky decomposition (fastest, requires positive-definite Hessian)
#' 2. Standard matrix solver
#' 3. Regularized Hessian with incremental adjustment
#' 4. Pseudo-inverse for highly ill-conditioned matrices
#' 5. Gradient descent as ultimate fallback
#'
#' The function also implements backtracking line search to ensure monotonic improvement in the
#' log-likelihood, with random parameter perturbation as a recovery strategy when backtracking fails.
#'
#' @param start A numeric vector containing initial values for parameters, with length
#'        corresponding to the selected family (see Details)
#' @param data A numeric vector containing observed data. All values must be in the interval (0,1)
#' @param family A character string specifying the distribution family. One of "gkw", "bkw", "kkw",
#'        "ekw", "mc", "kw", or "beta". Default: "gkw"
#' @param tol Convergence tolerance. The algorithm stops when the gradient norm or parameter/likelihood
#'        changes are below this value. Default: 1e-6
#' @param max_iter Maximum number of iterations. Default: 100
#' @param verbose Logical flag to print detailed progress information. Default: FALSE
#' @param use_hessian Logical flag to use Hessian information for parameter updates. If FALSE,
#'        the algorithm uses gradient descent instead. Default: TRUE
#' @param step_size Initial step size for parameter updates. Default: 1.0
#' @param enforce_bounds Logical flag to enforce parameter constraints. Default: TRUE
#' @param min_param_val Minimum allowed value for parameters (except delta). Default: 1e-5
#' @param max_param_val Maximum allowed value for parameters. Default: 1e5
#' @param get_num_hess Logical flag to calculate numerical Hessian in addition to analytical Hessian.
#'        Default: FALSE
#'
#' @return A list containing the following components:
#' \describe{
#'   \item{parameters}{A numeric vector with the estimated parameters}
#'   \item{loglik}{The maximized log-likelihood value}
#'   \item{iterations}{Number of iterations performed}
#'   \item{converged}{Logical flag indicating whether the algorithm converged}
#'   \item{param_history}{Matrix of parameter values at each iteration}
#'   \item{loglik_history}{Vector of log-likelihood values at each iteration}
#'   \item{gradient}{The gradient vector at the final parameter estimates}
#'   \item{hessian}{The Hessian matrix at the final parameter estimates}
#'   \item{std_errors}{Standard errors for the estimated parameters}
#'   \item{aic}{Akaike Information Criterion: AIC = 2k - 2ln(L)}
#'   \item{bic}{Bayesian Information Criterion: BIC = k ln(n) - 2ln(L)}
#'   \item{n}{Sample size}
#'   \item{status}{Character string indicating the termination status}
#'   \item{z_values}{Z-statistics for parameter significance tests}
#'   \item{p_values}{P-values for parameter significance tests}
#'   \item{param_names}{Character vector of parameter names}
#'   \item{family}{The distribution family used in the estimation}
#'   \item{numeric_hessian}{Numerical approximation of the Hessian (only if get_num_hess=TRUE)}
#' }
#'
#' @section Warning:
#' Convergence is not guaranteed for all datasets and initial values. It's recommended to:
#' \itemize{
#'   \item Try different initial values if convergence fails
#'   \item Check the gradient norm at the final solution to verify optimality
#'   \item Examine parameter history to identify potential issues
#'   \item Use the verbose option to get detailed progress information for troubleshooting
#' }
#'
#' @examples
#' \dontrun{
#' # Generate sample data from Beta(2,5) distribution for testing
#' set.seed(123)
#' sample_data <- rbeta(200, 2, 5)
#'
#' # Fit with full GKw model
#' gkw_result <- mle_fit(c(1.5, 4.5, 1.0, 0.0, 1.0), sample_data, family = "gkw")
#' gkw_result$parameters
#'
#' # Fit with simpler Kumaraswamy model
#' kw_result <- mle_fit(c(1.5, 4.5), sample_data, family = "kw")
#' kw_result$parameters
#'
#' # Fit with Beta model
#' beta_result <- mle_fit(c(2.0, 5.0), sample_data, family = "beta")
#' beta_result$parameters
#'
#' # Compare AIC/BIC values to select the best model
#' data.frame(
#'   family = c("gkw", "kw", "beta"),
#'   AIC = c(gkw_result$aic, kw_result$aic, beta_result$aic),
#'   BIC = c(gkw_result$bic, kw_result$bic, beta_result$bic)
#' )
#' }
#'
#' @references
#' Kumaraswamy, P. (1980). A generalized probability density function for double-bounded
#' random processes. Journal of Hydrology, 46(1-2), 79-88.
#'
#' Cordeiro, G. M., & de Castro, M. (2011). A new family of generalized distributions.
#' Journal of Statistical Computation and Simulation, 81(7), 883-898.
#'
#' Fletcher, R. (1987). Practical Methods of Optimization. John Wiley & Sons.
#'
#' @author Lopes, J. E.
#'
#' @export
nrgkw <- function(start, data, family = "gkw", tol = 1e-6, max_iter = 100L, verbose = FALSE, use_hessian = TRUE, step_size = 1.0, enforce_bounds = TRUE, min_param_val = 1e-5, max_param_val = 1e5, get_num_hess = FALSE) {
    .Call(`_gkwreg_nrgkw`, start, data, family, tol, max_iter, verbose, use_hessian, step_size, enforce_bounds, min_param_val, max_param_val, get_num_hess)
}

#' @title Calculate Parameters for the Generalized Kumaraswamy Distribution
#'
#' @description
#' Computes the parameters (alpha, beta, gamma, delta, lambda) for each observation based on design matrices and regression coefficients,
#' applying a positive link function as specified by link types and scale factors.
#'
#' @param X1 NumericMatrix design matrix for alpha.
#' @param X2 NumericMatrix design matrix for beta.
#' @param X3 NumericMatrix design matrix for gamma.
#' @param X4 NumericMatrix design matrix for delta.
#' @param X5 NumericMatrix design matrix for lambda.
#' @param beta1 NumericVector regression coefficients for X1.
#' @param beta2 NumericVector regression coefficients for X2.
#' @param beta3 NumericVector regression coefficients for X3.
#' @param beta4 NumericVector regression coefficients for X4.
#' @param beta5 NumericVector regression coefficients for X5.
#' @param link_types IntegerVector containing the link function type for each parameter.
#' @param scale_factors NumericVector with scale factors for each parameter.
#'
#' @return NumericMatrix with n rows and 5 columns corresponding to the calculated parameters.
#' @export
calculateParameters <- function(X1, X2, X3, X4, X5, beta1, beta2, beta3, beta4, beta5, link_types, scale_factors) {
    .Call(`_gkwreg_calculateParameters`, X1, X2, X3, X4, X5, beta1, beta2, beta3, beta4, beta5, link_types, scale_factors)
}

#' @title Calculate Means for the Generalized Kumaraswamy Distribution
#'
#' @description
#' Computes the mean of the distribution for each observation using numerical integration
#' (quadrature) with caching to avoid redundant calculations.
#'
#' @param params NumericMatrix with parameters (columns: alpha, beta, gamma, delta, lambda).
#'
#' @return NumericVector containing the calculated means for each observation.
#' @export
calculateMeans <- function(params) {
    .Call(`_gkwreg_calculateMeans`, params)
}

#' @title Calculate Densities for the Generalized Kumaraswamy Distribution
#'
#' @description
#' Evaluates the density (or its logarithm) for each observation given the parameters.
#'
#' @param y NumericVector of observations.
#' @param params NumericMatrix with parameters (columns: alpha, beta, gamma, delta, lambda).
#' @param log Logical indicating whether to return the log-density (default FALSE).
#'
#' @return NumericVector containing the evaluated densities.
#' @export
calculateDensities <- function(y, params, log = FALSE) {
    .Call(`_gkwreg_calculateDensities`, y, params, log)
}

#' @title Calculate Cumulative Probabilities for the Generalized Kumaraswamy Distribution
#'
#' @description
#' Computes the cumulative probabilities (CDF) for each observation given the parameters.
#'
#' @param y NumericVector of observations.
#' @param params NumericMatrix with parameters (columns: alpha, beta, gamma, delta, lambda).
#'
#' @return NumericVector containing the evaluated cumulative probabilities.
#' @export
calculateProbabilities <- function(y, params) {
    .Call(`_gkwreg_calculateProbabilities`, y, params)
}

#' @title Calculate Quantiles for the Generalized Kumaraswamy Distribution
#'
#' @description
#' Computes quantiles for the given probability levels using a bisection method for the first set
#' of parameters in the matrix.
#'
#' @param probs NumericVector of probabilities (values in (0,1)).
#' @param params NumericMatrix with parameters (columns: alpha, beta, gamma, delta, lambda).
#'
#' @return NumericVector containing the calculated quantiles.
#' @export
calculateQuantiles <- function(probs, params) {
    .Call(`_gkwreg_calculateQuantiles`, probs, params)
}

#' @title Calculate Response Residuals
#'
#' @description
#' Computes the raw response residuals as the difference between the observed and fitted values.
#'
#' @param y NumericVector of observations.
#' @param fitted NumericVector of fitted values.
#'
#' @return NumericVector of response residuals.
#' @export
calculateResponseResiduals <- function(y, fitted) {
    .Call(`_gkwreg_calculateResponseResiduals`, y, fitted)
}

#' @title Calculate Pearson Residuals
#'
#' @description
#' Computes the Pearson residuals based on the observed values, fitted means, and the approximate variance of the distribution.
#'
#' @param y NumericVector of observations.
#' @param fitted NumericVector of fitted values (means).
#' @param alpha NumericVector of alpha parameters.
#' @param beta NumericVector of beta parameters.
#' @param gamma NumericVector of gamma parameters.
#' @param delta NumericVector of delta parameters.
#' @param lambda NumericVector of lambda parameters.
#'
#' @return NumericVector of Pearson residuals.
#' @export
calculatePearsonResiduals <- function(y, fitted, alpha, beta, gamma, delta, lambda) {
    .Call(`_gkwreg_calculatePearsonResiduals`, y, fitted, alpha, beta, gamma, delta, lambda)
}

#' @title Calculate Deviance Residuals
#'
#' @description
#' Computes deviance residuals based on the log-likelihood of the observations.
#'
#' @param y NumericVector of observations.
#' @param fitted NumericVector of fitted values (means).
#' @param alpha NumericVector of alpha parameters.
#' @param beta NumericVector of beta parameters.
#' @param gamma NumericVector of gamma parameters.
#' @param delta NumericVector of delta parameters.
#' @param lambda NumericVector of lambda parameters.
#'
#' @return NumericVector of deviance residuals.
#' @export
calculateDevianceResiduals <- function(y, fitted, alpha, beta, gamma, delta, lambda) {
    .Call(`_gkwreg_calculateDevianceResiduals`, y, fitted, alpha, beta, gamma, delta, lambda)
}

#' @title Calculate Quantile Residuals
#'
#' @description
#' Computes quantile residuals by transforming the cumulative distribution function (CDF) values to the standard normal quantiles.
#'
#' @param y NumericVector of observations.
#' @param alpha NumericVector of alpha parameters.
#' @param beta NumericVector of beta parameters.
#' @param gamma NumericVector of gamma parameters.
#' @param delta NumericVector of delta parameters.
#' @param lambda NumericVector of lambda parameters.
#'
#' @return NumericVector of quantile residuals.
#' @export
calculateQuantileResiduals <- function(y, alpha, beta, gamma, delta, lambda) {
    .Call(`_gkwreg_calculateQuantileResiduals`, y, alpha, beta, gamma, delta, lambda)
}

#' @title Calculate Cox-Snell Residuals
#'
#' @description
#' Computes Cox-Snell residuals defined as -log(1 - F(y)), where F is the cumulative distribution function.
#'
#' @param y NumericVector of observations.
#' @param alpha NumericVector of alpha parameters.
#' @param beta NumericVector of beta parameters.
#' @param gamma NumericVector of gamma parameters.
#' @param delta NumericVector of delta parameters.
#' @param lambda NumericVector of lambda parameters.
#'
#' @return NumericVector of Cox-Snell residuals.
#' @export
calculateCoxSnellResiduals <- function(y, alpha, beta, gamma, delta, lambda) {
    .Call(`_gkwreg_calculateCoxSnellResiduals`, y, alpha, beta, gamma, delta, lambda)
}

#' @title Calculate Score Residuals
#'
#' @description
#' Computes score residuals based on the numerical derivative (score) of the log-likelihood with respect to the observation.
#'
#' @param y NumericVector of observations.
#' @param fitted NumericVector of fitted values (means).
#' @param alpha NumericVector of alpha parameters.
#' @param beta NumericVector of beta parameters.
#' @param gamma NumericVector of gamma parameters.
#' @param delta NumericVector of delta parameters.
#' @param lambda NumericVector of lambda parameters.
#'
#' @return NumericVector of score residuals.
#' @export
calculateScoreResiduals <- function(y, fitted, alpha, beta, gamma, delta, lambda) {
    .Call(`_gkwreg_calculateScoreResiduals`, y, fitted, alpha, beta, gamma, delta, lambda)
}

#' @title Calculate Modified Deviance Residuals
#'
#' @description
#' Adjusts deviance residuals to have a distribution closer to N(0,1) by standardizing them.
#'
#' @param y NumericVector of observations.
#' @param fitted NumericVector of fitted values (means).
#' @param alpha NumericVector of alpha parameters.
#' @param beta NumericVector of beta parameters.
#' @param gamma NumericVector of gamma parameters.
#' @param delta NumericVector of delta parameters.
#' @param lambda NumericVector of lambda parameters.
#'
#' @return NumericVector of modified deviance residuals.
#' @export
calculateModifiedDevianceResiduals <- function(y, fitted, alpha, beta, gamma, delta, lambda) {
    .Call(`_gkwreg_calculateModifiedDevianceResiduals`, y, fitted, alpha, beta, gamma, delta, lambda)
}

#' @title Calculate Partial Residuals
#'
#' @description
#' Computes partial residuals for a selected covariate by adding the product of the regression coefficient and
#' the corresponding design matrix value to the raw residual.
#'
#' @param y NumericVector of observations.
#' @param fitted NumericVector of fitted values.
#' @param X NumericMatrix of design matrix values.
#' @param beta NumericVector of regression coefficients.
#' @param covariate_idx Integer index for the selected covariate (0-indexed).
#'
#' @return NumericVector of partial residuals.
#' @export
calculatePartialResiduals <- function(y, fitted, X, beta, covariate_idx) {
    .Call(`_gkwreg_calculatePartialResiduals`, y, fitted, X, beta, covariate_idx)
}

