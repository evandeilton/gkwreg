<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Enhanced Newton-Raphson Optimization for GKw Family Distributions — nrgkw • gkwreg</title><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet"><link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet"><script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Enhanced Newton-Raphson Optimization for GKw Family Distributions — nrgkw"><meta name="description" content="An industrial-strength implementation of maximum likelihood estimation (MLE)
for the parameters of any distribution in the Generalized Kumaraswamy (GKw) family.
This function incorporates multiple advanced numerical techniques including trust region
methods, eigenvalue-based regularization, adaptive scaling, and sophisticated line
search to ensure robust convergence even for challenging datasets or extreme parameter values."><meta property="og:description" content="An industrial-strength implementation of maximum likelihood estimation (MLE)
for the parameters of any distribution in the Generalized Kumaraswamy (GKw) family.
This function incorporates multiple advanced numerical techniques including trust region
methods, eigenvalue-based regularization, adaptive scaling, and sophisticated line
search to ensure robust convergence even for challenging datasets or extreme parameter values."></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">gkwreg</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.0.6</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="active nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json"></form></li>
      </ul></div>


  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Enhanced Newton-Raphson Optimization for GKw Family Distributions</h1>

      <div class="d-none name"><code>nrgkw.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>An industrial-strength implementation of maximum likelihood estimation (MLE)
for the parameters of any distribution in the Generalized Kumaraswamy (GKw) family.
This function incorporates multiple advanced numerical techniques including trust region
methods, eigenvalue-based regularization, adaptive scaling, and sophisticated line
search to ensure robust convergence even for challenging datasets or extreme parameter values.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">nrgkw</span><span class="op">(</span></span>
<span>  start <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">as.numeric</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  family <span class="op">=</span> <span class="st">"gkw"</span>,</span>
<span>  tol <span class="op">=</span> <span class="fl">1e-06</span>,</span>
<span>  max_iter <span class="op">=</span> <span class="fl">100L</span>,</span>
<span>  verbose <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  optimization_method <span class="op">=</span> <span class="st">"trust-region"</span>,</span>
<span>  enforce_bounds <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  min_param_val <span class="op">=</span> <span class="fl">1e-05</span>,</span>
<span>  max_param_val <span class="op">=</span> <span class="fl">1e+05</span>,</span>
<span>  adaptive_scaling <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  use_stochastic_perturbation <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  get_num_hess <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  multi_start_attempts <span class="op">=</span> <span class="fl">3L</span>,</span>
<span>  eigenvalue_hessian_reg <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  max_backtrack <span class="op">=</span> <span class="fl">20L</span>,</span>
<span>  initial_trust_radius <span class="op">=</span> <span class="fl">1</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>


<dl><dt id="arg-start">start<a class="anchor" aria-label="anchor" href="#arg-start"></a></dt>
<dd><p>A numeric vector containing initial values for the parameters.
If NULL, automatic initialization is used based on the dataset characteristics.
The length and order must correspond to the selected <code>family</code>
(e.g., <code>c(alpha, beta, gamma, delta, lambda)</code> for "gkw"; <code>c(alpha, beta)</code> for "kw";
<code>c(gamma, delta)</code> for "beta").</p></dd>


<dt id="arg-data">data<a class="anchor" aria-label="anchor" href="#arg-data"></a></dt>
<dd><p>A numeric vector containing the observed data. All values must
be strictly between 0 and 1.</p></dd>


<dt id="arg-family">family<a class="anchor" aria-label="anchor" href="#arg-family"></a></dt>
<dd><p>A character string specifying the distribution family. One of
<code>"gkw"</code>, <code>"bkw"</code>, <code>"kkw"</code>, <code>"ekw"</code>, <code>"mc"</code>,
<code>"kw"</code>, or <code>"beta"</code>. Default: <code>"gkw"</code>.</p></dd>


<dt id="arg-tol">tol<a class="anchor" aria-label="anchor" href="#arg-tol"></a></dt>
<dd><p>Convergence tolerance. The algorithm stops when the Euclidean norm
of the gradient is below this value, or if relative changes in parameters
or the negative log-likelihood are below this threshold across consecutive
iterations. Default: <code>1e-6</code>.</p></dd>


<dt id="arg-max-iter">max_iter<a class="anchor" aria-label="anchor" href="#arg-max-iter"></a></dt>
<dd><p>Maximum number of iterations allowed. Default: <code>100</code>.</p></dd>


<dt id="arg-verbose">verbose<a class="anchor" aria-label="anchor" href="#arg-verbose"></a></dt>
<dd><p>Logical; if <code>TRUE</code>, prints detailed progress information
during optimization, including iteration number, negative log-likelihood,
gradient norm, and step adjustment details. Default: <code>FALSE</code>.</p></dd>


<dt id="arg-optimization-method">optimization_method<a class="anchor" aria-label="anchor" href="#arg-optimization-method"></a></dt>
<dd><p>Character string specifying the optimization method:
"trust-region" (default), "newton-raphson", or "hybrid" (starts with trust-region,
switches to newton-raphson near convergence).</p></dd>


<dt id="arg-enforce-bounds">enforce_bounds<a class="anchor" aria-label="anchor" href="#arg-enforce-bounds"></a></dt>
<dd><p>Logical; if <code>TRUE</code>, parameter values are constrained
to stay within <code>min_param_val</code>, <code>max_param_val</code> (and \(\delta \ge 0\))
during optimization. Default: <code>TRUE</code>.</p></dd>


<dt id="arg-min-param-val">min_param_val<a class="anchor" aria-label="anchor" href="#arg-min-param-val"></a></dt>
<dd><p>Minimum allowed value for parameters constrained to be
strictly positive (\(\alpha, \beta, \gamma, \lambda\)). Default: <code>1e-5</code>.</p></dd>


<dt id="arg-max-param-val">max_param_val<a class="anchor" aria-label="anchor" href="#arg-max-param-val"></a></dt>
<dd><p>Maximum allowed value for all parameters. Default: <code>1e5</code>.</p></dd>


<dt id="arg-adaptive-scaling">adaptive_scaling<a class="anchor" aria-label="anchor" href="#arg-adaptive-scaling"></a></dt>
<dd><p>Logical; if <code>TRUE</code>, parameters are automatically scaled
to improve numerical stability. Default: <code>TRUE</code>.</p></dd>


<dt id="arg-use-stochastic-perturbation">use_stochastic_perturbation<a class="anchor" aria-label="anchor" href="#arg-use-stochastic-perturbation"></a></dt>
<dd><p>Logical; if <code>TRUE</code>, applies random perturbations
when optimization stalls. Default: <code>TRUE</code>.</p></dd>


<dt id="arg-get-num-hess">get_num_hess<a class="anchor" aria-label="anchor" href="#arg-get-num-hess"></a></dt>
<dd><p>Logical; if <code>TRUE</code>, computes and returns a numerical
approximation of the Hessian at the solution. Default: <code>FALSE</code>.</p></dd>


<dt id="arg-multi-start-attempts">multi_start_attempts<a class="anchor" aria-label="anchor" href="#arg-multi-start-attempts"></a></dt>
<dd><p>Integer specifying the number of different starting points
to try if initial optimization fails to converge. Default: <code>3</code>.</p></dd>


<dt id="arg-eigenvalue-hessian-reg">eigenvalue_hessian_reg<a class="anchor" aria-label="anchor" href="#arg-eigenvalue-hessian-reg"></a></dt>
<dd><p>Logical; if <code>TRUE</code>, uses eigenvalue-based
regularization for the Hessian matrix. Default: <code>TRUE</code>.</p></dd>


<dt id="arg-max-backtrack">max_backtrack<a class="anchor" aria-label="anchor" href="#arg-max-backtrack"></a></dt>
<dd><p>Integer specifying the maximum number of backtracking steps
in line search. Default: <code>20</code>.</p></dd>


<dt id="arg-initial-trust-radius">initial_trust_radius<a class="anchor" aria-label="anchor" href="#arg-initial-trust-radius"></a></dt>
<dd><p>Initial radius for trust region method. Default: <code>1.0</code>.</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    <p>A list object of class <code>gkw_fit</code> containing the following components:</p>
<dl><dt>parameters</dt>
<dd><p>A named numeric vector with the estimated parameters.</p></dd>

<dt>loglik</dt>
<dd><p>The maximized value of the log-likelihood function.</p></dd>

<dt>iterations</dt>
<dd><p>Number of iterations performed.</p></dd>

<dt>converged</dt>
<dd><p>Logical flag indicating whether the algorithm converged successfully.</p></dd>

<dt>param_history</dt>
<dd><p>A matrix where rows represent iterations and columns represent parameter values.</p></dd>

<dt>loglik_history</dt>
<dd><p>A vector of log-likelihood values at each iteration.</p></dd>

<dt>gradient</dt>
<dd><p>The gradient vector at the final parameter estimates.</p></dd>

<dt>hessian</dt>
<dd><p>The analytical Hessian matrix at the final parameter estimates.</p></dd>

<dt>std_errors</dt>
<dd><p>A named numeric vector of approximate standard errors for the parameters.</p></dd>

<dt>aic</dt>
<dd><p>Akaike Information Criterion.</p></dd>

<dt>bic</dt>
<dd><p>Bayesian Information Criterion.</p></dd>

<dt>aicc</dt>
<dd><p>AIC with small sample correction.</p></dd>

<dt>n</dt>
<dd><p>The sample size.</p></dd>

<dt>status</dt>
<dd><p>A character string indicating the termination status.</p></dd>

<dt>z_values</dt>
<dd><p>A named numeric vector of Z-statistics for parameter significance testing.</p></dd>

<dt>p_values</dt>
<dd><p>A named numeric vector of two-sided p-values corresponding to the Z-statistics.</p></dd>

<dt>param_names</dt>
<dd><p>A character vector of the parameter names.</p></dd>

<dt>family</dt>
<dd><p>The distribution family used.</p></dd>

<dt>optimization_method</dt>
<dd><p>The optimization method used.</p></dd>

<dt>numeric_hessian</dt>
<dd><p>The numerically approximated Hessian at the solution (if requested).</p></dd>

<dt>condition_number</dt>
<dd><p>The condition number of the final Hessian, a measure of parameter identifiability.</p></dd>

<dt>scaling_factors</dt>
<dd><p>The scaling factors used for parameters (if adaptive scaling was enabled).</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="details">Details<a class="anchor" aria-label="anchor" href="#details"></a></h2>
    <p>This enhanced algorithm provides robust parameter estimation for the Generalized
Kumaraswamy distribution and its subfamilies. The function implements several
advanced numerical optimization techniques to maximize the likelihood function
reliably even in difficult cases.</p>
<div class="section">
<h3 id="the-gkw-family-of-distributions">The GKw Family of Distributions<a class="anchor" aria-label="anchor" href="#the-gkw-family-of-distributions"></a></h3>
<p>The Generalized Kumaraswamy (GKw) distribution, introduced by Carrasco, Ferrari,
and Cordeiro (2010), is a flexible five-parameter continuous distribution defined
on the standard unit interval (0,1). Its probability density function is given by:</p>
<p>$$f(x; \alpha, \beta, \gamma, \delta, \lambda) = \frac{\lambda\alpha\beta x^{\alpha-1}}{B(\gamma, \delta+1)}(1-x^{\alpha})^{\beta-1}[1-(1-x^{\alpha})^{\beta}]^{\gamma\lambda-1}\{1-[1-(1-x^{\alpha})^{\beta}]^{\lambda}\}^{\delta}$$</p>
<p>where \(\alpha, \beta, \gamma, \lambda &gt; 0\) and \(\delta \geq 0\) are the model
parameters, and \(B(\gamma, \delta+1)\) is the beta function.</p>
<p>The GKw distribution encompasses several important special cases:</p><ul><li><p><b>GKw</b> (5 parameters): \(\alpha, \beta, \gamma, \delta, \lambda\)</p></li>
<li><p><b>BKw</b> (4 parameters): \(\alpha, \beta, \gamma, \delta\) (with \(\lambda = 1\))</p></li>
<li><p><b>KKw</b> (4 parameters): \(\alpha, \beta, \delta, \lambda\) (with \(\gamma = 1\))</p></li>
<li><p><b>EKw</b> (3 parameters): \(\alpha, \beta, \lambda\) (with \(\gamma = 1, \delta = 0\))</p></li>
<li><p><b>Mc</b>  (3 parameters): \(\gamma, \delta, \lambda\) (with \(\alpha = 1, \beta = 1\))</p></li>
<li><p><b>Kw</b>  (2 parameters): \(\alpha, \beta\) (with \(\gamma = 1, \delta = 0, \lambda = 1\))</p></li>
<li><p><b>Beta</b>(2 parameters): \(\gamma, \delta\) (with \(\alpha = 1, \beta = 1, \lambda = 1\))</p></li>
</ul></div>

<div class="section">
<h3 id="trust-region-method-with-levenberg-marquardt-algorithm">Trust Region Method with Levenberg-Marquardt Algorithm<a class="anchor" aria-label="anchor" href="#trust-region-method-with-levenberg-marquardt-algorithm"></a></h3>
<p>The trust region approach restricts parameter updates to a region where the quadratic
approximation of the objective function is trusted to be accurate. This algorithm
implements the Levenberg-Marquardt variant, which solves the subproblem:</p>
<p>$$\min_p m_k(p) = -\nabla \ell(\theta_k)^T p + \frac{1}{2}p^T H_k p$$
$$\text{subject to } \|p\| \leq \Delta_k$$</p>
<p>where \(\nabla \ell(\theta_k)\) is the gradient, \(H_k\) is the Hessian, and \(\Delta_k\)
is the trust region radius at iteration \(k\).</p>
<p>The Levenberg-Marquardt approach adds a regularization parameter \(\lambda\) to the
Hessian, solving:</p>
<p>$$(H_k + \lambda I)p = -\nabla \ell(\theta_k)$$</p>
<p>The parameter \(\lambda\) controls the step size and direction:</p><ul><li><p>When \(\lambda\) is large, the step approaches a scaled steepest descent direction.</p></li>
<li><p>When \(\lambda\) is small, the step approaches the Newton direction.</p></li>
</ul><p>The algorithm dynamically adjusts \(\lambda\) based on the agreement between the quadratic model and the actual function:</p>
<p>$$\rho_k = \frac{f(\theta_k) - f(\theta_k + p_k)}{m_k(0) - m_k(p_k)}$$</p>
<p>The trust region radius is updated according to:</p><ul><li><p>If \(\rho_k &lt; 0.25\), reduce the radius: \(\Delta_{k+1} = 0.5\Delta_k\)</p></li>
<li><p>If \(\rho_k &gt; 0.75\) and \(\|p_k\| \approx \Delta_k\), increase the radius: \(\Delta_{k+1} = 2\Delta_k\)</p></li>
<li><p>Otherwise, leave the radius unchanged: \(\Delta_{k+1} = \Delta_k\)</p></li>
</ul><p>The step is accepted if \(\rho_k &gt; \eta\) (typically \(\eta = 0.1\)).</p>
</div>

<div class="section">
<h3 id="eigenvalue-based-hessian-regularization">Eigenvalue-Based Hessian Regularization<a class="anchor" aria-label="anchor" href="#eigenvalue-based-hessian-regularization"></a></h3>
<p>For the Newton-Raphson method to converge, the Hessian matrix must be positive definite.
This algorithm uses eigendecomposition to create a positive definite approximation that
preserves the Hessian's structure:</p>
<p>$$H = Q\Lambda Q^T$$</p>
<p>where \(Q\) contains the eigenvectors and \(\Lambda\) is a diagonal matrix of eigenvalues.</p>
<p>The regularized Hessian is constructed by:</p>
<p>$$\tilde{H} = Q\tilde{\Lambda}Q^T$$</p>
<p>where \(\tilde{\Lambda}\) contains modified eigenvalues:</p>
<p>$$\tilde{\lambda}_i = \max(\lambda_i, \epsilon)$$</p>
<p>with \(\epsilon\) being a small positive threshold (typically \(10^{-6}\)).</p>
<p>This approach is superior to diagonal loading (\(H + \lambda I\)) as it:</p><ul><li><p>Preserves the eigenvector structure of the original Hessian</p></li>
<li><p>Minimally modifies the eigenvalues needed to ensure positive definiteness</p></li>
<li><p>Better maintains the directional information in the Hessian</p></li>
</ul></div>

<div class="section">
<h3 id="parameter-scaling-for-numerical-stability">Parameter Scaling for Numerical Stability<a class="anchor" aria-label="anchor" href="#parameter-scaling-for-numerical-stability"></a></h3>
<p>When parameters have widely different magnitudes, optimization can become numerically
unstable. The adaptive scaling system transforms the parameter space to improve conditioning:</p>
<p>$$\theta_i^{scaled} = s_i \theta_i$$</p>
<p>where scaling factors \(s_i\) are determined by:</p><ul><li><p>For large parameters (\(|\theta_i| &gt; 100\)): \(s_i = 100/|\theta_i|\)</p></li>
<li><p>For small parameters (\(0 &lt; |\theta_i| &lt; 0.01\)): \(s_i = 0.01/|\theta_i|\)</p></li>
<li><p>Otherwise: \(s_i = 1\)</p></li>
</ul><p>The optimization is performed in the scaled space, with appropriate transformations
for the gradient and Hessian:</p>
<p>$$\nabla \ell(\theta^{scaled})_i = \frac{1}{s_i}\nabla \ell(\theta)_i$$
$$H(\theta^{scaled})_{ij} = \frac{1}{s_i s_j}H(\theta)_{ij}$$</p>
<p>The final results are back-transformed to the original parameter space before being returned.</p>
</div>

<div class="section">
<h3 id="line-search-with-wolfe-conditions">Line Search with Wolfe Conditions<a class="anchor" aria-label="anchor" href="#line-search-with-wolfe-conditions"></a></h3>
<p>The line search procedure ensures sufficient decrease in the objective function when
taking a step in the search direction. The implementation uses Wolfe conditions which
include both:</p><ol><li><p>Sufficient decrease (Armijo) condition:
$$f(\theta_k + \alpha p_k) \leq f(\theta_k) + c_1 \alpha \nabla f(\theta_k)^T p_k$$</p></li>
<li><p>Curvature condition:
$$|\nabla f(\theta_k + \alpha p_k)^T p_k| \leq c_2 |\nabla f(\theta_k)^T p_k|$$</p></li>
</ol><p>where \(0 &lt; c_1 &lt; c_2 &lt; 1\), typically \(c_1 = 10^{-4}\) and \(c_2 = 0.9\).</p>
<p>The step length \(\alpha\) is determined using polynomial interpolation:</p><ul><li><p>First iteration: quadratic interpolation</p></li>
<li><p>Subsequent iterations: cubic interpolation using function and derivative values</p></li>
</ul><p>The cubic polynomial model has the form:
$$a\alpha^3 + b\alpha^2 + c\alpha + d$$</p>
<p>The algorithm computes coefficients from values at two points, then finds the minimizer
of this polynomial subject to bounds to ensure convergence.</p>
</div>

<div class="section">
<h3 id="adaptive-numerical-differentiation">Adaptive Numerical Differentiation<a class="anchor" aria-label="anchor" href="#adaptive-numerical-differentiation"></a></h3>
<p>When analytical derivatives are unreliable, the algorithm uses numerical differentiation
with adaptive step sizes based on parameter magnitudes:</p>
<p>$$h_i = \max(h_{min}, \min(h_{base}, h_{base} \cdot |\theta_i|))$$</p>
<p>where \(h_{min}\) is a minimum step size (typically \(10^{-8}\)), \(h_{base}\)
is a base step size (typically \(10^{-5}\)), and \(\theta_i\) is the parameter value.</p>
<p>For computing diagonal Hessian elements, the central difference formula is used:</p>
<p>$$\frac{\partial^2 f}{\partial \theta_i^2} \approx \frac{f(\theta + h_i e_i) - 2f(\theta) + f(\theta - h_i e_i)}{h_i^2}$$</p>
<p>For mixed partial derivatives:</p>
<p>$$\frac{\partial^2 f}{\partial \theta_i \partial \theta_j} \approx \frac{f(\theta + h_i e_i + h_j e_j) - f(\theta + h_i e_i - h_j e_j) - f(\theta - h_i e_i + h_j e_j) + f(\theta - h_i e_i - h_j e_j)}{4h_i h_j}$$</p>
<p>The algorithm validates numerical differentiation by comparing with existing gradients
and adaptively adjusts step sizes when discrepancies are detected.</p>
</div>

<div class="section">
<h3 id="stochastic-perturbation">Stochastic Perturbation<a class="anchor" aria-label="anchor" href="#stochastic-perturbation"></a></h3>
<p>To escape flat regions or local minima, the algorithm implements controlled stochastic
perturbation when progress stalls (detected by monitoring gradient norm changes):</p>
<p>$$\theta_i^{new} = \theta_i + \Delta\theta_i$$</p>
<p>where the perturbation \(\Delta\theta_i\) combines:</p><ul><li><p>A directed component opposite to the gradient: \(-\text{sign}(\nabla \ell_i) \cdot 0.05 \cdot |\theta_i|\)</p></li>
<li><p>A random noise component: \(U(-0.05|\theta_i|, 0.05|\theta_i|)\)</p></li>
</ul><p>The perturbation is applied when:</p><ul><li><p>The relative change in gradient norm is below a threshold for several consecutive iterations</p></li>
<li><p>The algorithm appears to be stuck in a non-optimal region</p></li>
</ul><p>The perturbation is accepted only if it improves the objective function value.</p>
</div>

<div class="section">
<h3 id="multi-start-strategy">Multi-Start Strategy<a class="anchor" aria-label="anchor" href="#multi-start-strategy"></a></h3>
<p>For particularly challenging optimization landscapes, the algorithm can employ multiple
starting points:</p>
<ul><li><p>Initial values are generated using moment-based estimation and domain knowledge about each distribution family</p></li>
<li><p>Each initial point is randomly perturbed to explore different regions of the parameter space</p></li>
<li><p>Independent optimization runs are performed from each starting point</p></li>
<li><p>The best result (based on likelihood value and convergence status) is returned</p></li>
</ul><p>This approach increases the probability of finding the global optimum or a high-quality
local optimum, particularly for complex models with many parameters.</p>
</div>

<div class="section">
<h3 id="advanced-parameter-initialization">Advanced Parameter Initialization<a class="anchor" aria-label="anchor" href="#advanced-parameter-initialization"></a></h3>
<p>Intelligent starting values are critical for convergence in complex models. The algorithm
uses data-driven initialization based on:</p>
<ul><li><p>Method of moments estimators for beta parameters:
$$\alpha + \beta = \frac{\bar{x}(1-\bar{x})}{s^2} - 1$$
$$\alpha = (\alpha + \beta)\bar{x}$$</p></li>
<li><p>Transformations to Kumaraswamy parameters:
$$a_{Kw} = \sqrt{\alpha_{Beta}}$$
$$b_{Kw} = \sqrt{\beta_{Beta}}$$</p></li>
<li><p>Adjustments based on data skewness (detected via mean relative to 0.5)</p></li>
<li><p>Corrections based on data dispersion (range relative to (0,1) interval)</p></li>
</ul><p>The transformations between beta and Kumaraswamy parameters leverage the similarities
between these distributions while accounting for their parametric differences.</p>
</div>

<div class="section">
<h3 id="hybrid-optimization-strategy">Hybrid Optimization Strategy<a class="anchor" aria-label="anchor" href="#hybrid-optimization-strategy"></a></h3>
<p>The algorithm can dynamically switch between trust region and Newton-Raphson methods
based on optimization progress:</p>
<ul><li><p>Early iterations: trust region method for stability and global convergence properties</p></li>
<li><p>Later iterations (when close to optimum): Newton-Raphson with line search for quadratic convergence rate</p></li>
</ul><p>The switching criteria are based on iteration count and gradient norm, with additional
logic to handle cases where one method consistently fails.</p>
</div>

    </div>
    <div class="section level2">
    <h2 id="warning">Warning<a class="anchor" aria-label="anchor" href="#warning"></a></h2>


<p>Although this implementation is highly robust, fitting complex distributions can still be challenging.
For best results:</p><ul><li><p>Try multiple starting values if results seem suboptimal</p></li>
<li><p>Examine diagnostic information carefully, especially condition numbers and standard errors</p></li>
<li><p>Be cautious of parameter estimates at or very near boundaries</p></li>
<li><p>Consider model simplification if convergence is consistently problematic</p></li>
<li><p>For the full GKw model with 5 parameters, convergence may be sensitive to starting values</p></li>
<li><p>High condition numbers (&gt;1e6) may indicate parameter redundancy or weak identifiability</p></li>
</ul></div>
    <div class="section level2">
    <h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a></h2>
    <p>Carrasco, J. M. F., Ferrari, S. L. P., &amp; Cordeiro, G. M. (2010). A new generalized Kumaraswamy
distribution. arXiv preprint arXiv:1004.0911.</p>
<p>Nocedal, J., &amp; Wright, S. J. (2006). Numerical Optimization (2nd ed.). Springer.</p>
<p>Conn, A. R., Gould, N. I. M., &amp; Toint, P. L. (2000). Trust Region Methods. MPS-SIAM Series on Optimization.</p>
<p>Kumaraswamy, P. (1980). A generalized probability density function for double-bounded
random processes. Journal of Hydrology, 46(1-2), 79-88.</p>
    </div>
    <div class="section level2">
    <h2 id="author">Author<a class="anchor" aria-label="anchor" href="#author"></a></h2>
    <p>Enhanced by Lopes, J. E.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-examples">Examples<a class="anchor" aria-label="anchor" href="#ref-examples"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="co"># \donttest{</span></span></span>
<span class="r-in"><span><span class="co"># Generate sample data from a Beta(2,5) distribution for testing</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">sample_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="rbeta_.html">rbeta_</a></span><span class="op">(</span><span class="fl">200</span>, <span class="fl">2</span>, <span class="fl">5</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Automatic initialization (recommended for beginners)</span></span></span>
<span class="r-in"><span><span class="va">result_auto</span> <span class="op">&lt;-</span> <span class="fu">nrgkw</span><span class="op">(</span><span class="cn">NULL</span>, <span class="va">sample_data</span>, family <span class="op">=</span> <span class="st">"beta"</span>, verbose <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">result_auto</span><span class="op">$</span><span class="va">parameters</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] 2.464823 6.815824</span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">result_auto</span><span class="op">$</span><span class="va">loglik</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] 141.4309</span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Compare different optimization methods</span></span></span>
<span class="r-in"><span><span class="va">methods</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"trust-region"</span>, <span class="st">"newton-raphson"</span>, <span class="st">"hybrid"</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">results</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="kw">for</span> <span class="op">(</span><span class="va">method</span> <span class="kw">in</span> <span class="va">methods</span><span class="op">)</span> <span class="op">{</span></span></span>
<span class="r-in"><span>  <span class="va">results</span><span class="op">[[</span><span class="va">method</span><span class="op">]</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu">nrgkw</span><span class="op">(</span><span class="cn">NULL</span>, <span class="va">sample_data</span>, family <span class="op">=</span> <span class="st">"beta"</span>,</span></span>
<span class="r-in"><span>                               optimization_method <span class="op">=</span> <span class="va">method</span><span class="op">)</span></span></span>
<span class="r-in"><span>  <span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sprintf.html" class="external-link">sprintf</a></span><span class="op">(</span><span class="st">"Method: %s, AIC: %.4f\n"</span>, <span class="va">method</span>, <span class="va">results</span><span class="op">[[</span><span class="va">method</span><span class="op">]</span><span class="op">]</span><span class="op">$</span><span class="va">aic</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="op">}</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Method: trust-region, AIC: -278.8618</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Method: newton-raphson, AIC: -278.8625</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Method: hybrid, AIC: -278.8624</span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Fit the full GKw model with diagnostic information</span></span></span>
<span class="r-in"><span><span class="va">gkw_result</span> <span class="op">&lt;-</span> <span class="fu">nrgkw</span><span class="op">(</span><span class="cn">NULL</span>, <span class="va">sample_data</span>, family <span class="op">=</span> <span class="st">"gkw"</span>,</span></span>
<span class="r-in"><span>                      verbose <span class="op">=</span> <span class="cn">FALSE</span>, get_num_hess <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Examine parameter identifiability through condition number</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sprintf.html" class="external-link">sprintf</a></span><span class="op">(</span><span class="st">"Condition number: %.2e\n"</span>, <span class="va">gkw_result</span><span class="op">$</span><span class="va">condition_number</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Condition number: 1.53e+04</span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">gkw_result</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $numeric_hessian</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>            [,1]       [,2]        [,3]        [,4]         [,5]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1,]  39.794995  -4.571312    87.53233  -32.593270    444.06555</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [2,]  -4.571312   1.439542   -10.81872    5.857501    -56.75483</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [3,]  87.532328 -10.818724 32214.53615  -66.260100   1044.23175</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [4,] -32.593270   5.857501   -66.26010 4578.884637   -346.00560</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [5,] 444.065547 -56.754833  1044.23175 -346.005601 761245.86007</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $parameters</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] 4.2707707 5.0044444 1.0452777 1.4460356 0.2768684</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $loglik</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] 126.9857</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $iterations</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] 13</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $converged</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] TRUE</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $param_history</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>          alpha     beta     gamma     delta    lambda</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [1,] 2.779887 5.701873 1.1402705 0.2000000 1.0000000</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [2,] 3.901736 5.025495 0.8057830 0.3726515 0.4621240</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [3,] 4.252054 4.953307 0.7670138 0.4393842 0.3307695</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [4,] 4.692818 4.880098 0.7835407 0.5832174 0.2840876</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [5,] 4.921412 4.854780 0.8103231 0.7132308 0.2643620</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [6,] 5.056488 4.845088 0.8407961 0.8312636 0.2531734</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [7,] 5.141648 4.842219 0.8715628 0.9389885 0.2461530</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [8,] 5.194155 4.843513 0.9017787 1.0379001 0.2414211</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [9,] 5.212231 4.849203 0.9311883 1.1291323 0.2383453</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [10,] 5.171991 4.862079 0.9597182 1.2138763 0.2377228</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [11,] 5.037631 4.886110 0.9876201 1.2936404 0.2415265</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [12,] 4.760743 4.928432 1.0157522 1.3702120 0.2525798</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [13,] 4.270771 5.004444 1.0452777 1.4460356 0.2768684</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [14,] 4.270771 5.004444 1.0452777 1.4460356 0.2768684</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $loglik_history</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [1] -68.42598  80.12436  99.28342 102.17675 105.49573 108.64541 111.47944</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [8] 114.01580 116.35091 118.66266 121.14742 123.97769 126.98568 126.98568</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $gradient</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1]   -5.651978   -1.864505  -31.962465   -6.471147 -131.188205</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $hessian</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>            [,1]       [,2]       [,3]        [,4]       [,5]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1,]  39.779367  -5.175563   87.53160  -32.593405  444.06718</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [2,]  -5.175563   1.443531  -10.81950    5.857314  -56.75701</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [3,]  87.531604 -10.819502  242.21457  -66.260071 1044.23303</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [4,] -32.593405   5.857314  -66.26007   34.427692 -346.00579</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [5,] 444.067183 -56.757009 1044.23303 -346.005793 5723.65272</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $std_errors</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] 0.67219742 1.54630105 0.15554835 0.51217947 0.03920591</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $aic</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] -243.9714</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $bic</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] -227.4798</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $aicc</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] -243.9714</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $n</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] 200</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $family</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] "gkw"</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $optimization_method</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] "trust-region"</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $scaling_factors</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] 1 1 1 1 1</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $condition_number</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] 15289.35</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $status</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] "success"</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $z_values</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] 6.353447 3.236397 6.719953 2.823299 7.061904</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $p_values</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] 2.105428e-10 1.210488e-03 1.817828e-11 4.753227e-03 1.642365e-12</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $param_names</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] "alpha"  "beta"   "gamma"  "delta"  "lambda"</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Compare with simpler models using information criteria</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Information criteria comparison:\n"</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Information criteria comparison:</span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sprintf.html" class="external-link">sprintf</a></span><span class="op">(</span><span class="st">"GKw: AIC=%.4f, BIC=%.4f\n"</span>, <span class="va">gkw_result</span><span class="op">$</span><span class="va">aic</span>, <span class="va">gkw_result</span><span class="op">$</span><span class="va">bic</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> GKw: AIC=-243.9714, BIC=-227.4798</span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sprintf.html" class="external-link">sprintf</a></span><span class="op">(</span><span class="st">"Beta: AIC=%.4f, BIC=%.4f\n"</span>,</span></span>
<span class="r-in"><span>           <span class="va">results</span><span class="op">[[</span><span class="st">"trust-region"</span><span class="op">]</span><span class="op">]</span><span class="op">$</span><span class="va">aic</span>, <span class="va">results</span><span class="op">[[</span><span class="st">"trust-region"</span><span class="op">]</span><span class="op">]</span><span class="op">$</span><span class="va">bic</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Beta: AIC=-278.8618, BIC=-272.2652</span>
<span class="r-in"><span><span class="co"># }</span></span></span>
</code></pre></div>
    </div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Lopes J. E..</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer></div>





  </body></html>

