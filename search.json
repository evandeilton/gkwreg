[{"path":"https://evandeilton.github.io/gkwreg/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 gkwreg authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (‚ÄúSoftware‚Äù), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED ‚Äú‚Äù, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://evandeilton.github.io/gkwreg/articles/gkwreg-vs-betareg.html","id":"abstract","dir":"Articles","previous_headings":"","what":"Abstract","title":"Beta Regression vs Kumaraswamy-Based Models for Bounded Data","text":"Beta regression become standard approach modeling continuous responses bounded unit interval. However, reliance incomplete beta function cumulative distribution function (CDF) presents computational challenges, distribution may inadequately represent data heavy tails extreme concentrations near boundaries. study presents comprehensive comparison traditional Beta regression alternative approaches based Kumaraswamy distribution family, offers analytical tractability closed-form CDF maintaining comparable flexibility. Monte Carlo simulations across three distinct data-generating mechanisms‚Äîwell-specified Beta data, heavy-tailed distributions, extreme boundary-concentrated patterns‚Äîdemonstrate Kumaraswamy-based models provide substantial computational advantages (2-9√ó faster) equivalent superior statistical performance. Parameter estimation analysis reveals coefficient estimates remain consistent across models, standard errors can differ 15-40% depending distributional misspecification. Notably, non-standard distributional shapes, Kumaraswamy models achieve dramatically higher convergence rates (100% vs.¬†5.5% extreme U-shaped data) improved model fit metrics. Keywords: Beta regression, Kumaraswamy distribution, bounded data, unit interval, computational efficiency","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwreg/articles/gkwreg-vs-betareg.html","id":"motivation-and-background","dir":"Articles","previous_headings":"Introduction","what":"Motivation and Background","title":"Beta Regression vs Kumaraswamy-Based Models for Bounded Data","text":"Regression analysis continuous responses restricted unit interval (0,1)(0,1) arises frequently across scientific disciplines. Applications include modeling proportions, rates, percentages, bounded measures ecology, psychology, economics, biostatistics (Ferrari & Cribari-Neto, 2004; Smithson & Verkuilen, 2006). Beta regression, introduced systematically Ferrari & Cribari-Neto (2004), emerged predominant framework analyses. Beta distribution‚Äôs flexibility accommodating various shapes two-parameter family (Œ±,Œ≤)(Œ±, Œ≤) makes attractive modeling heterogeneous unit-interval data. However, several limitations warrant consideration: Computational burden: Beta distribution lacks closed-form CDF, requiring numerical integration Boundary behavior: May exhibit poor convergence extreme J-shaped U-shaped distributions Tail flexibility: Limited capacity accommodate distributions heavier tails Beta family naturally supports","code":""},{"path":"https://evandeilton.github.io/gkwreg/articles/gkwreg-vs-betareg.html","id":"the-kumaraswamy-alternative","dir":"Articles","previous_headings":"Introduction","what":"The Kumaraswamy Alternative","title":"Beta Regression vs Kumaraswamy-Based Models for Bounded Data","text":"Kumaraswamy (1980) introduced two-parameter distribution (0,1)(0,1) closely mimics Beta distribution properties offering closed-form CDF: F(x;Œ±,Œ≤)=1‚àí(1‚àíxŒ±)Œ≤F(x; Œ±, Œ≤) = 1 - (1-x^Œ±)^Œ≤ analytical tractability provides computational advantages maintaining statistical flexibility comparable Beta distribution. Recent extensions generalized Kumaraswamy family accommodate additional shape parameters, creating hierarchical structure nests Beta Kumaraswamy special cases (Cordeiro & de Castro, 2011).","code":""},{"path":"https://evandeilton.github.io/gkwreg/articles/gkwreg-vs-betareg.html","id":"study-objectives","dir":"Articles","previous_headings":"Introduction","what":"Study Objectives","title":"Beta Regression vs Kumaraswamy-Based Models for Bounded Data","text":"article addresses three research questions: Computational efficiency: Kumaraswamy-based regression models compare Beta regression terms estimation speed convergence reliability? Statistical adequacy: data-generating mechanisms Kumaraswamy models provide equivalent, superior, inferior fit compared Beta regression? Parameter estimation: coefficient estimates standard errors differ across distributional families, practical implications? address questions rigorous Monte Carlo simulations comparing betareg package (Cribari-Neto & Zeileis, 2010) gkwreg package, implements regression models Kumaraswamy, Exponentiated Kumaraswamy, Generalized Kumaraswamy distributions.","code":"library(gkwreg) library(betareg) library(ggplot2)  # Standardized color palette for all comparisons MODEL_COLORS <- c(   \"Beta (betareg)\" = \"#D32F2F\", # Red   \"Beta (gkwreg)\" = \"#1976D2\", # Blue   \"Kumaraswamy\" = \"#388E3C\", # Green   \"Exp. Kumaraswamy\" = \"#7B1FA2\" # Purple )  MODEL_NAMES <- c(   betareg = \"Beta (betareg)\",   gkw_beta = \"Beta (gkwreg)\",   gkw_kw = \"Kumaraswamy\",   gkw_ekw = \"Exp. Kumaraswamy\" )"},{"path":[]},{"path":[]},{"path":"https://evandeilton.github.io/gkwreg/articles/gkwreg-vs-betareg.html","id":"beta-distribution","dir":"Articles","previous_headings":"Theoretical Framework > Distributional Families","what":"Beta Distribution","title":"Beta Regression vs Kumaraswamy-Based Models for Bounded Data","text":"Beta distribution shape parameters Œ±,Œ≤>0Œ±, Œ≤ > 0 probability density function: f(x;Œ±,Œ≤)=xŒ±‚àí1(1‚àíx)Œ≤‚àí1B(Œ±,Œ≤),x‚àà(0,1)f(x; Œ±, Œ≤) = \\frac{x^{Œ±-1}(1-x)^{Œ≤-1}}{B(Œ±,Œ≤)}, \\quad x \\(0,1) B(Œ±,Œ≤)=‚à´01tŒ±‚àí1(1‚àít)Œ≤‚àí1dtB(Œ±,Œ≤) = \\int_0^1 t^{Œ±-1}(1-t)^{Œ≤-1}dt beta function. Key properties include: Mean: E[X]=Œ±/(Œ±+Œ≤)E[X] = Œ±/(Œ±+Œ≤) Variance: Var(X)=Œ±Œ≤/[(Œ±+Œ≤)2(Œ±+Œ≤+1)]\\text{Var}(X) = Œ±Œ≤/[(Œ±+Œ≤)^2(Œ±+Œ≤+1)] CDF: closed form; requires numerical integration","code":""},{"path":"https://evandeilton.github.io/gkwreg/articles/gkwreg-vs-betareg.html","id":"kumaraswamy-distribution","dir":"Articles","previous_headings":"Theoretical Framework > Distributional Families","what":"Kumaraswamy Distribution","title":"Beta Regression vs Kumaraswamy-Based Models for Bounded Data","text":"Kumaraswamy distribution (Kumaraswamy, 1980) parameters Œ±,Œ≤>0Œ±, Œ≤ > 0 PDF: f(x;Œ±,Œ≤)=Œ±Œ≤xŒ±‚àí1(1‚àíxŒ±)Œ≤‚àí1,x‚àà(0,1)f(x; Œ±, Œ≤) = Œ±Œ≤x^{Œ±-1}(1-x^Œ±)^{Œ≤-1}, \\quad x \\(0,1) Distinguished closed-form CDF: F(x;Œ±,Œ≤)=1‚àí(1‚àíxŒ±)Œ≤F(x; Œ±, Œ≤) = 1 - (1-x^Œ±)^Œ≤ analytical expression enables: - Efficient quantile computation via F‚àí1(u)=[1‚àí(1‚àíu)1/Œ≤]1/Œ±F^{-1}(u) = [1-(1-u)^{1/Œ≤}]^{1/Œ±} - Faster likelihood evaluations - Simplified asymptotic theory development Kumaraswamy distribution closely approximates Beta distribution parameter combinations offering superior computational properties.","code":""},{"path":"https://evandeilton.github.io/gkwreg/articles/gkwreg-vs-betareg.html","id":"exponentiated-kumaraswamy-distribution","dir":"Articles","previous_headings":"Theoretical Framework > Distributional Families","what":"Exponentiated Kumaraswamy Distribution","title":"Beta Regression vs Kumaraswamy-Based Models for Bounded Data","text":"three-parameter extension incorporating additional shape parameter Œª>0Œª > 0 control tail behavior: fEKw(x;Œ±,Œ≤,Œª)‚àùxŒªŒ±‚àí1(1‚àíxŒª)Œ±Œ≤‚àí1[1‚àí(1‚àíxŒª)Œ±]Œ≤‚àí1f_{EKw}(x; Œ±, Œ≤, Œª) \\propto x^{ŒªŒ±-1}(1-x^Œª)^{Œ±Œ≤-1}[1-(1-x^Œª)^Œ±]^{Œ≤-1} family accommodates heavier tails standard Kumaraswamy, providing greater flexibility non-standard distributions maintaining computational tractability.","code":""},{"path":"https://evandeilton.github.io/gkwreg/articles/gkwreg-vs-betareg.html","id":"regression-structures","dir":"Articles","previous_headings":"Theoretical Framework","what":"Regression Structures","title":"Beta Regression vs Kumaraswamy-Based Models for Bounded Data","text":"Beta Kumaraswamy regression frameworks model distributional parameters functions covariates. response Yi‚àà(0,1)Y_i \\(0,1) covariate vector ùê±i\\mathbf{x}_i: g(Œºi)=ùê±iTùõÉg(\\mu_i) = \\mathbf{x}_i^T\\boldsymbol{\\beta} g(‚ãÖ)g(\\cdot) link function (typically logit) Œºi\\mu_i represents conditional mean. Additional parameters (precision, shape) may also depend covariates separate linear predictors: h(œïi)=ùê≥iTùõÑh(\\phi_i) = \\mathbf{z}_i^T\\boldsymbol{\\gamma} Maximum likelihood estimation proceeds via numerical optimization log-likelihood. closed-form CDF Kumaraswamy-based models can substantially accelerate convergence, particularly large datasets complex model structures.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwreg/articles/gkwreg-vs-betareg.html","id":"design-and-methodology","dir":"Articles","previous_headings":"Simulation Study","what":"Design and Methodology","title":"Beta Regression vs Kumaraswamy-Based Models for Bounded Data","text":"conducted Monte Carlo simulations evaluate model performance across three scenarios representing distinct challenges bounded-data regression: Scenario 1: Well-specified Beta distribution (baseline performance) Scenario 2: Heavy-tailed distribution (robustness misspecification) Scenario 3: Extreme boundary concentration (convergence reliability) scenario, generated 200 independent datasets, split training (80%) testing (20%) subsets, fit four competing models: Beta (betareg): Traditional Beta regression via betareg package Beta (gkwreg): Beta regression via gkwreg (noting parameterization differences) Kumaraswamy: Two-parameter Kumaraswamy regression Exp. Kumaraswamy: Three-parameter extended family","code":""},{"path":"https://evandeilton.github.io/gkwreg/articles/gkwreg-vs-betareg.html","id":"performance-metrics","dir":"Articles","previous_headings":"Simulation Study > Design and Methodology","what":"Performance Metrics","title":"Beta Regression vs Kumaraswamy-Based Models for Bounded Data","text":"Model comparison employed multiple criteria: Convergence rate: Proportion successful optimizations Akaike Information Criterion (AIC): Balancing fit parsimony Root Mean Squared Error (RMSE): --sample predictive accuracy Computational time: Wall-clock seconds estimation Parameter estimates: Coefficient bias standard error accuracy","code":""},{"path":"https://evandeilton.github.io/gkwreg/articles/gkwreg-vs-betareg.html","id":"scenario-1-beta-distributed-data","dir":"Articles","previous_headings":"Simulation Study","what":"Scenario 1: Beta-Distributed Data","title":"Beta Regression vs Kumaraswamy-Based Models for Bounded Data","text":"Data-generating process: Responses follow Beta(Œºœï,(1‚àíŒº)œï)\\text{Beta}(Œº\\phi, (1-Œº)\\phi) : - logit(Œº)=0.5‚àí0.8x1+0.6x2\\text{logit}(Œº) = 0.5 - 0.8x_1 + 0.6x_2 - log(œï)=1.5+0.4x1\\log(\\phi) = 1.5 + 0.4x_1 - x1‚àºN(0,1)x_1 \\sim N(0,1), x2‚àºU(‚àí1,1)x_2 \\sim U(-1,1) - Sample size: n=300n = 300 scenario establishes baseline performance Beta regression assumptions hold exactly.","code":"dgp_beta <- function(n, params) {   x1 <- rnorm(n, 0, 1)   x2 <- runif(n, -1, 1)    eta_mu <- params$beta_mu[1] + params$beta_mu[2] * x1 + params$beta_mu[3] * x2   eta_phi <- params$beta_phi[1] + params$beta_phi[2] * x1    mu <- plogis(eta_mu)   phi <- exp(eta_phi)    y <- rbeta(n, mu * phi, (1 - mu) * phi)   y <- pmax(pmin(y, 0.999), 0.001)    data.frame(y = y, x1 = x1, x2 = x2, mu = mu, phi = phi) }"},{"path":"https://evandeilton.github.io/gkwreg/articles/gkwreg-vs-betareg.html","id":"visualizing-the-response-distribution","dir":"Articles","previous_headings":"Simulation Study > Scenario 1: Beta-Distributed Data","what":"Visualizing the Response Distribution","title":"Beta Regression vs Kumaraswamy-Based Models for Bounded Data","text":"Figure 1 illustrates distributional characteristics Beta-generated data. response YY exhibits moderate skewness smooth density across unit interval. scatter plots reveal clear covariate effects: x1x_1 demonstrates strong negative relationship YY (coefficient Œ≤‚ÇÅ = ‚àí0.8), x2x_2 shows positive association (Œ≤‚ÇÇ = 0.6). well-behaved structure represents ‚Äúideal case‚Äù Beta regression. Distributional Characteristics - Scenario 1 (Well-Specified Beta)","code":"set.seed(123) vis_data_s1 <- dgp_beta(1000, list(   beta_mu = c(0.5, -0.8, 0.6),   beta_phi = c(1.5, 0.4) ))  par(mfrow = c(2, 2), mar = c(4, 4, 2, 2))  # Response distribution hist(vis_data_s1$y,   breaks = 40, col = \"#388E3C\", border = \"white\",   main = \"Response Distribution\", xlab = \"Y\", prob = TRUE,   cex.main = 1.2, cex.lab = 1.1 ) lines(density(vis_data_s1$y), col = \"#D32F2F\", lwd = 2) legend(\"topright\", \"Kernel density\", col = \"#D32F2F\", lwd = 2, bty = \"n\")  # Effect of x1 plot(vis_data_s1$x1, vis_data_s1$y,   pch = 16, col = rgb(0, 0, 0, 0.3),   main = \"Covariate Effect: x1\", xlab = \"x1\", ylab = \"Y\",   cex.main = 1.2, cex.lab = 1.1 ) lines(lowess(vis_data_s1$x1, vis_data_s1$y), col = \"#D32F2F\", lwd = 3) abline(h = 0.5, lty = 2, col = \"gray50\")  # Effect of x2 plot(vis_data_s1$x2, vis_data_s1$y,   pch = 16, col = rgb(0, 0, 0, 0.3),   main = \"Covariate Effect: x2\", xlab = \"x2\", ylab = \"Y\",   cex.main = 1.2, cex.lab = 1.1 ) lines(lowess(vis_data_s1$x2, vis_data_s1$y), col = \"#388E3C\", lwd = 3) abline(h = 0.5, lty = 2, col = \"gray50\")  # Conditional variance plot(abs(vis_data_s1$x1), (vis_data_s1$y - vis_data_s1$mu)^2,   pch = 16, col = rgb(0, 0, 0, 0.2),   main = \"Heteroscedasticity Structure\",   xlab = \"|x1|\", ylab = \"Squared Residuals\",   cex.main = 1.2, cex.lab = 1.1 ) lines(lowess(abs(vis_data_s1$x1), (vis_data_s1$y - vis_data_s1$mu)^2),   col = \"#1976D2\", lwd = 3 ) # mtext(\"Figure 1: Distributional Characteristics - Scenario 1 (Well-Specified Beta)\", #       side = 3, line = -2, outer = TRUE, font = 2, cex = 1.1)"},{"path":"https://evandeilton.github.io/gkwreg/articles/gkwreg-vs-betareg.html","id":"simulation-results","dir":"Articles","previous_headings":"Simulation Study > Scenario 1: Beta-Distributed Data","what":"Simulation Results","title":"Beta Regression vs Kumaraswamy-Based Models for Bounded Data","text":"","code":"results_s1 <- run_full_simulation(   n_sim = 200,   n = 300,   dgp_fun = dgp_beta,   params = list(     beta_mu = c(0.5, -0.8, 0.6),     beta_phi = c(1.5, 0.4)   ),   formula = y ~ x1 + x2 | x1 )  comp_s1 <- make_comparison_table(results_s1)"},{"path":"https://evandeilton.github.io/gkwreg/articles/gkwreg-vs-betareg.html","id":"parameter-estimation-comparison","dir":"Articles","previous_headings":"Simulation Study > Scenario 1: Beta-Distributed Data","what":"Parameter Estimation Comparison","title":"Beta Regression vs Kumaraswamy-Based Models for Bounded Data","text":"assess coefficient recovery, fit Beta Kumaraswamy models single representative dataset compare parameter estimates. Table 1 presents estimates, standard errors, z-statistics. Table 1: Parameter Estimates - Scenario 1 (Well-Specified Beta, n=300) Interpretation coefficient estimates: models recover parameters minimal bias (biases < 0.05 absolute value). key finding standard error comparison (SE Ratio column): Mean parameters (Intercept, x1, x2): Standard errors differ 2-5%, indicating equivalent precision inference covariate effects Precision parameters (œÜ components): SE Ratio ‚âà 1.02-1.08, showing nearly identical uncertainty quantification Beta model correctly specified, approaches provide statistically equivalent inference. z-statistics (Est./SE) yield essentially identical conclusions parameter significance. validates Kumaraswamy drop-replacement well-specified scenarios.","code":"# Fit models to one dataset for coefficient comparison set.seed(456) data_coef_s1 <- dgp_beta(300, list(   beta_mu = c(0.5, -0.8, 0.6),   beta_phi = c(1.5, 0.4) ))  fit_beta_s1 <- betareg(y ~ x1 + x2 | x1, data = data_coef_s1) fit_kw_s1 <- gkwreg(y ~ x1 + x2 | x1, data = data_coef_s1, family = \"kw\")  # Extract coefficients coef_beta_s1 <- coef(fit_beta_s1) se_beta_s1 <- sqrt(diag(vcov(fit_beta_s1)))  coef_kw_s1 <- coef(fit_kw_s1) se_kw_s1 <- fit_kw_s1$se  # Build comparison table coef_names <- names(coef_beta_s1) true_values <- c(0.5, -0.8, 0.6, 1.5, 0.4)  coef_comparison_s1 <- data.frame(   Parameter = coef_names,   True_Value = true_values,   Beta_Est = round(coef_beta_s1, 4),   Beta_SE = round(se_beta_s1, 4),   Beta_Z = round(coef_beta_s1 / se_beta_s1, 2),   Kw_Est = round(coef_kw_s1, 4),   Kw_SE = round(se_kw_s1, 4),   Kw_Z = round(coef_kw_s1 / se_kw_s1, 2) )  # Calculate differences coef_comparison_s1$Bias_Beta <- round(coef_comparison_s1$Beta_Est - true_values, 4) coef_comparison_s1$Bias_Kw <- round(coef_comparison_s1$Kw_Est - true_values, 4) coef_comparison_s1$SE_Ratio <- round(coef_comparison_s1$Kw_SE / coef_comparison_s1$Beta_SE, 3)  knitr::kable(   row.names = FALSE,   coef_comparison_s1,   caption = \"Table 1: Parameter Estimates - Scenario 1 (Well-Specified Beta, n=300)\",   col.names = c(     \"Parameter\", \"True\", \"Est.\", \"SE\", \"z\", \"Est.\", \"SE\", \"z\",     \"Bias\", \"Bias\", \"SE Ratio\"   ),   align = c(\"l\", rep(\"r\", 10)) )"},{"path":"https://evandeilton.github.io/gkwreg/articles/gkwreg-vs-betareg.html","id":"scenario-2-heavy-tailed-data","dir":"Articles","previous_headings":"Simulation Study","what":"Scenario 2: Heavy-Tailed Data","title":"Beta Regression vs Kumaraswamy-Based Models for Bounded Data","text":"Data-generating process: Exponentiated Kumaraswamy distribution Œª=1.82Œª = 1.82 (exp(0.6)), inducing heavier tails Beta can accommodate: - log(Œ±)=0.8‚àí0.5x1\\log(Œ±) = 0.8 - 0.5x_1 - log(Œ≤)=0.3+0.4x2\\log(Œ≤) = 0.3 + 0.4x_2 - x1‚àºN(0,1)x_1 \\sim N(0,1), x2‚àºBernoulli(0.5)x_2 \\sim \\text{Bernoulli}(0.5) - Sample size: n=300n = 300 scenario tests model robustness true distribution deviates Beta assumptions.","code":"dgp_heavy_tails <- function(n, params) {   x1 <- rnorm(n, 0, 1)   x2 <- rbinom(n, 1, 0.5)    eta_alpha <- params$beta_alpha[1] + params$beta_alpha[2] * x1   eta_beta <- params$beta_beta[1] + params$beta_beta[2] * x2   eta_lambda <- params$beta_lambda[1]    alpha <- exp(eta_alpha)   beta <- exp(eta_beta)   lambda <- exp(eta_lambda)    u <- runif(n)   y <- (1 - (1 - u^(1 / beta))^(1 / alpha))^(1 / lambda)   y <- pmax(pmin(y, 0.9999), 0.0001)    data.frame(y = y, x1 = x1, x2 = factor(x2)) }"},{"path":"https://evandeilton.github.io/gkwreg/articles/gkwreg-vs-betareg.html","id":"visualizing-heavy-tailed-distributions","dir":"Articles","previous_headings":"Simulation Study > Scenario 2: Heavy-Tailed Data","what":"Visualizing Heavy-Tailed Distributions","title":"Beta Regression vs Kumaraswamy-Based Models for Bounded Data","text":"Figure 2 reveals critical feature distinguishing scenario: pronounced mass tails compared Beta‚Äôs exponential decay. histogram shows elevated frequencies near 0 1, creating ‚Äúfat tails‚Äù Beta regression struggles accommodate. overlaid density curve exhibits slower decay rates, characteristic Exponentiated Kumaraswamy‚Äôs third shape parameter. Distributional Characteristics - Scenario 2 (Heavy Tails) Q-Q plot (top right panel) provides definitive evidence tail divergence: observations systematically exceed Beta quantiles tails, departures increasing toward extremes. pattern indicates Beta regression systematically underestimate tail probabilities, leading poor probabilistic forecasts.","code":"set.seed(789) vis_data_s2 <- dgp_heavy_tails(1500, list(   beta_alpha = c(0.8, -0.5),   beta_beta = c(0.3, 0.4),   beta_lambda = c(0.6) ))  par(mfrow = c(2, 2), mar = c(4, 4, 3, 2))  # Response distribution hist(vis_data_s2$y,   breaks = 60, col = \"#7B1FA2\", border = \"white\",   main = \"Heavy-Tailed Distribution\", xlab = \"Y\", prob = TRUE,   cex.main = 1.2, cex.lab = 1.1 ) lines(density(vis_data_s2$y), col = \"#D32F2F\", lwd = 2) # Add Beta approximation for comparison beta_approx <- rbeta(1500, 2, 2) lines(density(beta_approx), col = \"#1976D2\", lwd = 2, lty = 2) legend(\"topright\", c(\"True density\", \"Beta approximation\"),   col = c(\"#D32F2F\", \"#1976D2\"), lwd = 2, lty = c(1, 2), bty = \"n\", cex = 0.9 )  # QQ plot against Beta qqplot(rbeta(1500, 2, 2), vis_data_s2$y,   main = \"Q-Q Plot: EKw vs Beta(2,2)\",   xlab = \"Beta(2,2) Quantiles\", ylab = \"Observed Quantiles\",   pch = 16, col = rgb(0, 0, 0, 0.3), cex.main = 1.2, cex.lab = 1.1 ) abline(0, 1, col = \"#D32F2F\", lwd = 2) text(0.2, 0.8, \"Heavier tails\\n(departures)\", col = \"#D32F2F\", cex = 0.9)  # Effect by group boxplot(y ~ x2,   data = vis_data_s2, col = c(\"#388E3C\", \"#7B1FA2\"),   main = \"Distribution by Group\", xlab = \"x2\", ylab = \"Y\",   names = c(\"Group 0\", \"Group 1\"), cex.main = 1.2, cex.lab = 1.1 )  # Tail behavior plot(sort(vis_data_s2$y)[1:50],   ylab = \"Y\", xlab = \"Order (Lower Tail)\",   main = \"Lower Tail Concentration\", pch = 16, col = \"#7B1FA2\",   cex.main = 1.2, cex.lab = 1.1 ) beta_tail <- sort(rbeta(1500, 2, 2))[1:50] points(beta_tail, pch = 1, col = \"#1976D2\") legend(\"topleft\", c(\"EKw\", \"Beta(2,2)\"),   col = c(\"#7B1FA2\", \"#1976D2\"),   pch = c(16, 1), bty = \"n\" ) # mtext(\"Figure 2: Distributional Characteristics - Scenario 2 (Heavy Tails)\", #       side = 3, line = -2, outer = TRUE, font = 2, cex = 1.1)"},{"path":"https://evandeilton.github.io/gkwreg/articles/gkwreg-vs-betareg.html","id":"simulation-results-1","dir":"Articles","previous_headings":"Simulation Study > Scenario 2: Heavy-Tailed Data","what":"Simulation Results","title":"Beta Regression vs Kumaraswamy-Based Models for Bounded Data","text":"","code":"results_s2 <- run_full_simulation(   n_sim = 200,   n = 300,   dgp_fun = dgp_heavy_tails,   params = list(     beta_alpha = c(0.8, -0.5),     beta_beta = c(0.3, 0.4),     beta_lambda = c(0.6)   ),   formula = y ~ x1 | x2 )  comp_s2 <- make_comparison_table(results_s2)"},{"path":"https://evandeilton.github.io/gkwreg/articles/gkwreg-vs-betareg.html","id":"parameter-estimation-under-misspecification","dir":"Articles","previous_headings":"Simulation Study > Scenario 2: Heavy-Tailed Data","what":"Parameter Estimation Under Misspecification","title":"Beta Regression vs Kumaraswamy-Based Models for Bounded Data","text":"true distribution Exponentiated Kumaraswamy fit Beta regression, parameter estimates become biased inference unreliable. Table 2 quantifies distortions. Table 2: Parameter Estimates - Scenario 2 (Heavy Tails, n=300) Critical finding standard errors: SE Ratio column reveals 15-40% inflation Kumaraswamy standard errors relative Beta. deficiency‚Äîreflects honest uncertainty quantification Beta misspecified: Beta regression underestimates uncertainty: SE artificially small, confidence intervals achieve < 95% coverage, hypothesis tests inflated Type error Kumaraswamy appropriately accounts tail variation: Larger SE reflects additional variability heavy-tailed data z-statistics tell story: Beta regression declares x1 ‚Äúhighly significant‚Äù (z = ‚àí14.31) Kumaraswamy provides conservative z = ‚àí10.98. truth, Beta‚Äôs inference anti-conservative due model misspecification. Kumaraswamy family, including parameters accommodate tail behavior, provides valid inference. Magnitude interpretation: 40% SE difference implies 95% CIs Beta regression ~28% narrow (1/1.4‚âà0.711/1.4 ‚âà 0.71). practical terms, researchers using Beta regression report false precision, potentially leading erroneous scientific conclusions.","code":"# Fit models to one dataset set.seed(101112) data_coef_s2 <- dgp_heavy_tails(300, list(   beta_alpha = c(0.8, -0.5),   beta_beta = c(0.3, 0.4),   beta_lambda = c(0.6) ))  fit_beta_s2 <- betareg(y ~ x1 | x2, data = data_coef_s2) fit_kw_s2 <- gkwreg(y ~ x1 | x2, data = data_coef_s2, family = \"kw\")  coef_beta_s2 <- coef(fit_beta_s2) se_beta_s2 <- sqrt(diag(vcov(fit_beta_s2)))  coef_kw_s2 <- coef(fit_kw_s2) se_kw_s2 <- fit_kw_s2$se  # Note: True parameters are on different scale (Œ±, Œ≤ vs Œº, œÜ) # Focus on relative comparisons coef_comparison_s2 <- data.frame(   Parameter = names(coef_beta_s2),   Beta_Est = round(coef_beta_s2, 4),   Beta_SE = round(se_beta_s2, 4),   Beta_Z = round(coef_beta_s2 / se_beta_s2, 2),   Kw_Est = round(coef_kw_s2, 4),   Kw_SE = round(se_kw_s2, 4),   Kw_Z = round(coef_kw_s2 / se_kw_s2, 2),   SE_Ratio = round(se_kw_s2 / se_beta_s2, 3) )  knitr::kable(   row.names = FALSE,   coef_comparison_s2,   caption = \"Table 2: Parameter Estimates - Scenario 2 (Heavy Tails, n=300)\",   # col.names = c(\"Parameter\", \"Est.\", \"SE\", \"z\", \"Est.\", \"SE\", \"z\", \"SE Ratio\"),   align = c(\"l\", rep(\"r\", 7)) )"},{"path":"https://evandeilton.github.io/gkwreg/articles/gkwreg-vs-betareg.html","id":"scenario-3-extreme-distributional-shapes","dir":"Articles","previous_headings":"Simulation Study","what":"Scenario 3: Extreme Distributional Shapes","title":"Beta Regression vs Kumaraswamy-Based Models for Bounded Data","text":"Data-generating process: Mixture J-shaped (concentrated near 0) U-shaped (concentrated boundaries) Kumaraswamy distributions: - J-shaped: log(Œ±)=‚àí1.5+0.2x1\\log(Œ±) = -1.5 + 0.2x_1, log(Œ≤)=2.0\\log(Œ≤) = 2.0 - U-shaped: log(Œ±)=‚àí1.8+0.1x1\\log(Œ±) = -1.8 + 0.1x_1, log(Œ≤)=‚àí0.8\\log(Œ≤) = -0.8 - x1‚àºN(0,1)x_1 \\sim N(0,1) - Sample size: n=400n = 400 challenging scenario assesses convergence reliability extreme boundary concentration.","code":"dgp_extreme <- function(n, params) {   x1 <- rnorm(n, 0, 1)   group <- sample(c(\"J\", \"U\"), n, replace = TRUE)    alpha <- ifelse(     group == \"J\",     exp(params$alpha_J[1] + params$alpha_J[2] * x1),     exp(params$alpha_U[1] + params$alpha_U[2] * x1)   )    beta <- ifelse(group == \"J\", exp(params$beta_J), exp(params$beta_U))    u <- runif(n)   y <- (1 - (1 - u)^(1 / beta))^(1 / alpha)   y <- pmax(pmin(y, 0.9999), 0.0001)    data.frame(y = y, x1 = x1, group = factor(group)) }"},{"path":"https://evandeilton.github.io/gkwreg/articles/gkwreg-vs-betareg.html","id":"visualizing-extreme-boundary-concentrations","dir":"Articles","previous_headings":"Simulation Study > Scenario 3: Extreme Distributional Shapes","what":"Visualizing Extreme Boundary Concentrations","title":"Beta Regression vs Kumaraswamy-Based Models for Bounded Data","text":"Figure 3 demonstrates pathological case Beta regression. J-shaped distribution (left panel) concentrates 80% mass 0.2, U-shaped distribution (right panel) exhibits bimodality peaks boundaries. patterns violate Beta regression‚Äôs assumption smooth, unimodal densities. Extreme Distributional Shapes - Scenario 3 (Boundary Concentration) empirical CDF (bottom right) quantifies severity: 45% observations fall 0.1 0.9. extreme boundary concentration creates numerical instabilities Beta regression‚Äôs likelihood, beta function B(Œ±,Œ≤)B(Œ±,Œ≤) becomes ill-conditioned shape parameters approaching zero.","code":"set.seed(131415) vis_data_s3 <- dgp_extreme(2000, list(   alpha_J = c(-1.5, 0.2),   beta_J = 2.0,   alpha_U = c(-1.8, 0.1),   beta_U = -0.8 ))  par(mfrow = c(2, 2), mar = c(4, 4, 3, 2))  # J-shaped distribution hist(vis_data_s3$y[vis_data_s3$group == \"J\"],   breaks = 50,   col = \"#FF6F00\", border = \"white\",   main = \"J-Shaped Distribution\", xlab = \"Y\", prob = TRUE,   xlim = c(0, 1), cex.main = 1.2, cex.lab = 1.1 ) lines(density(vis_data_s3$y[vis_data_s3$group == \"J\"]),   col = \"#D32F2F\", lwd = 2 ) text(0.5, 15, sprintf(   \"80%% of mass\\n< %.2f\",   quantile(vis_data_s3$y[vis_data_s3$group == \"J\"], 0.8) ), col = \"#D32F2F\", cex = 0.9 )  # U-shaped distribution hist(vis_data_s3$y[vis_data_s3$group == \"U\"],   breaks = 50,   col = \"#0277BD\", border = \"white\",   main = \"U-Shaped Distribution\", xlab = \"Y\", prob = TRUE,   xlim = c(0, 1), cex.main = 1.2, cex.lab = 1.1 ) lines(density(vis_data_s3$y[vis_data_s3$group == \"U\"]),   col = \"#D32F2F\", lwd = 2 ) text(0.5, 3, \"Bimodal:\\nconcentration\\nat boundaries\",   col = \"#D32F2F\", cex = 0.9 )  # Combined distribution plot(density(vis_data_s3$y),   main = \"Mixture Distribution\",   xlab = \"Y\", ylab = \"Density\", lwd = 2, col = \"#7B1FA2\",   cex.main = 1.2, cex.lab = 1.1 ) polygon(density(vis_data_s3$y), col = rgb(0.48, 0.12, 0.63, 0.3), border = NA)  # Empirical CDF showing boundary concentration plot(ecdf(vis_data_s3$y),   main = \"Empirical CDF\",   xlab = \"Y\", ylab = \"F(Y)\", lwd = 2, col = \"#388E3C\",   cex.main = 1.2, cex.lab = 1.1 ) abline(v = c(0.1, 0.9), lty = 2, col = \"gray40\") text(0.05, 0.5, sprintf(   \"%.0f%%\\n< 0.1\",   100 * mean(vis_data_s3$y < 0.1) ), col = \"#D32F2F\", cex = 0.9 ) text(0.95, 0.5, sprintf(   \"%.0f%%\\n> 0.9\",   100 * mean(vis_data_s3$y > 0.9) ), col = \"#D32F2F\", cex = 0.9 ) # mtext(\"Figure 3: Extreme Distributional Shapes - Scenario 3 (Boundary Concentration)\", #       side = 3, line = -2, outer = TRUE, font = 2, cex = 1.1)"},{"path":"https://evandeilton.github.io/gkwreg/articles/gkwreg-vs-betareg.html","id":"simulation-results-2","dir":"Articles","previous_headings":"Simulation Study > Scenario 3: Extreme Distributional Shapes","what":"Simulation Results","title":"Beta Regression vs Kumaraswamy-Based Models for Bounded Data","text":"","code":"results_s3 <- run_full_simulation(   n_sim = 200,   n = 400,   dgp_fun = dgp_extreme,   params = list(     alpha_J = c(-1.5, 0.2),     beta_J = 2.0,     alpha_U = c(-1.8, 0.1),     beta_U = -0.8   ),   formula = y ~ x1 * group | group )  comp_s3 <- make_comparison_table(results_s3)"},{"path":"https://evandeilton.github.io/gkwreg/articles/gkwreg-vs-betareg.html","id":"the-convergence-crisis","dir":"Articles","previous_headings":"Simulation Study > Scenario 3: Extreme Distributional Shapes","what":"The Convergence Crisis","title":"Beta Regression vs Kumaraswamy-Based Models for Bounded Data","text":"Table 3 documents Beta regression‚Äôs catastrophic failure confronted extreme shapes. Among 200 simulation replicates, Beta regression successfully converged 11 times (5.5%), Kumaraswamy achieved perfect reliability (100%). Table 3: Parameter Estimates - Scenario 3 (Extreme Shapes, n=400, Beta Converged) Beta converge (rare 5.5% cases), SE Ratio analysis reveals instability: Standard errors boundary-proximate parameters can 2-3√ó larger Beta regression, indicating optimizer operating near numerical cliff Conversely, SEs may artificially small due premature convergence, yielding anti-conservative inference fundamental insight: Beta regression merely inefficient extreme shapes‚Äîunreliable. 94.5% failure rate means researchers abandon analysis resort ad-hoc data transformations, scientifically problematic.","code":"# For this scenario, we'll fit to a single J-shaped dataset where Beta converges set.seed(161718) # Generate J-shaped only for better Beta convergence probability data_coef_s3 <- dgp_extreme(400, list(   alpha_J = c(-1.2, 0.15), # Slightly less extreme for illustration   beta_J = 1.8,   alpha_U = c(-1.5, 0.1),   beta_U = -0.5 ))  # Try fitting - Beta may fail fit_beta_s3 <- tryCatch(   {     betareg(y ~ x1 * group | group, data = data_coef_s3)   },   error = function(e) NULL )  fit_kw_s3 <- gkwreg(y ~ x1 * group | group, data = data_coef_s3, family = \"kw\")  if (!is.null(fit_beta_s3) && fit_beta_s3$converged) {   coef_beta_s3 <- coef(fit_beta_s3)   se_beta_s3 <- sqrt(diag(vcov(fit_beta_s3)))    coef_kw_s3 <- coef(fit_kw_s3)   se_kw_s3 <- fit_kw_s3$se    coef_comparison_s3 <- data.frame(     Parameter = names(coef_beta_s3),     Beta_Est = round(coef_beta_s3, 4),     Beta_SE = round(se_beta_s3, 4),     Beta_Z = round(coef_beta_s3 / se_beta_s3, 2),     Kw_Est = round(coef_kw_s3, 4),     Kw_SE = round(se_kw_s3, 4),     Kw_Z = round(coef_kw_s3 / se_kw_s3, 2),     SE_Ratio = round(se_kw_s3 / se_beta_s3, 3)   )    knitr::kable(     coef_comparison_s3,     caption = \"Table 3: Parameter Estimates - Scenario 3 (Extreme Shapes, n=400, Beta Converged)\",     col.names = c(\"Parameter\", \"Est.\", \"SE\", \"z\", \"Est.\", \"SE\", \"z\", \"SE Ratio\"),     align = c(\"l\", rep(\"r\", 7))   ) } else {   cat(\"**Table 3: Parameter Estimates - Scenario 3**\\n\\n\")   cat(\"Beta regression failed to converge (as expected in 94.5% of cases).\\n\")   cat(\"Only Kumaraswamy estimates are available:\\n\\n\")    coef_kw_s3 <- coef(fit_kw_s3)   se_kw_s3 <- fit_kw_s3$se    knitr::kable(     digits = 3,     data.frame(       row.names = FALSE,       Parameter = names(coef_kw_s3),       Estimate = round(coef_kw_s3, 4),       SE = round(se_kw_s3, 4),       z_stat = round(coef_kw_s3 / se_kw_s3, 2),       p_value = round(2 * pnorm(-abs(coef_kw_s3 / se_kw_s3)), 4)     ),     caption = \"Kumaraswamy Parameter Estimates (Beta Failed)\"   ) }"},{"path":[]},{"path":"https://evandeilton.github.io/gkwreg/articles/gkwreg-vs-betareg.html","id":"comparative-performance-across-scenarios","dir":"Articles","previous_headings":"Results and Discussion","what":"Comparative Performance Across Scenarios","title":"Beta Regression vs Kumaraswamy-Based Models for Bounded Data","text":"Table 4 synthesizes key performance metrics across three simulation scenarios. patterns reveal clear, actionable insights practitioners. Table 4: Comprehensive Model Comparison Across Three Simulation Scenarios","code":""},{"path":"https://evandeilton.github.io/gkwreg/articles/gkwreg-vs-betareg.html","id":"statistical-performance-summary","dir":"Articles","previous_headings":"Results and Discussion > Comparative Performance Across Scenarios","what":"Statistical Performance Summary","title":"Beta Regression vs Kumaraswamy-Based Models for Bounded Data","text":"Figure 4 visualizes critical trade-offs across scenarios. left panel shows AIC (model fit), middle panel convergence rates, right panel computational efficiency. Comparative Performance Across Scenarios Key takeaways Figure 4: Scenario 1 (Well-specified): Beta achieves marginally better AIC (‚àí224 vs ‚àí220), Kumaraswamy 2.5√ó faster perfect convergence Scenario 2 (Heavy tails): Kumaraswamy maintains competitive fit Beta becomes severely misspecified; converge reliably Scenario 3 (Extreme shapes): Beta‚Äôs AIC becomes uninformative due convergence failure; Kumaraswamy provides sole viable solution 20√ó speedup (comparing successful fits)","code":""},{"path":"https://evandeilton.github.io/gkwreg/articles/gkwreg-vs-betareg.html","id":"parameter-estimation-magnitude-and-precision","dir":"Articles","previous_headings":"Results and Discussion > Comparative Performance Across Scenarios","what":"Parameter Estimation: Magnitude and Precision","title":"Beta Regression vs Kumaraswamy-Based Models for Bounded Data","text":"Across scenarios, coefficient estimates show consistency standard errors reveal important differences: models correctly specified (Scenario 1): - Coefficient bias < 5% approaches - Standard errors differ < 10%, providing equivalent inference - Conclusion: Interchangeable inference covariate effects misspecification (Scenarios 2-3): - Beta standard errors 15-40% smaller appropriate, reflecting model overconfidence - Kumaraswamy standard errors honestly reflect distributional uncertainty - Consequence: Beta regression produces anti-conservative confidence intervals < 95% coverage finding profound implications scientific inference. Researchers using Beta regression heavy-tailed boundary-concentrated data systematically understate uncertainty, leading : - Inflated false discovery rates hypothesis testing - Overstated precision effect size estimates - Reproducibility failures subsequent studies use appropriate models","code":""},{"path":"https://evandeilton.github.io/gkwreg/articles/gkwreg-vs-betareg.html","id":"computational-efficiency-analysis","dir":"Articles","previous_headings":"Results and Discussion","what":"Computational Efficiency Analysis","title":"Beta Regression vs Kumaraswamy-Based Models for Bounded Data","text":"Table 5 aggregates computational performance across scenarios: Table 5: Average Computational Time Speedup Relative Beta Regression 2-9√ó speedup range Kumaraswamy reflects scenario complexity: - Simple models (Scenario 1): 2.5√ó faster - Complex models interactions (Scenario 3): 9√ó faster scaling behavior arises closed-form CDF‚Äôs advantage compounding model complexity. additional parameter requires likelihood evaluations optimization, amplifying per-evaluation efficiency gain. Practical implications application: interactive data analysis iterative model building, differences transform user experience ‚Äúcoffee break‚Äù ‚Äúinstantaneous response.‚Äù","code":""},{"path":"https://evandeilton.github.io/gkwreg/articles/gkwreg-vs-betareg.html","id":"practical-decision-framework","dir":"Articles","previous_headings":"Results and Discussion","what":"Practical Decision Framework","title":"Beta Regression vs Kumaraswamy-Based Models for Bounded Data","text":"propose evidence-based decision tree practitioners: Critical principle: uncertain, prefer Kumaraswamy. computational advantages guaranteed, potential fit disadvantages minimal arise perfectly specified Beta scenarios (rare practice).","code":"START: Bounded response data Y ‚àà (0,1) ‚îÇ ‚îú‚îÄ STEP 1: Examine distributional shape ‚îÇ  ‚îÇ ‚îÇ  ‚îú‚îÄ Q: Substantial concentration near 0 or 1? (>30% within 0.1 of boundaries) ‚îÇ  ‚îÇ  YES ‚Üí Use Kumaraswamy [Reason: Beta convergence unreliable] ‚îÇ  ‚îÇ  NO ‚Üí Continue to Step 2 ‚îÇ   ‚îú‚îÄ STEP 2: Assess computational constraints   ‚îÇ  ‚îÇ ‚îÇ  ‚îú‚îÄ Q: Require intensive computation? (CV, bootstrap, >100 models) ‚îÇ  ‚îÇ  YES ‚Üí Use Kumaraswamy [Reason: 2-9√ó speedup] ‚îÇ  ‚îÇ  NO ‚Üí Continue to Step 3 ‚îÇ ‚îú‚îÄ STEP 3: Evaluate distributional assumptions ‚îÇ  ‚îÇ ‚îÇ  ‚îú‚îÄ Q: Evidence of heavy tails or poor Beta fit? (QQ plots, AIC comparison) ‚îÇ  ‚îÇ  YES ‚Üí Use Exponentiated Kumaraswamy [Reason: Better tail accommodation] ‚îÇ  ‚îÇ  NO ‚Üí Continue to Step 4 ‚îÇ ‚îî‚îÄ STEP 4: Default choice    ‚îÇ    ‚îî‚îÄ Beta and Kumaraswamy both acceptable       Recommendation: Use Kumaraswamy for future-proofing       [Reason: Equivalent inference, better computational properties]"},{"path":[]},{"path":"https://evandeilton.github.io/gkwreg/articles/gkwreg-vs-betareg.html","id":"summary-of-findings","dir":"Articles","previous_headings":"Conclusions","what":"Summary of Findings","title":"Beta Regression vs Kumaraswamy-Based Models for Bounded Data","text":"comprehensive simulation study establishes Kumaraswamy-based regression models offer compelling advantages traditional Beta regression across multiple performance dimensions: Computational efficiency: 2-9√ó faster estimation across scenarios, advantages scaling model complexity Numerical stability: 100% vs.¬†5.5% convergence success extreme distributions, representing qualitative reliability difference Distributional flexibility: Superior accommodation heavy tails hierarchical extensions (Exponentiated Kumaraswamy) Statistical inference: Equivalent coefficient estimates Beta correct; honest standard errors misspecification (15-40% larger, reflecting true uncertainty vs.¬†Beta‚Äôs anti-conservative estimates) Practical applicability: Closed-form CDF enables efficient quantile regression, VaR estimation, probabilistic forecasting findings challenge Beta regression‚Äôs default status bounded-data analysis. Beta regression remains theoretically elegant widely understood, Kumaraswamy-based approaches provide statistically sound computationally superior alternative routine application.","code":""},{"path":"https://evandeilton.github.io/gkwreg/articles/gkwreg-vs-betareg.html","id":"theoretical-implications","dir":"Articles","previous_headings":"Conclusions","what":"Theoretical Implications","title":"Beta Regression vs Kumaraswamy-Based Models for Bounded Data","text":"Kumaraswamy distribution‚Äôs analytical tractability‚Äîspecifically closed-form CDF F(x)=1‚àí(1‚àíxŒ±)Œ≤F(x) = 1-(1-x^Œ±)^Œ≤‚Äîdemonstrates mathematical elegance computational efficiency need sacrificed statistical flexibility. contrasts false dichotomy often assumed ‚Äúsimple fast‚Äù versus ‚Äúcomplex accurate‚Äù models. Generalized Kumaraswamy family‚Äôs hierarchical structure provides principled framework model selection: Beta‚äÇKumaraswamy‚äÇExp. Kumaraswamy‚äÇGen. Kumaraswamy\\text{Beta} \\subset \\text{Kumaraswamy} \\subset \\text{Exp. Kumaraswamy} \\subset \\text{Gen. Kumaraswamy} nesting enables likelihood ratio tests information criteria-based selection, analogous GLMM hierarchy, maintaining computational feasibility throughout.","code":""},{"path":"https://evandeilton.github.io/gkwreg/articles/gkwreg-vs-betareg.html","id":"methodological-contributions","dir":"Articles","previous_headings":"Conclusions","what":"Methodological Contributions","title":"Beta Regression vs Kumaraswamy-Based Models for Bounded Data","text":"study contributes three methodological insights: Standard error inflation misspecification: Documented 15-40% SE underestimation Beta regression non-Beta data, direct implications coverage probability hypothesis test validity Convergence failure predictors: Identified boundary concentration (>30% observations within 0.1 boundaries) critical predictor Beta regression numerical instability Computational scaling laws: Established Kumaraswamy‚Äôs speedup advantage grows model complexity, 2.5√ó simple models 9√ó complex interactions quantitative benchmarks provide practitioners concrete decision rules rather vague guidance.","code":""},{"path":"https://evandeilton.github.io/gkwreg/articles/gkwreg-vs-betareg.html","id":"limitations-and-future-directions","dir":"Articles","previous_headings":"Conclusions","what":"Limitations and Future Directions","title":"Beta Regression vs Kumaraswamy-Based Models for Bounded Data","text":"Several limitations warrant acknowledgment: Sample sizes: Simulations employed moderate sample sizes (n = 300-400); asymptotics large (n > 10,000) small (n < 50) samples require investigation Covariate structures: Simple linear predictors examined; nonlinear effects, smoothing splines, high-dimensional settings deserve attention Missing data: Impact missingness mechanisms (MCAR, MAR, MNAR) relative performance unexplored Bayesian inference: Comparison focused maximum likelihood; MCMC implementations Kumaraswamy models prior sensitivity analysis needed Discrete-continuous mixtures: Zero-inflated one-inflated extensions addressed Future research examine: Asymptotic relative efficiency: Formal Cram√©r-Rao lower bound comparisons correct misspecified models Diagnostic tools: Development residual plots, influence measures, goodness--fit tests specific Kumaraswamy regression Time series extensions: Adaptation longitudinal, panel, time series structures Multivariate generalizations: Joint modeling multiple bounded responses Machine learning integration: Incorporation ensemble methods, boosting, neural networks","code":""},{"path":"https://evandeilton.github.io/gkwreg/articles/gkwreg-vs-betareg.html","id":"recommendations-for-practice","dir":"Articles","previous_headings":"Conclusions","what":"Recommendations for Practice","title":"Beta Regression vs Kumaraswamy-Based Models for Bounded Data","text":"applied researchers analyzing bounded continuous data: Default strategy: Consider Kumaraswamy primary choice exploratory analysis given computational advantages robustness. switch Beta specific theoretical reasons warrant (e.g., maintaining consistency established literature field) Diagnostic protocol: Generate histogram density overlay assess tail behavior Create QQ plot Beta distribution identify departures Calculate proportion observations within 0.1 boundaries diagnostic suggests misspecification, employ Exponentiated Kumaraswamy Inference guidelines: correctly specified models: Beta Kumaraswamy provide equivalent inference misspecified models: Kumaraswamy standard errors accurately reflect uncertainty Always report 95% CIs, just p-values, make precision explicit Computational planning: intensive procedures (cross-validation, bootstrap, permutation tests), 2-9√ó Kumaraswamy speedup transforms feasibility. Budget computational resources accordingly. Reporting standards: Document: distributional family used Convergence diagnostics (models converged? optimization details?) Computational time (reproducibility methods comparison) Model selection criteria (AIC, BIC) across candidate families Software implementation: gkwreg package provides accessible implementation syntax closely paralleling betareg: syntactic similarity facilitates adoption experimentation.","code":"# Beta regression fit_beta <- betareg(y ~ x1 + x2 | z, data = mydata)  # Kumaraswamy regression (drop-in replacement) fit_kw <- gkwreg(y ~ x1 + x2 | z, data = mydata, family = \"kw\")  # Compare AIC(fit_beta, fit_kw)"},{"path":"https://evandeilton.github.io/gkwreg/articles/gkwreg-vs-betareg.html","id":"final-perspective","dir":"Articles","previous_headings":"Conclusions","what":"Final Perspective","title":"Beta Regression vs Kumaraswamy-Based Models for Bounded Data","text":"dominance Beta regression bounded-data analysis reflects historical precedent software availability inherent statistical superiority. study demonstrates Kumaraswamy-based models merely ‚Äúalternatives‚Äù often superior choices across performance dimensions matter practice: reliability, speed, inferential validity. statistical software ecosystems mature computational efficiency becomes increasingly valued (reproducibility, scalability, environmental impact), anticipate growing adoption Kumaraswamy regression de facto standard unit-interval data analysis. transition Beta Kumaraswamy parallels historical shifts normal-based robust methods‚Äîabandoning tradition, embracing better tools available. broader statistical community, work illustrates continued value revisiting foundational methodologies modern computational tools simulation-based evaluation. Distributions introduced decades ago (Kumaraswamy, 1980) may offer unrecognized advantages paired contemporary software algorithmic advances.","code":""},{"path":"https://evandeilton.github.io/gkwreg/articles/gkwreg-vs-betareg.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Beta Regression vs Kumaraswamy-Based Models for Bounded Data","text":"Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation, 81(7), 883-898. Cribari-Neto, F., & Zeileis, . (2010). Beta regression R. Journal Statistical Software, 34(2), 1-24. Ferrari, S. L. P., & Cribari-Neto, F. (2004). Beta regression modelling rates proportions. Journal Applied Statistics, 31(7), 799-815. Kumaraswamy, P. (1980). generalized probability density function double-bounded random processes. Journal Hydrology, 46(1-2), 79-88. Smithson, M., & Verkuilen, J. (2006). better lemon squeezer? Maximum-likelihood regression beta-distributed dependent variables. Psychological Methods, 11(1), 54-71.","code":""},{"path":"https://evandeilton.github.io/gkwreg/articles/gkwreg-vs-betareg.html","id":"session-information","dir":"Articles","previous_headings":"","what":"Session Information","title":"Beta Regression vs Kumaraswamy-Based Models for Bounded Data","text":"","code":"R version 4.5.1 (2025-06-13) Platform: x86_64-pc-linux-gnu Running under: Ubuntu 24.04.3 LTS  Matrix products: default BLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3  LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.26.so;  LAPACK version 3.12.0  locale:  [1] LC_CTYPE=C.UTF-8       LC_NUMERIC=C           LC_TIME=C.UTF-8         [4] LC_COLLATE=C.UTF-8     LC_MONETARY=C.UTF-8    LC_MESSAGES=C.UTF-8     [7] LC_PAPER=C.UTF-8       LC_NAME=C              LC_ADDRESS=C           [10] LC_TELEPHONE=C         LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C     time zone: UTC tzcode source: system (glibc)  attached base packages: [1] stats     graphics  grDevices utils     datasets  methods   base       other attached packages: [1] ggplot2_4.0.0 betareg_3.2-4 gkwreg_2.1.1   loaded via a namespace (and not attached):  [1] sandwich_3.1-1         rappdirs_0.3.3         sass_0.4.10             [4] generics_0.1.4         lattice_0.22-7         digest_0.6.37           [7] magrittr_2.0.4         evaluate_1.0.5         grid_4.5.1             [10] RColorBrewer_1.1-3     fastmap_1.2.0          jsonlite_2.0.0         [13] Matrix_1.7-3           nnet_7.3-20            Formula_1.2-5          [16] scales_1.4.0           codetools_0.2-20       numDeriv_2016.8-1.1    [19] modeltools_0.2-24      textshaping_1.0.4      jquerylib_0.1.4        [22] cli_3.6.5              rlang_1.1.6            withr_3.0.2            [25] RcppArmadillo_15.0.2-2 cachem_1.1.0           yaml_2.3.10            [28] tools_4.5.1            flexmix_2.3-20         dplyr_1.1.4            [31] vctrs_0.6.5            R6_2.6.1               stats4_4.5.1           [34] zoo_1.8-14             lifecycle_1.0.4        fs_1.6.6               [37] ragg_1.5.0             pkgconfig_2.0.3        desc_1.4.3             [40] pkgdown_2.1.3          bslib_0.9.0            pillar_1.11.1          [43] gtable_0.3.6           glue_1.8.0             Rcpp_1.1.0             [46] systemfonts_1.3.1      tidyselect_1.2.1       tibble_3.3.0           [49] xfun_0.53              lmtest_0.9-40          knitr_1.50             [52] farver_2.1.2           htmltools_0.5.8.1      rmarkdown_2.30         [55] gkwdist_1.0.3          TMB_1.9.18             compiler_4.5.1         [58] S7_0.2.0"},{"path":"https://evandeilton.github.io/gkwreg/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Lopes J. E.. Author, maintainer.","code":""},{"path":"https://evandeilton.github.io/gkwreg/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"J. E. L (2025). gkwreg: Generalized Kumaraswamy Regression Models Bounded Data. R package version 2.1.1, https://github.com/evandeilton/gkwreg.","code":"@Manual{,   title = {gkwreg: Generalized Kumaraswamy Regression Models for Bounded Data},   author = {Lopes {J. E.}},   year = {2025},   note = {R package version 2.1.1},   url = {https://github.com/evandeilton/gkwreg}, }"},{"path":[]},{"path":"https://evandeilton.github.io/gkwreg/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Generalized Kumaraswamy Regression Models for Bounded Data","text":"gkwreg package provides comprehensive computationally efficient framework regression modeling data restricted standard unit interval (0, 1), including proportions, rates, fractions, percentages, bounded indices. Beta regression traditional approach data, gkwreg focuses Generalized Kumaraswamy (GKw) distribution family, offering exceptional flexibility encompassing seven important bounded distributions‚Äîincluding Beta Kumaraswamy‚Äîspecial limiting cases. package enables full distributional regression, relevant parameters can modeled functions covariates flexible link functions. Maximum Likelihood estimation performed efficiently via Template Model Builder (TMB) framework, leveraging Automatic Differentiation (AD) superior computational speed, numerical accuracy, optimization stability.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwreg/index.html","id":"id_-flexible-distribution-hierarchy","dir":"","previous_headings":"Key Features","what":"üìä Flexible Distribution Hierarchy","title":"Generalized Kumaraswamy Regression Models for Bounded Data","text":"Model bounded data using 5-parameter Generalized Kumaraswamy (GKw) distribution seven nested subfamilies: family offers distinct flexibility-parsimony tradeoffs. Start simple (kw beta) compare nested models using likelihood ratio tests information criteria.","code":""},{"path":"https://evandeilton.github.io/gkwreg/index.html","id":"id_-advanced-regression-modeling","dir":"","previous_headings":"Key Features","what":"üéØ Advanced Regression Modeling","title":"Generalized Kumaraswamy Regression Models for Bounded Data","text":"Extended formula syntax parameter-specific linear predictors: Example: yield ~ batch + temp | temp | 1 | temp | batch Multiple link functions optional scaling: Positive parameters (Œ±, Œ≤, Œ≥, Œª): log (default), sqrt, inverse, identity Probability parameters (Œ¥ ‚àà (0,1)): logit (default), probit, cloglog, cauchy Link scaling: Control transformation intensity via link_scale (useful numerical stability) Flexible control via gkw_control(): Multiple optimizers: nlminb (default), BFGS, Nelder-Mead, CG, SANN, L-BFGS-B Custom starting values, convergence tolerances, iteration limits Fast fitting mode (disable Hessian computation point estimates ) Debugging tools (verbose output, trace levels)","code":"y ~ alpha_predictors | beta_predictors | gamma_predictors | delta_predictors | lambda_predictors"},{"path":"https://evandeilton.github.io/gkwreg/index.html","id":"id_-computational-efficiency","dir":"","previous_headings":"Key Features","what":"‚ö° Computational Efficiency","title":"Generalized Kumaraswamy Regression Models for Bounded Data","text":"Exact gradients Hessians (machine precision) 10-100√ó faster numerical differentiation Superior convergence stability Intelligent caching intermediate calculations Vectorized operations via Eigen/Armadillo Memory-efficient large datasets (n > 100,000)","code":""},{"path":"https://evandeilton.github.io/gkwreg/index.html","id":"id_-comprehensive-inference-tools","dir":"","previous_headings":"Key Features","what":"üî¨ Comprehensive Inference Tools","title":"Generalized Kumaraswamy Regression Models for Bounded Data","text":"Standard R Methods (familiar workflow): - summary(), print(), coef(), vcov(), confint() - logLik(), AIC(), BIC(), nobs() - fitted(), residuals(), predict() - anova() nested model comparisons Advanced Prediction (predict.gkwreg): - Multiple prediction types: - \"response\": Expected mean E(Y|X) - \"parameter\": parameter values (Œ±, Œ≤, Œ≥, Œ¥, Œª) - \"link\": Linear predictors (inverse link) - \"variance\": Predicted variance Var(Y|X) - \"density\", \"probability\", \"quantile\": Distribution functions specified values - Element-wise vectorized evaluation - Predictions alternative distributional assumptions Model Comparison: - Likelihood ratio tests: anova(), lrtest() - Information criteria: AIC(), BIC() multi-model comparison - Automated nesting detection proper test statistics","code":""},{"path":"https://evandeilton.github.io/gkwreg/index.html","id":"id_-sophisticated-diagnostics","dir":"","previous_headings":"Key Features","what":"üìà Sophisticated Diagnostics","title":"Generalized Kumaraswamy Regression Models for Bounded Data","text":"6 Diagnostic Plot Types (plot.gkwreg): 1. Residuals vs Observation Indices: Detect autocorrelation, temporal patterns 2. Cook‚Äôs Distance: Identify influential observations (threshold: 4/n) 3. Leverage vs Fitted Values: Flag high-leverage points (threshold: 2p/n) 4. Residuals vs Linear Predictor: Check linearity, heteroscedasticity 5. Half-Normal Plot Simulated Envelope: Assess distributional adequacy 6. Predicted vs Observed: Overall goodness--fit Advanced Features: - Dual graphics systems: Base R (fast) ggplot2 (publication-quality) - Multiple residual types: Quantile (default), Pearson, Deviance - Customizable: Named-list interface titles, themes, arrangement - Performance: Automatic sampling large datasets, adjustable envelope simulations - Programmatic access: save_diagnostics = TRUE returns computed measures","code":""},{"path":"https://evandeilton.github.io/gkwreg/index.html","id":"id_-ecosystem-integration","dir":"","previous_headings":"Key Features","what":"üîó Ecosystem Integration","title":"Generalized Kumaraswamy Regression Models for Bounded Data","text":"Density (dgkw, dkw, dbeta, etc.) CDF (pgkw, pkw, pbeta, etc.) Quantile (qgkw, qkw, qbeta, etc.) Random generation (rgkw, rkw, rbeta, etc.) implemented optimized C++ speed broom: tidy(), glance(), augment() methods (available) tidyverse: Works naturally dplyr, ggplot2 pipelines Standard workflows: Model selection, cross-validation, bootstrapping","code":""},{"path":"https://evandeilton.github.io/gkwreg/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Generalized Kumaraswamy Regression Models for Bounded Data","text":"","code":"# Install from CRAN (stable release): install.packages(\"gkwreg\")  # Install companion distribution package: install.packages(\"gkwdist\")  # Or install development versions from GitHub: # install.packages(\"devtools\") devtools::install_github(\"evandeilton/gkwdist\") devtools::install_github(\"evandeilton/gkwreg\")"},{"path":[]},{"path":"https://evandeilton.github.io/gkwreg/index.html","id":"basic-regression","dir":"","previous_headings":"Quick Start","what":"Basic Regression","title":"Generalized Kumaraswamy Regression Models for Bounded Data","text":"","code":"library(gkwreg) library(gkwdist)  # Simulate data set.seed(123) n <- 500 x1 <- runif(n, -2, 2) x2 <- rnorm(n)  # True parameters (log link) alpha_true <- exp(0.8 + 0.3 * x1) beta_true <- exp(1.2 - 0.2 * x2)  # Generate response from Kumaraswamy distribution y <- rkw(n, alpha = alpha_true, beta = beta_true) y <- pmax(pmin(y, 1 - 1e-7), 1e-7) # Ensure strict bounds df <- data.frame(y = y, x1 = x1, x2 = x2)  # Fit Kumaraswamy regression # Formula: alpha ~ x1, beta ~ x2 (intercept-only models also supported) fit_kw <- gkwreg(y ~ x1 | x2, data = df, family = \"kw\")  # View results summary(fit_kw)"},{"path":"https://evandeilton.github.io/gkwreg/index.html","id":"advanced-prediction","dir":"","previous_headings":"Quick Start","what":"Advanced Prediction","title":"Generalized Kumaraswamy Regression Models for Bounded Data","text":"","code":"# Create prediction grid newdata <- data.frame(   x1 = seq(-2, 2, length.out = 100),   x2 = 0 )  # Predict different quantities pred_mean <- predict(fit_kw, newdata, type = \"response\") # E(Y|X) pred_var <- predict(fit_kw, newdata, type = \"variance\") # Var(Y|X) pred_alpha <- predict(fit_kw, newdata, type = \"alpha\") # Œ± parameter pred_params <- predict(fit_kw, newdata, type = \"parameter\") # All parameters  # Evaluate density at y = 0.5 for each observation dens_values <- predict(fit_kw, newdata, type = \"density\", at = 0.5)  # Compute quantiles (10th, 50th, 90th percentiles) quantiles <- predict(fit_kw, newdata,   type = \"quantile\",   at = c(0.1, 0.5, 0.9), elementwise = FALSE )"},{"path":"https://evandeilton.github.io/gkwreg/index.html","id":"model-comparison","dir":"","previous_headings":"Quick Start","what":"Model Comparison","title":"Generalized Kumaraswamy Regression Models for Bounded Data","text":"","code":"# Fit nested models fit0 <- gkwreg(y ~ 1, data = df, family = \"kw\") # Null model fit1 <- gkwreg(y ~ x1, data = df, family = \"kw\") # + x1 fit2 <- gkwreg(y ~ x1 | x2, data = df, family = \"kw\") # + x2 on beta  # Information criteria comparison AIC(fit0, fit1, fit2)  # Likelihood ratio tests anova(fit0, fit1, fit2, test = \"Chisq\")"},{"path":"https://evandeilton.github.io/gkwreg/index.html","id":"diagnostic-plots","dir":"","previous_headings":"Quick Start","what":"Diagnostic Plots","title":"Generalized Kumaraswamy Regression Models for Bounded Data","text":"","code":"# All diagnostic plots (base R graphics) par(mfrow = c(3, 2)) plot(fit_kw, ask = FALSE)  # Select specific plots with customization plot(fit_kw,   which = c(2, 5, 6), # Cook's distance, Half-normal, Pred vs Obs   type = \"quantile\", # Quantile residuals (recommended)   caption = list(     \"2\" = \"Influential Points\",     \"5\" = \"Distributional Check\"   ),   nsim = 200, # More accurate envelope   level = 0.95 ) # 95% confidence  # Modern ggplot2 version with grid arrangement plot(fit_kw,   use_ggplot = TRUE,   arrange_plots = TRUE,   theme_fn = ggplot2::theme_bw )  # Extract diagnostic data for custom analysis diag <- plot(fit_kw, save_diagnostics = TRUE) head(diag$data) # Access Cook's distance, leverage, residuals, etc."},{"path":"https://evandeilton.github.io/gkwreg/index.html","id":"real-data-example","dir":"","previous_headings":"","what":"Real Data Example","title":"Generalized Kumaraswamy Regression Models for Bounded Data","text":"","code":"# Food Expenditure Data (proportion spent on food) data(\"FoodExpenditure\") food <- FoodExpenditure food$prop <- food$food / food$income  # Fit different distributional families fit_beta <- gkwreg(prop ~ income + persons, data = food, family = \"beta\") fit_kw <- gkwreg(prop ~ income + persons, data = food, family = \"kw\") fit_ekw <- gkwreg(prop ~ income + persons, data = food, family = \"ekw\")  # Compare families comparison <- data.frame(   Family = c(\"Beta\", \"Kumaraswamy\", \"Exp. Kumaraswamy\"),   LogLik = c(logLik(fit_beta), logLik(fit_kw), logLik(fit_ekw)),   AIC = c(AIC(fit_beta), AIC(fit_kw), AIC(fit_ekw)),   BIC = c(BIC(fit_beta), BIC(fit_kw), BIC(fit_ekw)) ) print(comparison)  # Visualize best fit best_fit <- fit_kw plot(food$income, food$prop,   xlab = \"Income\", ylab = \"Food Proportion\",   main = \"Food Expenditure Pattern\", pch = 16, col = \"gray40\" ) income_seq <- seq(min(food$income), max(food$income), length = 100) pred_df <- data.frame(income = income_seq, persons = median(food$persons)) lines(income_seq, predict(best_fit, pred_df), col = \"red\", lwd = 2)"},{"path":[]},{"path":"https://evandeilton.github.io/gkwreg/index.html","id":"custom-optimization-control","dir":"","previous_headings":"Advanced Features","what":"Custom Optimization Control","title":"Generalized Kumaraswamy Regression Models for Bounded Data","text":"","code":"library(gkwreg) library(gkwdist)  # Simulate data set.seed(123) n <- 500 x <- runif(n, 1, 5) x1 <- runif(n, -2, 2) x2 <- rnorm(n) x3 <- rnorm(n, 1, 4)  # True parameters (log link) alpha_true <- exp(0.8 + 0.3 * x1) beta_true <- exp(1.2 - 0.2 * x2)  # Generate response from Kumaraswamy distribution y <- rkw(n, alpha = alpha_true, beta = beta_true) y <- pmax(pmin(y, 1 - 1e-7), 1e-7) # Ensure strict bounds df <- data.frame(y = y, x = x, x1 = x1, x2 = x2, x3 = x3)  # Default control (used automatically) fit <- gkwreg(y ~ x1, data = df, family = \"kw\")  # Increase iterations for difficult problems fit_robust <- gkwreg(y ~ x1,   data = df, family = \"kw\",   control = gkw_control(maxit = 1000, trace = 1) )  # Try alternative optimizer fit_bfgs <- gkwreg(y ~ x1,   data = df, family = \"kw\",   control = gkw_control(method = \"BFGS\") )  # Fast fitting without standard errors (exploratory analysis) fit_fast <- gkwreg(y ~ x1,   data = df, family = \"kw\",   control = gkw_control(hessian = FALSE) )  # Custom starting values fit_custom <- gkwreg(y ~ x1 + x2 | x3,   data = df, family = \"kw\",   control = gkw_control(     start = list(       alpha = c(0.5, 0.2, -0.1), # Intercept + 2 slopes       beta  = c(1.0, 0.3) # Intercept + 1 slope     )   ) )"},{"path":"https://evandeilton.github.io/gkwreg/index.html","id":"link-functions-and-scaling","dir":"","previous_headings":"Advanced Features","what":"Link Functions and Scaling","title":"Generalized Kumaraswamy Regression Models for Bounded Data","text":"","code":"# Default: log link for all parameters fit_default <- gkwreg(y ~ x | x, data = df, family = \"kw\")  # Custom link functions per parameter fit_links <- gkwreg(y ~ x | x,   data = df, family = \"kw\",   link = list(alpha = \"sqrt\", beta = \"log\") )  # Link scaling (control transformation intensity) # Larger scale = gentler transformation, smaller = steeper fit_scaled <- gkwreg(y ~ x | x,   data = df, family = \"kw\",   link_scale = list(alpha = 5, beta = 15) )"},{"path":"https://evandeilton.github.io/gkwreg/index.html","id":"working-with-large-datasets","dir":"","previous_headings":"Advanced Features","what":"Working with Large Datasets","title":"Generalized Kumaraswamy Regression Models for Bounded Data","text":"","code":"# Large dataset example set.seed(456) n_large <- 100000 x_large <- rnorm(n_large) y_large <- rkw(n_large, alpha = exp(0.5 + 0.2 * x_large), beta = exp(1.0)) df_large <- data.frame(y = y_large, x = x_large)  # Fast fitting fit_large <- gkwreg(y ~ x,   data = df_large, family = \"kw\",   control = gkw_control(hessian = FALSE) )  # Diagnostic plots with sampling (much faster) plot(fit_large,   which = c(1, 2, 4, 6), # Skip computationally intensive plot 5   sample_size = 5000 ) # Use random sample of 5000 obs"},{"path":[]},{"path":"https://evandeilton.github.io/gkwreg/index.html","id":"the-generalized-kumaraswamy-distribution","dir":"","previous_headings":"Mathematical Background","what":"The Generalized Kumaraswamy Distribution","title":"Generalized Kumaraswamy Regression Models for Bounded Data","text":"GKw distribution five-parameter family variables (0, 1) cumulative distribution function: F(x;Œ±,Œ≤,Œ≥,Œ¥,Œª)=[1‚àí(1‚àíxŒ±)Œ≤]Œª(Œ≥,Œ¥)F(x; \\alpha, \\beta, \\gamma, \\delta, \\lambda) = I_{[1-(1-x^{\\alpha})^{\\beta}]^{\\lambda}}(\\gamma, \\delta) Iz(,b)I_z(,b) regularized incomplete beta function. probability density function : f(x;Œ±,Œ≤,Œ≥,Œ¥,Œª)=ŒªŒ±Œ≤xŒ±‚àí1B(Œ≥,Œ¥)(1‚àíxŒ±)Œ≤‚àí1[1‚àí(1‚àíxŒ±)Œ≤]Œ≥Œª‚àí1{1‚àí[1‚àí(1‚àíxŒ±)Œ≤]Œª}Œ¥‚àí1f(x; \\alpha, \\beta, \\gamma, \\delta, \\lambda) = \\frac{\\lambda \\alpha \\beta x^{\\alpha-1}}{B(\\gamma, \\delta)} (1-x^{\\alpha})^{\\beta-1} [1-(1-x^{\\alpha})^{\\beta}]^{\\gamma\\lambda-1} \\{1-[1-(1-x^{\\alpha})^{\\beta}]^{\\lambda}\\}^{\\delta-1} Parameter Roles: - Œ±, Œ≤: Control basic shape (inherited Kumaraswamy) - Œ≥, Œ¥: Govern tail behavior concentration - Œª: Additional flexibility skewness peaks parameterization captures diverse shapes: symmetric, skewed, unimodal, bimodal, J-shaped, U-shaped, bathtub-shaped.","code":""},{"path":"https://evandeilton.github.io/gkwreg/index.html","id":"regression-framework","dir":"","previous_headings":"Mathematical Background","what":"Regression Framework","title":"Generalized Kumaraswamy Regression Models for Bounded Data","text":"response yi‚àà(0,1)y_i \\(0,1) following GKw family distribution, parameter Œ∏ip‚àà{Œ±i,Œ≤i,Œ≥i,Œ¥i,Œªi}\\theta_{ip} \\\\{\\alpha_i, \\beta_i, \\gamma_i, \\delta_i, \\lambda_i\\} depends covariates via link functions: gp(Œ∏ip)=Œ∑ip=ùê±ip‚ä§ùõÉpg_p(\\theta_{ip}) = \\eta_{ip} = \\mathbf{x}_{ip}^\\top \\boldsymbol{\\beta}_p Maximum likelihood estimation maximizes: ‚Ñì(Œò;ùê≤,ùêó)=‚àë=1nlogf(yi;Œ∏i(Œò))\\ell(\\Theta; \\mathbf{y}, \\mathbf{X}) = \\sum_{=1}^{n} \\log f(y_i; \\theta_i(\\Theta)) TMB computes exact gradients ‚àá‚Ñì\\nabla \\ell Hessian ùêá\\mathbf{H} via automatic differentiation, enabling fast stable optimization.","code":""},{"path":"https://evandeilton.github.io/gkwreg/index.html","id":"computational-engine-tmb","dir":"","previous_headings":"","what":"Computational Engine: TMB","title":"Generalized Kumaraswamy Regression Models for Bounded Data","text":"Template Model Builder (TMB) translates statistical models optimized C++ code automatic differentiation: Advantages: - Speed: 10-100√ó faster numerical differentiation - Accuracy: Machine-precision derivatives (< 1e-15 relative error) - Stability: Exact Hessian improves convergence reliability - Scalability: Efficient large n many parameters Hood:","code":"R Formula ‚Üí TMB C++ Template ‚Üí Automatic Differentiation ‚Üí  Compiled Object ‚Üí Fast Optimization (nlminb/optim) ‚Üí  Standard Errors (Hessian inversion)"},{"path":"https://evandeilton.github.io/gkwreg/index.html","id":"comparison-with-other-packages","dir":"","previous_headings":"","what":"Comparison with Other Packages","title":"Generalized Kumaraswamy Regression Models for Bounded Data","text":"use gkwreg: ‚úÖ Need flexible bounded distributions beyond Beta ‚úÖ Large datasets requiring fast computation ‚úÖ parameters depend covariates ‚úÖ Frequentist inference preferred ‚úÖ Standard R workflow integration consider alternatives: Random/mixed effects needed ‚Üí gamlss, brms Bayesian inference required ‚Üí brms Beta distribution sufficient ‚Üí betareg (simpler)","code":""},{"path":"https://evandeilton.github.io/gkwreg/index.html","id":"documentation-and-support","dir":"","previous_headings":"","what":"Documentation and Support","title":"Generalized Kumaraswamy Regression Models for Bounded Data","text":"Reference Manual: help(package = \"gkwreg\") Vignettes: browseVignettes(\"gkwreg\") Function Help: ?gkwreg, ?predict.gkwreg, ?plot.gkwreg, ?gkw_control GitHub Issues: Report bugs request features Examples: See examples/ directory package source","code":""},{"path":"https://evandeilton.github.io/gkwreg/index.html","id":"references","dir":"","previous_headings":"","what":"References","title":"Generalized Kumaraswamy Regression Models for Bounded Data","text":"Primary References: Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation, 81(7), 883-898. DOI: 10.1080/00949650903530745 Kumaraswamy, P. (1980). generalized probability density function double-bounded random processes. Journal Hydrology, 46(1-2), 79-88. DOI: 10.1016/0022-1694(80)90036-0 TMB Framework: Kristensen, K., Nielsen, ., Berg, C. W., Skaug, H., & Bell, B. M. (2016). TMB: Automatic Differentiation Laplace Approximation. Journal Statistical Software, 70(5), 1-21. DOI: 10.18637/jss.v070.i05 Related Distributions: Jones, M. C. (2009). Kumaraswamy‚Äôs distribution: beta-type distribution tractability advantages. Statistical Methodology, 6(1), 70-81. DOI: 10.1016/j.stamet.2008.04.001 Carrasco, J. M. F., Ferrari, S. L. P., & Cordeiro, G. M. (2010). new generalized Kumaraswamy distribution. arXiv preprint arXiv:1004.0911. Beta Regression: Ferrari, S. L. P., & Cribari-Neto, F. (2004). Beta regression modelling rates proportions. Journal Applied Statistics, 31(7), 799-815. DOI: 10.1080/0266476042000214501 Cribari-Neto, F., & Zeileis, . (2010). Beta Regression R. Journal Statistical Software, 34(2), 1-24. DOI: 10.18637/jss.v034.i02","code":""},{"path":"https://evandeilton.github.io/gkwreg/index.html","id":"contributing","dir":"","previous_headings":"","what":"Contributing","title":"Generalized Kumaraswamy Regression Models for Bounded Data","text":"Contributions welcome! Ways contribute: üêõ Report bugs: GitHub Issues üí° Suggest features: Open feature request issue üìù Improve documentation: Submit pull requests typos, clarifications üî¨ Add examples: Share use cases research üß™ Extend functionality: Propose new methods families Development Workflow: 1. Fork repository 2. Create feature branch (git checkout -b feature/amazing-feature) 3. Commit changes (git commit -m 'Add amazing feature') 4. Push branch (git push origin feature/amazing-feature) 5. Open Pull Request","code":""},{"path":"https://evandeilton.github.io/gkwreg/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Generalized Kumaraswamy Regression Models for Bounded Data","text":"use gkwreg research, please cite:","code":"citation(\"gkwreg\") To cite package ‚Äògkwreg‚Äô in publications use:    J. E. L (2025). _gkwreg: Generalized Kumaraswamy Regression Models for Bounded Data_. R package version 2.0.0,   <https://github.com/evandeilton/gkwreg>.  A BibTeX entry for LaTeX users is    @Manual{,     title = {gkwreg: Generalized Kumaraswamy Regression Models for Bounded Data},     author = {Lopes, {J. E.}},     year = {2025},     note = {R package version 2.0.0},     url = {https://github.com/evandeilton/gkwreg},   }"},{"path":"https://evandeilton.github.io/gkwreg/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"Generalized Kumaraswamy Regression Models for Bounded Data","text":"package licensed MIT License. See LICENSE file details.","code":""},{"path":"https://evandeilton.github.io/gkwreg/index.html","id":"author-and-maintainer","dir":"","previous_headings":"","what":"Author and Maintainer","title":"Generalized Kumaraswamy Regression Models for Bounded Data","text":"Lopes, J. E. üìß evandeilton@gmail.com üèõÔ∏è LEG - Laborat√≥rio de Estat√≠stica e Geoinforma√ß√£o üéì UFPR - Universidade Federal Paran√°, Brazil üîó GitHub | ORCID","code":""},{"path":"https://evandeilton.github.io/gkwreg/index.html","id":"acknowledgments","dir":"","previous_headings":"","what":"Acknowledgments","title":"Generalized Kumaraswamy Regression Models for Bounded Data","text":"TMB Development Team outstanding computational framework betareg gamlss authors inspiration design patterns R Core Team R language ecosystem Contributors users providing feedback bug reports Happy Modeling! üìä‚ú®","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/AIC.gkwreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Akaike Information Criterion for GKw Regression Models ‚Äî AIC.gkwreg","title":"Akaike Information Criterion for GKw Regression Models ‚Äî AIC.gkwreg","text":"Calculates Akaike Information Criterion (AIC) fitted Generalized Kumaraswamy regression models.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/AIC.gkwreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Akaike Information Criterion for GKw Regression Models ‚Äî AIC.gkwreg","text":"","code":"# S3 method for class 'gkwreg' AIC(object, ..., k = 2)"},{"path":"https://evandeilton.github.io/gkwreg/reference/AIC.gkwreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Akaike Information Criterion for GKw Regression Models ‚Äî AIC.gkwreg","text":"object object class \"gkwreg\", typically obtained gkwreg. ... Optionally fitted model objects. k Numeric, penalty per parameter. Default k = 2 classical AIC. Setting k = log(n) gives BIC-equivalent penalty.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/AIC.gkwreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Akaike Information Criterion for GKw Regression Models ‚Äî AIC.gkwreg","text":"one object provided, returns numeric value AIC. multiple objects provided, returns data frame columns df AIC, rows named according object names call.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/AIC.gkwreg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Akaike Information Criterion for GKw Regression Models ‚Äî AIC.gkwreg","text":"AIC computed : $$AIC = -2\\ell(\\hat{\\theta}) + k \\cdot p$$ \\(\\ell(\\hat{\\theta})\\) maximized log-likelihood \\(p\\) number estimated parameters. multiple objects provided, data frame comparing models returned. Lower AIC values indicate better models, balancing goodness--fit model complexity. small sample sizes, consider corrected AIC (AICc): $$AICc = AIC + \\frac{2p(p+1)}{n-p-1}$$ \\(n\\) sample size. correction automatically applied can calculated manually.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/AIC.gkwreg.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Akaike Information Criterion for GKw Regression Models ‚Äî AIC.gkwreg","text":"Akaike, H. (1974). new look statistical model identification. IEEE Transactions Automatic Control, 19(6), 716‚Äì723. doi:10.1109/TAC.1974.1100705 Burnham, K. P., & Anderson, D. R. (2004). Multimodel inference: Understanding AIC BIC model selection. Sociological Methods & Research, 33(2), 261‚Äì304. doi:10.1177/0049124104268644","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwreg/reference/AIC.gkwreg.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Akaike Information Criterion for GKw Regression Models ‚Äî AIC.gkwreg","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/AIC.gkwreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Akaike Information Criterion for GKw Regression Models ‚Äî AIC.gkwreg","text":"","code":"# \\donttest{ # Load example data data(GasolineYield)  # Fit competing models fit1 <- gkwreg(yield ~ batch, data = GasolineYield, family = \"kw\") fit2 <- gkwreg(yield ~ batch + temp, data = GasolineYield, family = \"kw\") #> Warning: NaNs produced fit3 <- gkwreg(yield ~ temp, data = GasolineYield, family = \"kw\")  # Calculate AIC for single model AIC(fit1) #> [1] -42.93436  # Compare multiple models (with proper names) AIC(fit1, fit2, fit3) #>      df        AIC #> fit1 11  -42.93436 #> fit2 12 -169.93784 #> fit3  3  -74.90259  # Use different penalty AIC(fit1, k = 4) #> [1] -20.93436 # }"},{"path":"https://evandeilton.github.io/gkwreg/reference/BIC.gkwreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Bayesian Information Criterion for GKw Regression Models ‚Äî BIC.gkwreg","title":"Bayesian Information Criterion for GKw Regression Models ‚Äî BIC.gkwreg","text":"Calculates Bayesian Information Criterion (BIC), also known Schwarz Information Criterion (SIC), fitted Generalized Kumaraswamy regression models.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/BIC.gkwreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bayesian Information Criterion for GKw Regression Models ‚Äî BIC.gkwreg","text":"","code":"# S3 method for class 'gkwreg' BIC(object, ...)"},{"path":"https://evandeilton.github.io/gkwreg/reference/BIC.gkwreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bayesian Information Criterion for GKw Regression Models ‚Äî BIC.gkwreg","text":"object object class \"gkwreg\", typically obtained gkwreg. ... Optionally fitted model objects.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/BIC.gkwreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bayesian Information Criterion for GKw Regression Models ‚Äî BIC.gkwreg","text":"one object provided, returns numeric value BIC. multiple objects provided, returns data frame columns df BIC, rows named according object names call.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/BIC.gkwreg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bayesian Information Criterion for GKw Regression Models ‚Äî BIC.gkwreg","text":"BIC computed : $$BIC = -2\\ell(\\hat{\\theta}) + p \\cdot \\log(n)$$ \\(\\ell(\\hat{\\theta})\\) maximized log-likelihood, \\(p\\) number estimated parameters, \\(n\\) sample size. multiple objects provided, data frame comparing models returned. Lower BIC values indicate better models. BIC penalizes model complexity heavily AIC, particularly large samples, tends favor parsimonious models. BIC can derived Bayesian perspective approximation logarithm Bayes factor, certain regularity conditions assuming uniform priors.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/BIC.gkwreg.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Bayesian Information Criterion for GKw Regression Models ‚Äî BIC.gkwreg","text":"Schwarz, G. (1978). Estimating dimension model. Annals Statistics, 6(2), 461‚Äì464. doi:10.1214/aos/1176344136","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwreg/reference/BIC.gkwreg.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Bayesian Information Criterion for GKw Regression Models ‚Äî BIC.gkwreg","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/BIC.gkwreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bayesian Information Criterion for GKw Regression Models ‚Äî BIC.gkwreg","text":"","code":"# \\donttest{ # Load example data data(GasolineYield)  # Fit competing models fit1 <- gkwreg(yield ~ batch, data = GasolineYield, family = \"kw\") fit2 <- gkwreg(yield ~ batch + temp, data = GasolineYield, family = \"kw\") #> Warning: NaNs produced fit3 <- gkwreg(yield ~ temp, data = GasolineYield, family = \"kw\")  # Calculate BIC for single model BIC(fit1) #> [1] -26.81126  # Compare multiple models (with proper names) BIC(fit1, fit2, fit3) #>      df        BIC #> fit1 11  -26.81126 #> fit2 12 -152.34901 #> fit3  3  -70.50538 # }"},{"path":"https://evandeilton.github.io/gkwreg/reference/CarTask.html","id":null,"dir":"Reference","previous_headings":"","what":"Partition-Primed Probability Judgement Task for Car Dealership ‚Äî CarTask","title":"Partition-Primed Probability Judgement Task for Car Dealership ‚Äî CarTask","text":"Data cognitive experiment examining partition priming affects probability judgments car dealership context. Participants judged probabilities different framing conditions.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/CarTask.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Partition-Primed Probability Judgement Task for Car Dealership ‚Äî CarTask","text":"","code":"CarTask"},{"path":"https://evandeilton.github.io/gkwreg/reference/CarTask.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Partition-Primed Probability Judgement Task for Car Dealership ‚Äî CarTask","text":"data frame 155 observations 3 variables: probability numeric. Estimated probability (response variable). task factor levels Car Salesperson indicating condition/question type. NFCCscale numeric. Combined score Need Closure (NFC) Need Certainty (NCC) scales, strongly correlated.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/CarTask.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Partition-Primed Probability Judgement Task for Car Dealership ‚Äî CarTask","text":"Taken Smithson et al. (2011) supplements.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/CarTask.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Partition-Primed Probability Judgement Task for Car Dealership ‚Äî CarTask","text":"participants study undergraduate students Australian National University, obtained course credit first-year Psychology participation. Task questions: Car condition: \"probability customer trades coupe?\" Salesperson condition: \"probability customer buys car Carlos?\" (four possible salespersons) key manipulation implicit partition: Car condition, multiple car types (binary: coupe vs. coupe), Salesperson condition, four specific salespersons. Classical findings suggest different partition structures lead different probability estimates even actual probabilities equivalent. NFCC scale (Need Closure Certainty) measures individual differences tolerance ambiguity. Higher scores indicate greater need definitive answers discomfort uncertainty.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/CarTask.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Partition-Primed Probability Judgement Task for Car Dealership ‚Äî CarTask","text":"Smithson, M., Merkle, E.C., Verkuilen, J. (2011). Beta Regression Finite Mixture Models Polarization Priming. Journal Educational Behavioral Statistics, 36(6), 804‚Äì831. doi:10.3102/1076998610396893 Smithson, M., Segale, C. (2009). Partition Priming Judgments Imprecise Probabilities. Journal Statistical Theory Practice, 3(1), 169‚Äì181.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/CarTask.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Partition-Primed Probability Judgement Task for Car Dealership ‚Äî CarTask","text":"","code":"# \\donttest{ require(gkwreg) require(gkwdist) #> Loading required package: gkwdist  data(CarTask)  # Example 1: Task effects on probability judgments # Do people judge probabilities differently for car vs. salesperson? fit_kw <- gkwreg(   probability ~ task,   data = CarTask,   family = \"kw\" ) summary(fit_kw) #>  #> Generalized Kumaraswamy Regression Model Summary #>  #> Family: kw  #>  #> Call: #> gkwreg(formula = probability ~ task, data = CarTask, family = \"kw\") #>  #> Residuals: #>     Min  Q1.25%  Median    Mean  Q3.75%     Max  #> -0.3274 -0.1604 -0.0233 -0.0182  0.0726  0.6057  #>  #> Coefficients: #>                       Estimate Std. Error z value Pr(>|z|)     #> alpha:(Intercept)      0.59548    0.09165   6.498 8.16e-11 *** #> alpha:taskSalesperson -0.11015    0.10146  -1.086    0.278     #> beta:(Intercept)       1.09659    0.12178   9.004  < 2e-16 *** #> --- #> Signif. codes:  0 ‚Äò***‚Äô 0.001 ‚Äò**‚Äô 0.01 ‚Äò*‚Äô 0.05 ‚Äò.‚Äô 0.1 ‚Äò ‚Äô 1 #>  #> Confidence intervals (95%): #>                            3%    98% #> alpha:(Intercept)      0.4159 0.7751 #> alpha:taskSalesperson -0.3090 0.0887 #> beta:(Intercept)       0.8579 1.3353 #>  #> Link functions: #> alpha: log #> beta: log #>  #> Fitted parameter means: #> alpha: 1.72 #> beta: 2.991 #> gamma: 1 #> delta: 0 #> lambda: 1 #>  #> Model fit statistics: #> Number of observations: 155  #> Number of parameters: 3  #> Residual degrees of freedom: 152  #> Log-likelihood: 34.76  #> AIC: -63.52  #> BIC: -54.39  #> RMSE: 0.1812  #> Efron's R2: -0.002858  #> Mean Absolute Error: 0.1485  #>  #> Convergence status: Successful  #> Iterations: 14  #>   # Interpretation: # - Alpha: Task type affects mean probability estimate #   Salesperson condition (1/4 = 0.25) vs. car type (unclear baseline)  # Example 2: Individual differences model # Need for Closure/Certainty may moderate probability judgments fit_kw_nfcc <- gkwreg(   probability ~ task * NFCCscale |     task,   data = CarTask,   family = \"kw\" ) summary(fit_kw_nfcc) #>  #> Generalized Kumaraswamy Regression Model Summary #>  #> Family: kw  #>  #> Call: #> gkwreg(formula = probability ~ task * NFCCscale | task, data = CarTask,  #>     family = \"kw\") #>  #> Residuals: #>     Min  Q1.25%  Median    Mean  Q3.75%     Max  #> -0.3059 -0.1553 -0.0094 -0.0183  0.0915  0.5954  #>  #> Coefficients: #>                                 Estimate Std. Error z value Pr(>|z|)     #> alpha:(Intercept)                 0.0106     0.4239   0.025   0.9801     #> alpha:taskSalesperson             0.4263     0.7016   0.608   0.5434     #> alpha:NFCCscale                   0.2272     0.1232   1.845   0.0651 .   #> alpha:taskSalesperson:NFCCscale  -0.2456     0.2011  -1.221   0.2220     #> beta:(Intercept)                  1.4714     0.1864   7.892 2.97e-15 *** #> beta:taskSalesperson             -0.6039     0.2487  -2.428   0.0152 *   #> --- #> Signif. codes:  0 ‚Äò***‚Äô 0.001 ‚Äò**‚Äô 0.01 ‚Äò*‚Äô 0.05 ‚Äò.‚Äô 0.1 ‚Äò ‚Äô 1 #>  #> Confidence intervals (95%): #>                                      3%     98% #> alpha:(Intercept)               -0.8202  0.8414 #> alpha:taskSalesperson           -0.9489  1.8015 #> alpha:NFCCscale                 -0.0142  0.4687 #> alpha:taskSalesperson:NFCCscale -0.6397  0.1486 #> beta:(Intercept)                 1.1060  1.8368 #> beta:taskSalesperson            -1.0915 -0.1164 #>  #> Link functions: #> alpha: log #> beta: log #>  #> Fitted parameter means: #> alpha: 1.815 #> beta: 3.373 #> gamma: 1 #> delta: 0 #> lambda: 1 #>  #> Model fit statistics: #> Number of observations: 155  #> Number of parameters: 6  #> Residual degrees of freedom: 149  #> Log-likelihood: 38.98  #> AIC: -65.96  #> BIC: -47.7  #> RMSE: 0.1795  #> Efron's R2: 0.01639  #> Mean Absolute Error: 0.1467  #>  #> Convergence status: Successful  #> Iterations: 21  #>   # Interpretation: # - Interaction: NFCC may have different effects depending on task #   People high in need for certainty may respond differently to #   explicit partitions (4 salespersons) vs. implicit partitions (car types) # - Beta: Precision varies by task type  # Example 3: Exponentiated Kumaraswamy for extreme estimates # Some participants may give very extreme probability estimates fit_ekw <- gkwreg(   probability ~ task * NFCCscale | # alpha     task | # beta     task, # lambda: extremity differs by task   data = CarTask,   family = \"ekw\" ) #> Warning: NaNs produced summary(fit_ekw) #>  #> Generalized Kumaraswamy Regression Model Summary #>  #> Family: ekw  #>  #> Call: #> gkwreg(formula = probability ~ task * NFCCscale | task | task,  #>     data = CarTask, family = \"ekw\") #>  #> Residuals: #>     Min  Q1.25%  Median    Mean  Q3.75%     Max  #> -0.4728 -0.0728  0.0999  0.1040  0.3235  0.9989  #>  #> Coefficients: #>                                  Estimate Std. Error z value Pr(>|z|)     #> alpha:(Intercept)               -13.13564    0.21825 -60.186  < 2e-16 *** #> alpha:taskSalesperson           -10.49121    0.22878 -45.857  < 2e-16 *** #> alpha:NFCCscale                   0.22818    0.04907   4.650 3.32e-06 *** #> alpha:taskSalesperson:NFCCscale  -0.30671    0.05122  -5.988 2.12e-09 *** #> beta:(Intercept)                  0.81773        NaN     NaN      NaN     #> beta:taskSalesperson             -0.16489        NaN     NaN      NaN     #> lambda:(Intercept)               29.27821        NaN     NaN      NaN     #> lambda:taskSalesperson           20.61126        NaN     NaN      NaN     #> --- #> Signif. codes:  0 ‚Äò***‚Äô 0.001 ‚Äò**‚Äô 0.01 ‚Äò*‚Äô 0.05 ‚Äò.‚Äô 0.1 ‚Äò ‚Äô 1 #>  #> Confidence intervals (95%): #>                                       3%      98% #> alpha:(Intercept)               -13.5634 -12.7079 #> alpha:taskSalesperson           -10.9396 -10.0428 #> alpha:NFCCscale                   0.1320   0.3244 #> alpha:taskSalesperson:NFCCscale  -0.4071  -0.2063 #> beta:(Intercept)                     NaN      NaN #> beta:taskSalesperson                 NaN      NaN #> lambda:(Intercept)                   NaN      NaN #> lambda:taskSalesperson               NaN      NaN #>  #> Link functions: #> alpha: log #> beta: log #> lambda: log #>  #> Fitted parameter means: #> alpha: 2.142e-06 #> beta: 2.094 #> gamma: 1 #> delta: 0 #> lambda: 2.304e+21 #>  #> Model fit statistics: #> Number of observations: 155  #> Number of parameters: 8  #> Residual degrees of freedom: 147  #> Log-likelihood: 327.3  #> AIC: -638.6  #> BIC: -614.3  #> RMSE: 0.3416  #> Efron's R2: -2.563  #> Mean Absolute Error: 0.2827  #>  #> Convergence status: Failed  #> Iterations: 61  #>   # Interpretation: # - Lambda varies by task: Salesperson condition (explicit partition) #   may produce more extreme estimates (closer to 0 or 1)  # Visualization: Probability by task and NFCC plot(probability ~ NFCCscale,   data = CarTask,   col = c(\"blue\", \"red\")[task], pch = 19,   xlab = \"Need for Closure/Certainty\", ylab = \"Probability Estimate\",   main = \"Car Task: Individual Differences in Probability Judgment\" ) legend(\"topright\",   legend = levels(CarTask$task),   col = c(\"blue\", \"red\"), pch = 19 )   # Distribution comparison boxplot(probability ~ task,   data = CarTask,   xlab = \"Task Condition\", ylab = \"Probability Estimate\",   main = \"Partition Priming Effects\",   col = c(\"lightblue\", \"lightcoral\") ) abline(h = 0.25, lty = 2, col = \"gray\") text(1.5, 0.27, \"Uniform (1/4)\", col = \"gray\")  # }"},{"path":"https://evandeilton.github.io/gkwreg/reference/FoodExpenditure.html","id":null,"dir":"Reference","previous_headings":"","what":"Proportion of Household Income Spent on Food ‚Äî FoodExpenditure","title":"Proportion of Household Income Spent on Food ‚Äî FoodExpenditure","text":"Cross-section data annual food expenditure annual income random sample households large U.S. city. dataset models proportion income spent food function total income household size.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/FoodExpenditure.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Proportion of Household Income Spent on Food ‚Äî FoodExpenditure","text":"","code":"FoodExpenditure"},{"path":"https://evandeilton.github.io/gkwreg/reference/FoodExpenditure.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Proportion of Household Income Spent on Food ‚Äî FoodExpenditure","text":"data frame 38 observations 3 variables: food numeric. Annual food expenditure U.S. dollars. income numeric. Annual household income U.S. dollars. persons numeric. Number persons household.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/FoodExpenditure.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Proportion of Household Income Spent on Food ‚Äî FoodExpenditure","text":"Taken Griffiths et al. (1993, Table 15.4).","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/FoodExpenditure.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Proportion of Household Income Spent on Food ‚Äî FoodExpenditure","text":"classic econometric dataset taken Griffiths et al. (1993, Table 15.4) cite Leser (1963) original source. data used model Engel curves, describe household expenditure particular good service varies household income. response variable interest typically food/income, proportion income spent food, follows beta distribution properties bounded 0 1.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/FoodExpenditure.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Proportion of Household Income Spent on Food ‚Äî FoodExpenditure","text":"Cribari-Neto, F., Zeileis, . (2010). Beta Regression R. Journal Statistical Software, 34(2), 1‚Äì24. doi:10.18637/jss.v034.i02 Ferrari, S.L.P., Cribari-Neto, F. (2004). Beta Regression Modeling Rates Proportions. Journal Applied Statistics, 31(7), 799‚Äì815. Griffiths, W.E., Hill, R.C., Judge, G.G. (1993). Learning Practicing Econometrics. New York: John Wiley Sons. Leser, C.E.V. (1963). Forms Engel Functions. Econometrica, 31(4), 694‚Äì703.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/FoodExpenditure.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Proportion of Household Income Spent on Food ‚Äî FoodExpenditure","text":"","code":"# \\donttest{ require(gkwreg) require(gkwdist)  data(FoodExpenditure) FoodExpenditure$prop <- FoodExpenditure$food / FoodExpenditure$income  # Example 1: Basic Kumaraswamy regression # Proportion spent on food decreases with income (Engel's law) # Larger households spend more on food fit_kw <- gkwreg(prop ~ income + persons,   data = FoodExpenditure,   family = \"kw\" ) summary(fit_kw) #>  #> Generalized Kumaraswamy Regression Model Summary #>  #> Family: kw  #>  #> Call: #> gkwreg(formula = prop ~ income + persons, data = FoodExpenditure,  #>     family = \"kw\") #>  #> Residuals: #>     Min  Q1.25%  Median    Mean  Q3.75%     Max  #> -0.1636 -0.0376  0.0095 -0.0022  0.0480  0.1458  #>  #> Coefficients: #>                    Estimate Std. Error z value Pr(>|z|)     #> alpha:(Intercept)  1.622786   0.177013   9.168  < 2e-16 *** #> alpha:income      -0.007130   0.001623  -4.393 1.12e-05 *** #> alpha:persons      0.083647   0.019204   4.356 1.33e-05 *** #> beta:(Intercept)   5.162036   0.658351   7.841 4.47e-15 *** #> --- #> Signif. codes:  0 ‚Äò***‚Äô 0.001 ‚Äò**‚Äô 0.01 ‚Äò*‚Äô 0.05 ‚Äò.‚Äô 0.1 ‚Äò ‚Äô 1 #>  #> Confidence intervals (95%): #>                        3%     98% #> alpha:(Intercept)  1.2758  1.9697 #> alpha:income      -0.0103 -0.0039 #> alpha:persons      0.0460  0.1213 #> beta:(Intercept)   3.8717  6.4524 #>  #> Link functions: #> alpha: log #> beta: log #>  #> Fitted parameter means: #> alpha: 4.598 #> beta: 174.3 #> gamma: 1 #> delta: 0 #> lambda: 1 #>  #> Model fit statistics: #> Number of observations: 38  #> Number of parameters: 4  #> Residual degrees of freedom: 34  #> Log-likelihood: 45.77  #> AIC: -83.54  #> BIC: -76.99  #> RMSE: 0.07455  #> Efron's R2: 0.4446  #> Mean Absolute Error: 0.05842  #>  #> Convergence status: Successful  #> Iterations: 17  #>   # Interpretation: # - Alpha: Negative income effect (Engel's law) #   Positive household size effect # - Beta: Constant precision (homoscedastic model)  # Example 2: Heteroscedastic model # Variability in food proportion may differ by income and household size fit_kw_hetero <- gkwreg(   prop ~ income + persons |     income + persons,   data = FoodExpenditure,   family = \"kw\" ) summary(fit_kw_hetero) #>  #> Generalized Kumaraswamy Regression Model Summary #>  #> Family: kw  #>  #> Call: #> gkwreg(formula = prop ~ income + persons | income + persons,  #>     data = FoodExpenditure, family = \"kw\") #>  #> Residuals: #>     Min  Q1.25%  Median    Mean  Q3.75%     Max  #> -0.1736 -0.0356  0.0125  0.0002  0.0382  0.1546  #>  #> Coefficients: #>                    Estimate Std. Error z value Pr(>|z|)     #> alpha:(Intercept)  1.891196   0.326327   5.795 6.82e-09 *** #> alpha:income       0.001421   0.004482   0.317 0.751221     #> alpha:persons     -0.090024   0.045650  -1.972 0.048604 *   #> beta:(Intercept)   7.500712   2.073678   3.617 0.000298 *** #> beta:income        0.042825   0.030398   1.409 0.158900     #> beta:persons      -1.017206   0.291303  -3.492 0.000480 *** #> --- #> Signif. codes:  0 ‚Äò***‚Äô 0.001 ‚Äò**‚Äô 0.01 ‚Äò*‚Äô 0.05 ‚Äò.‚Äô 0.1 ‚Äò ‚Äô 1 #>  #> Confidence intervals (95%): #>                        3%     98% #> alpha:(Intercept)  1.2516  2.5308 #> alpha:income      -0.0074  0.0102 #> alpha:persons     -0.1795 -0.0006 #> beta:(Intercept)   3.4364 11.5650 #> beta:income       -0.0168  0.1024 #> beta:persons      -1.5882 -0.4463 #>  #> Link functions: #> alpha: log #> beta: log #>  #> Fitted parameter means: #> alpha: 5.28 #> beta: 2782 #> gamma: 1 #> delta: 0 #> lambda: 1 #>  #> Model fit statistics: #> Number of observations: 38  #> Number of parameters: 6  #> Residual degrees of freedom: 32  #> Log-likelihood: 51.68  #> AIC: -91.36  #> BIC: -81.54  #> RMSE: 0.06989  #> Efron's R2: 0.5118  #> Mean Absolute Error: 0.05405  #>  #> Convergence status: Successful  #> Iterations: 31  #>   # Interpretation: # - Beta: Precision varies with both income and household size #   Wealthier or larger households may show different spending variability  # Test for heteroscedasticity anova(fit_kw, fit_kw_hetero) #> Analysis of Deviance Table #>  #> Model 1: prop ~ income + persons #> Model 2: prop ~ income + persons | income + persons #>  #>               Resid. Df Resid. Dev Df Deviance  Pr(>Chi)    #> fit_kw         34.00000  -91.53671                          #> fit_kw_hetero  32.00000 -103.36364  2 11.82693 0.0027028 ** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1  # Example 3: Exponentiated Kumaraswamy for extreme spending patterns # Some households may have unusual food spending (very frugal or lavish) fit_ekw <- gkwreg(   prop ~ income + persons | # alpha     persons | # beta: household size affects precision     income, # lambda: income affects extremity   data = FoodExpenditure,   family = \"ekw\" ) summary(fit_ekw) #>  #> Generalized Kumaraswamy Regression Model Summary #>  #> Family: ekw  #>  #> Call: #> gkwreg(formula = prop ~ income + persons | persons | income,  #>     data = FoodExpenditure, family = \"ekw\") #>  #> Residuals: #>     Min  Q1.25%  Median    Mean  Q3.75%     Max  #> -0.1932 -0.0295  0.0234  0.0037  0.0396  0.1747  #>  #> Coefficients: #>                     Estimate Std. Error z value Pr(>|z|)     #> alpha:(Intercept)   2.188747   0.450856   4.855 1.21e-06 *** #> alpha:income       -0.003871   0.001919  -2.018  0.04362 *   #> alpha:persons      -0.109282   0.051203  -2.134  0.03282 *   #> beta:(Intercept)    9.826068   3.736876   2.629  0.00855 **  #> beta:persons       -1.105766   0.502560  -2.200  0.02779 *   #> lambda:(Intercept)  0.682952   1.182022   0.578  0.56341     #> lambda:income      -0.010845   0.013268  -0.817  0.41369     #> --- #> Signif. codes:  0 ‚Äò***‚Äô 0.001 ‚Äò**‚Äô 0.01 ‚Äò*‚Äô 0.05 ‚Äò.‚Äô 0.1 ‚Äò ‚Äô 1 #>  #> Confidence intervals (95%): #>                         3%     98% #> alpha:(Intercept)   1.3051  3.0724 #> alpha:income       -0.0076 -0.0001 #> alpha:persons      -0.2096 -0.0089 #> beta:(Intercept)    2.5019 17.1502 #> beta:persons       -2.0908 -0.1208 #> lambda:(Intercept) -1.6338  2.9997 #> lambda:income      -0.0368  0.0152 #>  #> Link functions: #> alpha: log #> beta: log #> lambda: log #>  #> Fitted parameter means: #> alpha: 4.906 #> beta: 1260 #> gamma: 1 #> delta: 0 #> lambda: 1.018 #>  #> Model fit statistics: #> Number of observations: 38  #> Number of parameters: 7  #> Residual degrees of freedom: 31  #> Log-likelihood: 50.31  #> AIC: -86.63  #> BIC: -75.17  #> RMSE: 0.07347  #> Efron's R2: 0.4605  #> Mean Absolute Error: 0.05648  #>  #> Convergence status: Successful  #> Iterations: 63  #>   # Interpretation: # - Lambda: Income level affects tail behavior #   Rich households may show more extreme (unusual) spending patterns  # Visualization: Engel curve plot(prop ~ income,   data = FoodExpenditure,   xlab = \"Annual Income ($)\", ylab = \"Proportion Spent on Food\",   main = \"Engel Curve for Food Expenditure\" ) # Add fitted values FoodExpenditure$fitted_kw <- fitted(fit_kw) points(FoodExpenditure$income, FoodExpenditure$fitted_kw,   col = \"blue\", pch = 19, cex = 0.8 ) legend(\"topright\",   legend = c(\"Observed\", \"Fitted\"),   col = c(\"black\", \"blue\"), pch = c(1, 19) )  # }"},{"path":"https://evandeilton.github.io/gkwreg/reference/GasolineYield.html","id":null,"dir":"Reference","previous_headings":"","what":"Gasoline Yield from Crude Oil ‚Äî GasolineYield","title":"Gasoline Yield from Crude Oil ‚Äî GasolineYield","text":"Operational data proportion crude oil converted gasoline distillation fractionation processes.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/GasolineYield.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gasoline Yield from Crude Oil ‚Äî GasolineYield","text":"","code":"GasolineYield"},{"path":"https://evandeilton.github.io/gkwreg/reference/GasolineYield.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Gasoline Yield from Crude Oil ‚Äî GasolineYield","text":"data frame 32 observations 6 variables: yield numeric. Proportion crude oil converted gasoline distillation fractionation (response variable). gravity numeric. Crude oil gravity degrees API (American Petroleum Institute scale). pressure numeric. Vapor pressure crude oil pounds per square inch (psi). temp10 numeric. Temperature degrees Fahrenheit 10\\ crude oil vaporized. temp numeric. Temperature degrees Fahrenheit gasoline vaporized (end point). batch factor. Batch indicator distinguishing 10 different crude oils used experiment.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/GasolineYield.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Gasoline Yield from Crude Oil ‚Äî GasolineYield","text":"Taken Prater (1956).","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/GasolineYield.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Gasoline Yield from Crude Oil ‚Äî GasolineYield","text":"dataset collected Prater (1956) study gasoline yield crude oil. dependent variable proportion crude oil distillation fractionation. Atkinson (1985) analyzed dataset using linear regression noted \"indication error distribution quite symmetrical, giving rise unduly large small residuals\". dataset contains 32 observations. noted (Daniel Wood, 1971, Chapter 8) ten sets values first three explanatory variables correspond ten different crudes subjected experimentally controlled distillation conditions. conditions captured variable batch data ordered according ascending order temp10.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/GasolineYield.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Gasoline Yield from Crude Oil ‚Äî GasolineYield","text":"Atkinson, .C. (1985). Plots, Transformations Regression: Introduction Graphical Methods Diagnostic Regression Analysis. New York: Oxford University Press. Cribari-Neto, F., Zeileis, . (2010). Beta Regression R. Journal Statistical Software, 34(2), 1‚Äì24. doi:10.18637/jss.v034.i02 Daniel, C., Wood, F.S. (1971). Fitting Equations Data. New York: John Wiley Sons. Ferrari, S.L.P., Cribari-Neto, F. (2004). Beta Regression Modeling Rates Proportions. Journal Applied Statistics, 31(7), 799‚Äì815. Prater, N.H. (1956). Estimate Gasoline Yields Crudes. Petroleum Refiner, 35(5), 236‚Äì238.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/GasolineYield.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gasoline Yield from Crude Oil ‚Äî GasolineYield","text":"","code":"# \\donttest{ require(gkwreg) require(gkwdist)  data(GasolineYield)  # Example 1: Kumaraswamy regression with batch effects # Model mean yield as function of batch and temperature # Allow precision to vary with temperature (heteroscedasticity) fit_kw <- gkwreg(yield ~ batch + temp | temp,   data = GasolineYield,   family = \"kw\" ) summary(fit_kw) #>  #> Generalized Kumaraswamy Regression Model Summary #>  #> Family: kw  #>  #> Call: #> gkwreg(formula = yield ~ batch + temp | temp, data = GasolineYield,  #>     family = \"kw\") #>  #> Residuals: #>     Min  Q1.25%  Median    Mean  Q3.75%     Max  #> -0.0642 -0.0099  0.0018 -0.0029  0.0070  0.0528  #>  #> Coefficients: #>                    Estimate Std. Error   z value Pr(>|z|)     #> alpha:(Intercept) 2.241e-01  3.123e-02 7.178e+00 7.07e-13 *** #> alpha:batch1      8.261e-01  2.965e-02 2.786e+01  < 2e-16 *** #> alpha:batch2      5.826e-01  3.182e-02 1.831e+01  < 2e-16 *** #> alpha:batch3      7.100e-01  2.948e-02 2.409e+01  < 2e-16 *** #> alpha:batch4      4.631e-01  2.669e-02 1.735e+01  < 2e-16 *** #> alpha:batch5      5.204e-01  2.669e-02 1.950e+01  < 2e-16 *** #> alpha:batch6      4.482e-01  2.788e-02 1.608e+01  < 2e-16 *** #> alpha:batch7      2.234e-01  2.561e-02 8.725e+00  < 2e-16 *** #> alpha:batch8      2.011e-01  2.747e-02 7.322e+00 2.45e-13 *** #> alpha:batch9      1.388e-01  3.000e-02 4.627e+00 3.72e-06 *** #> alpha:temp        6.619e-03  1.280e-08 5.172e+05  < 2e-16 *** #> beta:(Intercept)  1.621e+01  1.429e+00 1.134e+01  < 2e-16 *** #> beta:temp         3.811e-02  2.875e-03 1.326e+01  < 2e-16 *** #> --- #> Signif. codes:  0 ‚Äò***‚Äô 0.001 ‚Äò**‚Äô 0.01 ‚Äò*‚Äô 0.05 ‚Äò.‚Äô 0.1 ‚Äò ‚Äô 1 #>  #> Confidence intervals (95%): #>                        3%     98% #> alpha:(Intercept)  0.1629  0.2853 #> alpha:batch1       0.7680  0.8843 #> alpha:batch2       0.5202  0.6449 #> alpha:batch3       0.6522  0.7678 #> alpha:batch4       0.4107  0.5154 #> alpha:batch5       0.4681  0.5727 #> alpha:batch6       0.3935  0.5028 #> alpha:batch7       0.1732  0.2736 #> alpha:batch8       0.1473  0.2550 #> alpha:batch9       0.0800  0.1976 #> alpha:temp         0.0066  0.0066 #> beta:(Intercept)  13.4054 19.0064 #> beta:temp          0.0325  0.0437 #>  #> Link functions: #> alpha: log #> beta: log #>  #> Fitted parameter means: #> alpha: 18.86 #> beta: 1.864e+13 #> gamma: 1 #> delta: 0 #> lambda: 1 #>  #> Model fit statistics: #> Number of observations: 32  #> Number of parameters: 13  #> Residual degrees of freedom: 19  #> Log-likelihood: 96.73  #> AIC: -167.5  #> BIC: -148.4  #> RMSE: 0.0206  #> Efron's R2: 0.9619  #> Mean Absolute Error: 0.01403  #>  #> Convergence status: Failed  #> Iterations: 85  #>   # Interpretation: # - Alpha (mean): Different batches have different baseline yields #   Temperature affects yield transformation # - Beta (precision): Higher temperatures may produce more variable yields  # Example 2: Full model with all physical-chemical properties fit_kw_full <- gkwreg(   yield ~ gravity + pressure + temp10 + temp |     temp10 + temp,   data = GasolineYield,   family = \"kw\" ) #> Warning: NaNs produced summary(fit_kw_full) #>  #> Generalized Kumaraswamy Regression Model Summary #>  #> Family: kw  #>  #> Call: #> gkwreg(formula = yield ~ gravity + pressure + temp10 + temp |  #>     temp10 + temp, data = GasolineYield, family = \"kw\") #>  #> Residuals: #>     Min  Q1.25%  Median    Mean  Q3.75%     Max  #> -0.0516 -0.0169 -0.0034 -0.0053  0.0033  0.0444  #>  #> Coefficients: #>                    Estimate Std. Error z value Pr(>|z|)     #> alpha:(Intercept)  0.457549   0.166035   2.756  0.00586 **  #> alpha:gravity      0.001539   0.003912   0.393  0.69399     #> alpha:pressure     0.024644   0.012936   1.905  0.05676 .   #> alpha:temp10      -0.001364        NaN     NaN      NaN     #> alpha:temp         0.005833        NaN     NaN      NaN     #> beta:(Intercept)  -1.766712   3.731448  -0.473  0.63588     #> beta:temp10        0.059930   0.013139   4.561 5.08e-06 *** #> beta:temp          0.008332   0.001735   4.802 1.57e-06 *** #> --- #> Signif. codes:  0 ‚Äò***‚Äô 0.001 ‚Äò**‚Äô 0.01 ‚Äò*‚Äô 0.05 ‚Äò.‚Äô 0.1 ‚Äò ‚Äô 1 #>  #> Confidence intervals (95%): #>                        3%    98% #> alpha:(Intercept)  0.1321 0.7830 #> alpha:gravity     -0.0061 0.0092 #> alpha:pressure    -0.0007 0.0500 #> alpha:temp10          NaN    NaN #> alpha:temp            NaN    NaN #> beta:(Intercept)  -9.0802 5.5468 #> beta:temp10        0.0342 0.0857 #> beta:temp          0.0049 0.0117 #>  #> Link functions: #> alpha: log #> beta: log #>  #> Fitted parameter means: #> alpha: 9.935 #> beta: 59339339 #> gamma: 1 #> delta: 0 #> lambda: 1 #>  #> Model fit statistics: #> Number of observations: 32  #> Number of parameters: 8  #> Residual degrees of freedom: 24  #> Log-likelihood: 80.45  #> AIC: -144.9  #> BIC: -133.2  #> RMSE: 0.02081  #> Efron's R2: 0.9611  #> Mean Absolute Error: 0.01542  #>  #> Convergence status: Successful  #> Iterations: 70  #>   # Interpretation: # - Mean model captures effects of crude oil properties # - Precision varies with vaporization temperatures  # Example 3: Exponentiated Kumaraswamy for extreme yields # Some batches may produce unusually high/low yields fit_ekw <- gkwreg(   yield ~ batch + temp | # alpha: batch effects     temp | # beta: temperature precision     batch, # lambda: batch-specific tail behavior   data = GasolineYield,   family = \"ekw\" ) summary(fit_ekw) #>  #> Generalized Kumaraswamy Regression Model Summary #>  #> Family: ekw  #>  #> Call: #> gkwreg(formula = yield ~ batch + temp | temp | batch, data = GasolineYield,  #>     family = \"ekw\") #>  #> Residuals: #>     Min  Q1.25%  Median    Mean  Q3.75%     Max  #> -0.0353 -0.0133 -0.0020  0.0049  0.0082  0.2229  #>  #> Coefficients: #>                     Estimate Std. Error z value Pr(>|z|) #> alpha:(Intercept)  -0.367172        NaN     NaN      NaN #> alpha:batch1        0.527312        NaN     NaN      NaN #> alpha:batch2        0.484926        NaN     NaN      NaN #> alpha:batch3        0.678431        NaN     NaN      NaN #> alpha:batch4        0.319332        NaN     NaN      NaN #> alpha:batch5        0.503547        NaN     NaN      NaN #> alpha:batch6        0.303719        NaN     NaN      NaN #> alpha:batch7        0.162551        NaN     NaN      NaN #> alpha:batch8        0.192103        NaN     NaN      NaN #> alpha:batch9        0.097541        NaN     NaN      NaN #> alpha:temp          0.006092        NaN     NaN      NaN #> beta:(Intercept)    9.778013        NaN     NaN      NaN #> beta:temp           0.011640        NaN     NaN      NaN #> lambda:(Intercept) -0.178560        NaN     NaN      NaN #> lambda:batch1      35.456725        NaN     NaN      NaN #> lambda:batch2       3.490460        NaN     NaN      NaN #> lambda:batch3       1.122573        NaN     NaN      NaN #> lambda:batch4       7.227665        NaN     NaN      NaN #> lambda:batch5       0.685733        NaN     NaN      NaN #> lambda:batch6       7.410365        NaN     NaN      NaN #> lambda:batch7       2.274554        NaN     NaN      NaN #> lambda:batch8       0.762437        NaN     NaN      NaN #> lambda:batch9       1.441623        NaN     NaN      NaN #>  #> Confidence intervals (95%): #>                     3% 98% #> alpha:(Intercept)  NaN NaN #> alpha:batch1       NaN NaN #> alpha:batch2       NaN NaN #> alpha:batch3       NaN NaN #> alpha:batch4       NaN NaN #> alpha:batch5       NaN NaN #> alpha:batch6       NaN NaN #> alpha:batch7       NaN NaN #> alpha:batch8       NaN NaN #> alpha:batch9       NaN NaN #> alpha:temp         NaN NaN #> beta:(Intercept)   NaN NaN #> beta:temp          NaN NaN #> lambda:(Intercept) NaN NaN #> lambda:batch1      NaN NaN #> lambda:batch2      NaN NaN #> lambda:batch3      NaN NaN #> lambda:batch4      NaN NaN #> lambda:batch5      NaN NaN #> lambda:batch6      NaN NaN #> lambda:batch7      NaN NaN #> lambda:batch8      NaN NaN #> lambda:batch9      NaN NaN #>  #> Link functions: #> alpha: log #> beta: log #> lambda: log #>  #> Fitted parameter means: #> alpha: 7.856 #> beta: 1117127 #> gamma: 1 #> delta: 0 #> lambda: 2.618e+14 #>  #> Model fit statistics: #> Number of observations: 32  #> Number of parameters: 23  #> Residual degrees of freedom: 9  #> Log-likelihood: 114  #> AIC: -182  #> BIC: -148.3  #> RMSE: 0.04234  #> Efron's R2: 0.8391  #> Mean Absolute Error: 0.01906  #>  #> Convergence status: Failed  #> Iterations: 96  #>   # Interpretation: # - Lambda varies by batch: Some crude oils have more extreme #   yield distributions (heavy tails for very high/low yields)  # Model comparison: Does tail flexibility improve fit? anova(fit_kw, fit_ekw) #> Analysis of Deviance Table #>  #> Model 1: yield ~ batch + temp | temp #> Model 2: yield ~ batch + temp | temp | batch #>  #>         Resid. Df Resid. Dev Df Deviance   Pr(>Chi)     #> fit_kw   19.00000 -193.45292                            #> fit_ekw   9.00000 -227.96270 10 34.50978 0.00015134 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1  # Diagnostic plots par(mfrow = c(2, 2)) plot(fit_kw, which = c(1, 2, 4, 5)) #> Simulating envelope ( 100 iterations): .......... Done!  par(mfrow = c(1, 1)) # }"},{"path":"https://evandeilton.github.io/gkwreg/reference/ImpreciseTask.html","id":null,"dir":"Reference","previous_headings":"","what":"Imprecise Probabilities for Sunday Weather and Boeing Stock Task ‚Äî ImpreciseTask","title":"Imprecise Probabilities for Sunday Weather and Boeing Stock Task ‚Äî ImpreciseTask","text":"Data cognitive psychology experiment participants estimated upper lower probabilities events occur occur. study examines judgment uncertainty imprecise probability assessments.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/ImpreciseTask.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Imprecise Probabilities for Sunday Weather and Boeing Stock Task ‚Äî ImpreciseTask","text":"","code":"ImpreciseTask"},{"path":"https://evandeilton.github.io/gkwreg/reference/ImpreciseTask.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Imprecise Probabilities for Sunday Weather and Boeing Stock Task ‚Äî ImpreciseTask","text":"data frame 242 observations 3 variables: task factor levels Boeing stock Sunday weather. Indicates task participant performed. location numeric. Average lower estimate event occur upper estimate event occur (proportion). difference numeric. Difference upper lower probability estimates, measuring imprecision uncertainty.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/ImpreciseTask.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Imprecise Probabilities for Sunday Weather and Boeing Stock Task ‚Äî ImpreciseTask","text":"Taken Smithson et al. (2011) supplements.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/ImpreciseTask.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Imprecise Probabilities for Sunday Weather and Boeing Stock Task ‚Äî ImpreciseTask","text":"participants study either first- second-year undergraduate students psychology Australian universities, none strong background probability theory familiar imprecise probability theories. Sunday weather task, participants asked estimate probability temperature Canberra airport Sunday higher specified value. Boeing stock task, participants asked estimate probability Boeing's stock rise list 30 companies. task, participants asked provide lower upper estimates event occur occur.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/ImpreciseTask.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Imprecise Probabilities for Sunday Weather and Boeing Stock Task ‚Äî ImpreciseTask","text":"Smithson, M., Merkle, E.C., Verkuilen, J. (2011). Beta Regression Finite Mixture Models Polarization Priming. Journal Educational Behavioral Statistics, 36(6), 804‚Äì831. doi:10.3102/1076998610396893 Smithson, M., Segale, C. (2009). Partition Priming Judgments Imprecise Probabilities. Journal Statistical Theory Practice, 3(1), 169‚Äì181.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/ImpreciseTask.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Imprecise Probabilities for Sunday Weather and Boeing Stock Task ‚Äî ImpreciseTask","text":"","code":"# \\donttest{ require(gkwreg) require(gkwdist)  data(ImpreciseTask)  # Example 1: Basic model with task effects # Probability location varies by task type and uncertainty level fit_kw <- gkwreg(location ~ task * difference,   data = ImpreciseTask,   family = \"kw\" ) summary(fit_kw) #>  #> Generalized Kumaraswamy Regression Model Summary #>  #> Family: kw  #>  #> Call: #> gkwreg(formula = location ~ task * difference, data = ImpreciseTask,  #>     family = \"kw\") #>  #> Residuals: #>     Min  Q1.25%  Median    Mean  Q3.75%     Max  #> -0.3556 -0.0788  0.0274  0.0019  0.0944  0.3499  #>  #> Coefficients: #>                                     Estimate Std. Error z value Pr(>|z|)     #> alpha:(Intercept)                    1.25134    0.11593  10.794   <2e-16 *** #> alpha:taskSunday weather            -0.09543    0.11108  -0.859   0.3903     #> alpha:difference                     0.28623    0.21709   1.318   0.1874     #> alpha:taskSunday weather:difference  0.43791    0.25964   1.687   0.0917 .   #> beta:(Intercept)                     2.74022    0.15340  17.864   <2e-16 *** #> --- #> Signif. codes:  0 ‚Äò***‚Äô 0.001 ‚Äò**‚Äô 0.01 ‚Äò*‚Äô 0.05 ‚Äò.‚Äô 0.1 ‚Äò ‚Äô 1 #>  #> Confidence intervals (95%): #>                                          3%    98% #> alpha:(Intercept)                    1.0241 1.4786 #> alpha:taskSunday weather            -0.3131 0.1223 #> alpha:difference                    -0.1393 0.7117 #> alpha:taskSunday weather:difference -0.0710 0.9468 #> beta:(Intercept)                     2.4396 3.0409 #>  #> Link functions: #> alpha: log #> beta: log #>  #> Fitted parameter means: #> alpha: 3.805 #> beta: 15.47 #> gamma: 1 #> delta: 0 #> lambda: 1 #>  #> Model fit statistics: #> Number of observations: 242  #> Number of parameters: 5  #> Residual degrees of freedom: 237  #> Log-likelihood: 162.2  #> AIC: -314.3  #> BIC: -296.9  #> RMSE: 0.1198  #> Efron's R2: 0.101  #> Mean Absolute Error: 0.0981  #>  #> Convergence status: Successful  #> Iterations: 21  #>   # Interpretation: # - Alpha: Task type and uncertainty (difference) interact to affect #   probability estimates # - Different tasks may have different baseline probability assessments  # Example 2: Heteroscedastic model # Precision of estimates may vary by task and uncertainty fit_kw_hetero <- gkwreg(   location ~ task * difference |     task + difference,   data = ImpreciseTask,   family = \"kw\" ) summary(fit_kw_hetero) #>  #> Generalized Kumaraswamy Regression Model Summary #>  #> Family: kw  #>  #> Call: #> gkwreg(formula = location ~ task * difference | task + difference,  #>     data = ImpreciseTask, family = \"kw\") #>  #> Residuals: #>     Min  Q1.25%  Median    Mean  Q3.75%     Max  #> -0.3607 -0.0787  0.0333  0.0010  0.0907  0.3574  #>  #> Coefficients: #>                                     Estimate Std. Error z value Pr(>|z|)     #> alpha:(Intercept)                     1.7403     0.1329  13.092  < 2e-16 *** #> alpha:taskSunday weather             -0.4913     0.1365  -3.598 0.000320 *** #> alpha:difference                     -0.1068     0.2145  -0.498 0.618539     #> alpha:taskSunday weather:difference   0.3001     0.2410   1.245 0.213134     #> beta:(Intercept)                      4.4688     0.4707   9.493  < 2e-16 *** #> beta:taskSunday weather              -1.4832     0.4354  -3.407 0.000658 *** #> beta:difference                      -1.3788     0.5970  -2.309 0.020925 *   #> --- #> Signif. codes:  0 ‚Äò***‚Äô 0.001 ‚Äò**‚Äô 0.01 ‚Äò*‚Äô 0.05 ‚Äò.‚Äô 0.1 ‚Äò ‚Äô 1 #>  #> Confidence intervals (95%): #>                                          3%     98% #> alpha:(Intercept)                    1.4798  2.0009 #> alpha:taskSunday weather            -0.7589 -0.2237 #> alpha:difference                    -0.5272  0.3136 #> alpha:taskSunday weather:difference -0.1723  0.7725 #> beta:(Intercept)                     3.5462  5.3914 #> beta:taskSunday weather             -2.3366 -0.6298 #> beta:difference                     -2.5489 -0.2086 #>  #> Link functions: #> alpha: log #> beta: log #>  #> Fitted parameter means: #> alpha: 4.164 #> beta: 25.37 #> gamma: 1 #> delta: 0 #> lambda: 1 #>  #> Model fit statistics: #> Number of observations: 242  #> Number of parameters: 7  #> Residual degrees of freedom: 235  #> Log-likelihood: 170.6  #> AIC: -327.3  #> BIC: -302.9  #> RMSE: 0.1197  #> Efron's R2: 0.102  #> Mean Absolute Error: 0.09725  #>  #> Convergence status: Successful  #> Iterations: 26  #>   # Interpretation: # - Beta: Variability in estimates differs between tasks #   Higher uncertainty (difference) may lead to less precise estimates  # Example 3: McDonald distribution for extreme uncertainty # Some participants may show very extreme probability assessments fit_mc <- gkwreg(   location ~ task * difference | # gamma: full interaction     task * difference | # delta: full interaction     task, # lambda: task affects extremity   data = ImpreciseTask,   family = \"mc\",   control = gkw_control(     method = \"BFGS\",     maxit = 1500   ) ) #> Warning: NaNs produced summary(fit_mc) #>  #> Generalized Kumaraswamy Regression Model Summary #>  #> Family: mc  #>  #> Call: #> gkwreg(formula = location ~ task * difference | task * difference |  #>     task, data = ImpreciseTask, family = \"mc\", control = gkw_control(method = \"BFGS\",  #>     maxit = 1500)) #>  #> Residuals: #>     Min  Q1.25%  Median    Mean  Q3.75%     Max  #> -0.2631  0.1058  0.2147  0.1669  0.2255  0.6379  #>  #> Coefficients: #>                                     Estimate Std. Error z value Pr(>|z|) #> gamma:(Intercept)                    0.12000        NaN     NaN      NaN #> gamma:taskSunday weather             0.08321    0.37727   0.221    0.825 #> gamma:difference                     0.03513        NaN     NaN      NaN #> gamma:taskSunday weather:difference  0.01876        NaN     NaN      NaN #> delta:(Intercept)                   -0.08309        NaN     NaN      NaN #> delta:taskSunday weather            -0.05747    0.58059  -0.099    0.921 #> delta:difference                    -0.02637        NaN     NaN      NaN #> delta:taskSunday weather:difference -0.01482    1.06142  -0.014    0.989 #> lambda:(Intercept)                   0.25123        NaN     NaN      NaN #> lambda:taskSunday weather            0.17376        NaN     NaN      NaN #>  #> Confidence intervals (95%): #>                                          3%    98% #> gamma:(Intercept)                       NaN    NaN #> gamma:taskSunday weather            -0.6562 0.8226 #> gamma:difference                        NaN    NaN #> gamma:taskSunday weather:difference     NaN    NaN #> delta:(Intercept)                       NaN    NaN #> delta:taskSunday weather            -1.1954 1.0805 #> delta:difference                        NaN    NaN #> delta:taskSunday weather:difference -2.0952 2.0655 #> lambda:(Intercept)                      NaN    NaN #> lambda:taskSunday weather               NaN    NaN #>  #> Link functions: #> gamma: log #> delta: logit #> lambda: log #>  #> Fitted parameter means: #> alpha: 1 #> beta: 1 #> gamma: 1.212 #> delta: 4.668 #> lambda: 1.457 #>  #> Model fit statistics: #> Number of observations: 242  #> Number of parameters: 10  #> Residual degrees of freedom: 232  #> Log-likelihood: 20.49  #> AIC: -20.97  #> BIC: 13.92  #> RMSE: 0.2123  #> Efron's R2: -1.824  #> Mean Absolute Error: 0.1885  #>  #> Convergence status: Successful  #> Iterations: 7  #>   # Interpretation: # - Lambda varies by task: Weather vs. stock may produce #   different patterns of extreme probability assessments # }"},{"path":"https://evandeilton.github.io/gkwreg/reference/LossAversion.html","id":null,"dir":"Reference","previous_headings":"","what":"(No) Myopic Loss Aversion in Adolescents ‚Äî LossAversion","title":"(No) Myopic Loss Aversion in Adolescents ‚Äî LossAversion","text":"Data behavioral economics experiment assessing extent myopic loss aversion among adolescents aged 11 19 years. experiment tests whether short-term investment horizons lead conservative investment behavior.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/LossAversion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"(No) Myopic Loss Aversion in Adolescents ‚Äî LossAversion","text":"","code":"LossAversion"},{"path":"https://evandeilton.github.io/gkwreg/reference/LossAversion.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"(No) Myopic Loss Aversion in Adolescents ‚Äî LossAversion","text":"data frame 570 observations 7 variables: invest numeric. Average proportion tokens invested across 9 rounds experiment (response variable). gender factor. Gender player (team players). male factor. (least one ) player(s) male (team)? age numeric. Age player (average age case team). grade factor. School grade player(s). arrangement factor. Investment horizon treatment levels short (1 round), medium (3 rounds), long (9 rounds). treatment factor. Type treatment: long vs. short.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/LossAversion.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"(No) Myopic Loss Aversion in Adolescents ‚Äî LossAversion","text":"Data collected Matthias Sutter Daniela Gl√§tzle-R√ºtzler, Universit√§t Innsbruck.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/LossAversion.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"(No) Myopic Loss Aversion in Adolescents ‚Äî LossAversion","text":"data collected Matthias Sutter Daniela Gl√§tzle-R√ºtzler (Universit√§t Innsbruck) experiment high-school students Tyrol, Austria (Schwaz Innsbruck). experiment tests theory myopic loss aversion, proposes investors shorter evaluation periods loss-averse thus invest less risky assets. Classical theory predicts players short investment horizons (myopic view) invest less due loss aversion. However, Sutter et al. (2015) found evidence myopic loss aversion adolescents, contrary findings adult populations. investment game structure: round, players invest tokens risky asset 50% chance doubling losing investment. treatment varied feedback frequency (short = every round, medium = every 3 rounds, long = end).","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/LossAversion.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"(No) Myopic Loss Aversion in Adolescents ‚Äî LossAversion","text":"Sutter, M., Kocher, M.G., Gl√§tzle-R√ºtzler, D., Trautmann, S.T. (2015). Myopic Loss Aversion Adolescents? ‚Äì Experimental Note. Journal Economic Behavior & Organization, 111, 169‚Äì176. doi:10.1016/j.jebo.2014.12.021 Kosmidis, ., Zeileis, . (2024). Extended-Support Beta Regression (0, 1) Responses. arXiv:2409.07233. doi:10.48550/arXiv.2409.07233","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/LossAversion.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"(No) Myopic Loss Aversion in Adolescents ‚Äî LossAversion","text":"","code":"# \\donttest{ require(gkwreg) require(gkwdist)  data(LossAversion) # Control bounds  LossAversion$invest <- with(   LossAversion,   ifelse(invest <= 0, 0.000001,     ifelse(invest >= 1, 0.999999, invest)   ) ) # Example 1: Test for myopic loss aversion # Do short-term players invest less? (They shouldn't, per Sutter et al.) fit_kw <- gkwreg(   invest ~ arrangement + age + male + grade |     arrangement + male,   data = LossAversion,   family = \"kw\" ) summary(fit_kw) #>  #> Generalized Kumaraswamy Regression Model Summary #>  #> Family: kw  #>  #> Call: #> gkwreg(formula = invest ~ arrangement + age + male + grade |  #>     arrangement + male, data = LossAversion, family = \"kw\") #>  #> Residuals: #>     Min  Q1.25%  Median    Mean  Q3.75%     Max  #> -0.5002 -0.2002  0.0000  0.0037  0.1999  0.5000  #>  #> Coefficients: #>                       Estimate Std. Error z value Pr(>|z|) #> alpha:(Intercept)      0.00000    0.47351       0        1 #> alpha:arrangementteam  0.00000    0.18358       0        1 #> alpha:age              0.00000    0.03771       0        1 #> alpha:maleyes          0.00000    0.12103       0        1 #> alpha:grade10-12       0.00000    0.17325       0        1 #> beta:(Intercept)       0.00000    0.09653       0        1 #> beta:arrangementteam   0.00000    0.16937       0        1 #> beta:maleyes           0.00000    0.13944       0        1 #>  #> Confidence intervals (95%): #>                            3%    98% #> alpha:(Intercept)     -0.9281 0.9281 #> alpha:arrangementteam -0.3598 0.3598 #> alpha:age             -0.0739 0.0739 #> alpha:maleyes         -0.2372 0.2372 #> alpha:grade10-12      -0.3396 0.3396 #> beta:(Intercept)      -0.1892 0.1892 #> beta:arrangementteam  -0.3320 0.3320 #> beta:maleyes          -0.2733 0.2733 #>  #> Link functions: #> alpha: log #> beta: log #>  #> Fitted parameter means: #> alpha: 1 #> beta: 0.9996 #> gamma: 1 #> delta: 0 #> lambda: 1 #>  #> Model fit statistics: #> Number of observations: 570  #> Number of parameters: 8  #> Residual degrees of freedom: 562  #> Log-likelihood: -3e+21  #> AIC: 6e+21  #> BIC: 6e+21  #> RMSE: 0.2678  #> Efron's R2: 7.819e-05  #> Mean Absolute Error: 0.2217  #>  #> Convergence status: Successful  #> Iterations: 1  #>   # Interpretation: # - Alpha: Effect of investment horizon (arrangement) on mean investment #   Age and gender effects on risk-taking # - Beta: Precision varies by horizon and gender #   (some groups more consistent than others)  # Example 2: Interaction effects # Does the horizon effect differ by age/grade? fit_kw_interact <- gkwreg(   invest ~ grade * (arrangement + age) + male |     arrangement + male + grade,   data = LossAversion,   family = \"kw\" ) summary(fit_kw_interact) #>  #> Generalized Kumaraswamy Regression Model Summary #>  #> Family: kw  #>  #> Call: #> gkwreg(formula = invest ~ grade * (arrangement + age) + male |  #>     arrangement + male + grade, data = LossAversion, family = \"kw\") #>  #> Residuals: #>     Min  Q1.25%  Median    Mean  Q3.75%     Max  #> -0.5002 -0.2002  0.0000  0.0037  0.2000  0.5000  #>  #> Coefficients: #>                                  Estimate Std. Error z value Pr(>|z|) #> alpha:(Intercept)                 0.00000    0.67535       0        1 #> alpha:grade10-12                  0.00000    1.12039       0        1 #> alpha:arrangementteam             0.00000    0.21132       0        1 #> alpha:age                         0.00000    0.05342       0        1 #> alpha:maleyes                     0.00000    0.12237       0        1 #> alpha:grade10-12:arrangementteam  0.00000    0.22609       0        1 #> alpha:grade10-12:age              0.00000    0.07630       0        1 #> beta:(Intercept)                  0.00000    0.11264       0        1 #> beta:arrangementteam              0.00000    0.17198       0        1 #> beta:maleyes                      0.00000    0.13977       0        1 #> beta:grade10-12                   0.00000    0.14404       0        1 #>  #> Confidence intervals (95%): #>                                       3%    98% #> alpha:(Intercept)                -1.3237 1.3237 #> alpha:grade10-12                 -2.1959 2.1959 #> alpha:arrangementteam            -0.4142 0.4142 #> alpha:age                        -0.1047 0.1047 #> alpha:maleyes                    -0.2398 0.2398 #> alpha:grade10-12:arrangementteam -0.4431 0.4431 #> alpha:grade10-12:age             -0.1495 0.1495 #> beta:(Intercept)                 -0.2208 0.2208 #> beta:arrangementteam             -0.3371 0.3371 #> beta:maleyes                     -0.2740 0.2740 #> beta:grade10-12                  -0.2823 0.2823 #>  #> Link functions: #> alpha: log #> beta: log #>  #> Fitted parameter means: #> alpha: 1 #> beta: 0.9996 #> gamma: 1 #> delta: 0 #> lambda: 1 #>  #> Model fit statistics: #> Number of observations: 570  #> Number of parameters: 11  #> Residual degrees of freedom: 559  #> Log-likelihood: -3e+21  #> AIC: 6e+21  #> BIC: 6e+21  #> RMSE: 0.2679  #> Efron's R2: -0.0001649  #> Mean Absolute Error: 0.2218  #>  #> Convergence status: Successful  #> Iterations: 1  #>   # Interpretation: # - Grade √ó arrangement interaction tests if myopic loss aversion #   emerges differently at different developmental stages  # Example 3: Extended-support for boundary observations # Some students invest 0% or 100% of tokens # Original 'invest' variable may include exact 0 and 1 values fit_xbx <- gkwreg(   invest ~ grade * (arrangement + age) + male |     arrangement + male + grade,   data = LossAversion,   family = \"kw\" # Note: for true [0,1] support, use extended-support models ) summary(fit_xbx) #>  #> Generalized Kumaraswamy Regression Model Summary #>  #> Family: kw  #>  #> Call: #> gkwreg(formula = invest ~ grade * (arrangement + age) + male |  #>     arrangement + male + grade, data = LossAversion, family = \"kw\") #>  #> Residuals: #>     Min  Q1.25%  Median    Mean  Q3.75%     Max  #> -0.5002 -0.2002  0.0000  0.0037  0.2000  0.5000  #>  #> Coefficients: #>                                  Estimate Std. Error z value Pr(>|z|) #> alpha:(Intercept)                 0.00000    0.67535       0        1 #> alpha:grade10-12                  0.00000    1.12039       0        1 #> alpha:arrangementteam             0.00000    0.21132       0        1 #> alpha:age                         0.00000    0.05342       0        1 #> alpha:maleyes                     0.00000    0.12237       0        1 #> alpha:grade10-12:arrangementteam  0.00000    0.22609       0        1 #> alpha:grade10-12:age              0.00000    0.07630       0        1 #> beta:(Intercept)                  0.00000    0.11264       0        1 #> beta:arrangementteam              0.00000    0.17198       0        1 #> beta:maleyes                      0.00000    0.13977       0        1 #> beta:grade10-12                   0.00000    0.14404       0        1 #>  #> Confidence intervals (95%): #>                                       3%    98% #> alpha:(Intercept)                -1.3237 1.3237 #> alpha:grade10-12                 -2.1959 2.1959 #> alpha:arrangementteam            -0.4142 0.4142 #> alpha:age                        -0.1047 0.1047 #> alpha:maleyes                    -0.2398 0.2398 #> alpha:grade10-12:arrangementteam -0.4431 0.4431 #> alpha:grade10-12:age             -0.1495 0.1495 #> beta:(Intercept)                 -0.2208 0.2208 #> beta:arrangementteam             -0.3371 0.3371 #> beta:maleyes                     -0.2740 0.2740 #> beta:grade10-12                  -0.2823 0.2823 #>  #> Link functions: #> alpha: log #> beta: log #>  #> Fitted parameter means: #> alpha: 1 #> beta: 0.9996 #> gamma: 1 #> delta: 0 #> lambda: 1 #>  #> Model fit statistics: #> Number of observations: 570  #> Number of parameters: 11  #> Residual degrees of freedom: 559  #> Log-likelihood: -3e+21  #> AIC: 6e+21  #> BIC: 6e+21  #> RMSE: 0.2679  #> Efron's R2: -0.0001649  #> Mean Absolute Error: 0.2218  #>  #> Convergence status: Successful  #> Iterations: 1  #>   # Interpretation: # - Model accommodates extreme risk-taking (all-in or all-out strategies)  # Compare models anova(fit_kw, fit_kw_interact) #> Analysis of Deviance Table #>  #> Model 1: invest ~ arrangement + age + male + grade | arrangement + male #> Model 2: invest ~ grade * (arrangement + age) + male | arrangement + male +  #> Model 2:     grade #>  #>                 Resid. Df Resid. Dev Df Deviance Pr(>Chi)   #> fit_kw          562.00000      6e+21                        #> fit_kw_interact 559.00000      6e+21  3  0.00000        1   #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1  # Visualization: Investment by horizon boxplot(invest ~ arrangement,   data = LossAversion,   xlab = \"Investment Horizon\", ylab = \"Proportion Invested\",   main = \"No Myopic Loss Aversion in Adolescents\",   col = c(\"lightblue\", \"lightgreen\", \"lightyellow\") )  # }"},{"path":"https://evandeilton.github.io/gkwreg/reference/MockJurors.html","id":null,"dir":"Reference","previous_headings":"","what":"Confidence of Mock Jurors in Their Verdicts ‚Äî MockJurors","title":"Confidence of Mock Jurors in Their Verdicts ‚Äî MockJurors","text":"Data study examining factors influence mock juror confidence verdicts criminal trials. experiment manipulates verdict options (two-option vs. three-option) presence conflicting testimonial evidence.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/MockJurors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Confidence of Mock Jurors in Their Verdicts ‚Äî MockJurors","text":"","code":"MockJurors"},{"path":"https://evandeilton.github.io/gkwreg/reference/MockJurors.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Confidence of Mock Jurors in Their Verdicts ‚Äî MockJurors","text":"data frame 104 observations 3 variables: confidence numeric. Juror confidence verdict, scaled open unit interval (0, 1). Original scale 0-100. verdict factor indicating whether two-option verdict (guilty vs. acquittal) three-option verdict (Scottish 'proven' alternative) requested. Sum contrast coding employed. conflict factor. conflicting testimonial evidence? Values yes. Sum contrast coding employed.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/MockJurors.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Confidence of Mock Jurors in Their Verdicts ‚Äî MockJurors","text":"Data collected Deady (2004), analyzed Smithson Verkuilen (2006).","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/MockJurors.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Confidence of Mock Jurors in Their Verdicts ‚Äî MockJurors","text":"data collected Deady (2004) among first-year psychology students Australian National University. experiment examined availability third verdict option ('proven') conflicting evidence affect juror confidence. Smithson Verkuilen (2006) employed data, scaling original confidence (scale 0-100) open unit interval using transformation: ((original_confidence/100) * 103 - 0.5) / 104. Important note: original coding conflict data provided Smithson's homepage -1/1 Smithson Verkuilen (2006) describe mean /yes. However, results (sample statistics, histograms, etc.) suggest actually means yes/, employed corrected MockJurors dataset.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/MockJurors.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Confidence of Mock Jurors in Their Verdicts ‚Äî MockJurors","text":"Deady, S. (2004). Psychological Third Verdict: 'Proven' 'Willing Make Decision'? Unpublished honors thesis, Australian National University, Canberra. Smithson, M., Verkuilen, J. (2006). Better Lemon Squeezer? Maximum-Likelihood Regression Beta-Distributed Dependent Variables. Psychological Methods, 11(1), 54‚Äì71.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/MockJurors.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Confidence of Mock Jurors in Their Verdicts ‚Äî MockJurors","text":"","code":"# \\donttest{ require(gkwreg) require(gkwdist)  data(MockJurors)  # Example 1: Main effects model with heteroscedasticity # Confidence depends on verdict options and conflicting evidence # Variability may also depend on these factors fit_kw <- gkwreg(   confidence ~ verdict + conflict |     verdict * conflict,   data = MockJurors,   family = \"kw\" ) summary(fit_kw) #>  #> Generalized Kumaraswamy Regression Model Summary #>  #> Family: kw  #>  #> Call: #> gkwreg(formula = confidence ~ verdict + conflict | verdict *  #>     conflict, data = MockJurors, family = \"kw\") #>  #> Residuals: #>     Min  Q1.25%  Median    Mean  Q3.75%     Max  #> -0.6484 -0.1143  0.0515  0.0152  0.1827  0.3416  #>  #> Coefficients: #>                       Estimate Std. Error z value Pr(>|z|)     #> alpha:(Intercept)      0.70572    0.13722   5.143 2.71e-07 *** #> alpha:verdict         -0.31540    0.15835  -1.992  0.04640 *   #> alpha:conflict         0.21806    0.15492   1.408  0.15925     #> beta:(Intercept)      -0.14787    0.12674  -1.167  0.24332     #> beta:verdict          -0.35402    0.13337  -2.654  0.00794 **  #> beta:conflict          0.10940    0.13351   0.819  0.41258     #> beta:verdict:conflict -0.12932    0.09992  -1.294  0.19558     #> --- #> Signif. codes:  0 ‚Äò***‚Äô 0.001 ‚Äò**‚Äô 0.01 ‚Äò*‚Äô 0.05 ‚Äò.‚Äô 0.1 ‚Äò ‚Äô 1 #>  #> Confidence intervals (95%): #>                            3%     98% #> alpha:(Intercept)      0.4368  0.9747 #> alpha:verdict         -0.6258 -0.0050 #> alpha:conflict        -0.0856  0.5217 #> beta:(Intercept)      -0.3963  0.1005 #> beta:verdict          -0.6154 -0.0926 #> beta:conflict         -0.1523  0.3711 #> beta:verdict:conflict -0.3252  0.0665 #>  #> Link functions: #> alpha: log #> beta: log #>  #> Fitted parameter means: #> alpha: 2.184 #> beta: 0.9347 #> gamma: 1 #> delta: 0 #> lambda: 1 #>  #> Model fit statistics: #> Number of observations: 104  #> Number of parameters: 7  #> Residual degrees of freedom: 97  #> Log-likelihood: 35.56  #> AIC: -57.12  #> BIC: -38.61  #> RMSE: 0.2084  #> Efron's R2: 0.0305  #> Mean Absolute Error: 0.1657  #>  #> Convergence status: Successful  #> Iterations: 18  #>   # Interpretation: # - Alpha (mean): Additive effects of verdict type and conflict #   Three-option verdicts may reduce confidence #   Conflicting evidence reduces confidence # - Beta (precision): Interaction suggests confidence variability #   depends on combination of verdict options and evidence type  # Example 2: Full interaction in mean model fit_kw_interact <- gkwreg(   confidence ~ verdict * conflict |     verdict * conflict,   data = MockJurors,   family = \"kw\" ) summary(fit_kw_interact) #>  #> Generalized Kumaraswamy Regression Model Summary #>  #> Family: kw  #>  #> Call: #> gkwreg(formula = confidence ~ verdict * conflict | verdict *  #>     conflict, data = MockJurors, family = \"kw\") #>  #> Residuals: #>     Min  Q1.25%  Median    Mean  Q3.75%     Max  #> -0.6078 -0.1026  0.0131  0.0076  0.1653  0.3822  #>  #> Coefficients: #>                        Estimate Std. Error z value Pr(>|z|)     #> alpha:(Intercept)       0.78602    0.13396   5.867 4.43e-09 *** #> alpha:verdict          -0.31171    0.13396  -2.327  0.01997 *   #> alpha:conflict          0.30523    0.13396   2.278  0.02270 *   #> alpha:verdict:conflict  0.41032    0.13396   3.063  0.00219 **  #> beta:(Intercept)       -0.09854    0.12599  -0.782  0.43415     #> beta:verdict           -0.34600    0.12599  -2.746  0.00603 **  #> beta:conflict           0.11003    0.12599   0.873  0.38250     #> beta:verdict:conflict   0.10701    0.12599   0.849  0.39569     #> --- #> Signif. codes:  0 ‚Äò***‚Äô 0.001 ‚Äò**‚Äô 0.01 ‚Äò*‚Äô 0.05 ‚Äò.‚Äô 0.1 ‚Äò ‚Äô 1 #>  #> Confidence intervals (95%): #>                             3%     98% #> alpha:(Intercept)       0.5235  1.0486 #> alpha:verdict          -0.5743 -0.0491 #> alpha:conflict          0.0427  0.5678 #> alpha:verdict:conflict  0.1478  0.6729 #> beta:(Intercept)       -0.3455  0.1484 #> beta:verdict           -0.5929 -0.0991 #> beta:conflict          -0.1369  0.3570 #> beta:verdict:conflict  -0.1399  0.3539 #>  #> Link functions: #> alpha: log #> beta: log #>  #> Fitted parameter means: #> alpha: 2.549 #> beta: 0.9711 #> gamma: 1 #> delta: 0 #> lambda: 1 #>  #> Model fit statistics: #> Number of observations: 104  #> Number of parameters: 8  #> Residual degrees of freedom: 96  #> Log-likelihood: 40.12  #> AIC: -64.24  #> BIC: -43.09  #> RMSE: 0.2078  #> Efron's R2: 0.03573  #> Mean Absolute Error: 0.1631  #>  #> Convergence status: Successful  #> Iterations: 18  #>   # Interpretation: # - Full interaction: Third verdict option may have different effects #   depending on whether evidence is conflicting  # Test interaction significance anova(fit_kw, fit_kw_interact) #> Analysis of Deviance Table #>  #> Model 1: confidence ~ verdict + conflict | verdict * conflict #> Model 2: confidence ~ verdict * conflict | verdict * conflict #>  #>                 Resid. Df Resid. Dev Df Deviance  Pr(>Chi)    #> fit_kw           97.00000  -71.12225                          #> fit_kw_interact  96.00000  -80.24264  1  9.12039 0.0025278 ** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1  # Example 3: McDonald distribution for extreme confidence patterns # Jurors may show very high confidence (ceiling effects) or very low # confidence depending on conditions fit_mc <- gkwreg(   confidence ~ verdict * conflict | # gamma: full interaction     verdict * conflict | # delta: full interaction     verdict + conflict, # lambda: additive extremity effects   data = MockJurors,   family = \"mc\",   control = gkw_control(     method = \"BFGS\",     maxit = 1500,     reltol = 1e-8   ) ) summary(fit_mc) #>  #> Generalized Kumaraswamy Regression Model Summary #>  #> Family: mc  #>  #> Call: #> gkwreg(formula = confidence ~ verdict * conflict | verdict *  #>     conflict | verdict + conflict, data = MockJurors, family = \"mc\",  #>     control = gkw_control(method = \"BFGS\", maxit = 1500, reltol = 1e-08)) #>  #> Residuals: #>     Min  Q1.25%  Median    Mean  Q3.75%     Max  #> -0.4395 -0.0471  0.0520  0.1064  0.2500  0.7032  #>  #> Coefficients: #>                        Estimate Std. Error z value Pr(>|z|)     #> gamma:(Intercept)        3.2186     5.7452   0.560   0.5753     #> gamma:verdict            2.0199     5.5102   0.367   0.7139     #> gamma:conflict          -0.7418     0.6489  -1.143   0.2530     #> gamma:verdict:conflict   0.9145     0.1266   7.224 5.04e-13 *** #> delta:(Intercept)       -3.6223     0.3943  -9.186  < 2e-16 *** #> delta:verdict           -0.8930     0.3948  -2.262   0.0237 *   #> delta:conflict           0.2426     0.3944   0.615   0.5386     #> delta:verdict:conflict   0.7301     0.3960   1.843   0.0653 .   #> lambda:(Intercept)      -2.2131     5.7326  -0.386   0.6995     #> lambda:verdict          -2.3000     5.5063  -0.418   0.6762     #> lambda:conflict          1.0677     0.6352   1.681   0.0928 .   #> --- #> Signif. codes:  0 ‚Äò***‚Äô 0.001 ‚Äò**‚Äô 0.01 ‚Äò*‚Äô 0.05 ‚Äò.‚Äô 0.1 ‚Äò ‚Äô 1 #>  #> Confidence intervals (95%): #>                              3%     98% #> gamma:(Intercept)       -8.0418 14.4790 #> gamma:verdict           -8.7798 12.8196 #> gamma:conflict          -2.0136  0.5300 #> gamma:verdict:conflict   0.6664  1.1627 #> delta:(Intercept)       -4.3952 -2.8494 #> delta:verdict           -1.6667 -0.1193 #> delta:conflict          -0.5305  1.0156 #> delta:verdict:conflict  -0.0461  1.5063 #> lambda:(Intercept)     -13.4488  9.0225 #> lambda:verdict         -13.0922  8.4921 #> lambda:conflict         -0.1773  2.3127 #>  #> Link functions: #> gamma: log #> delta: logit #> lambda: log #>  #> Fitted parameter means: #> alpha: 1 #> beta: 1 #> gamma: 100.7 #> delta: 0.4194 #> lambda: 0.8955 #>  #> Model fit statistics: #> Number of observations: 104  #> Number of parameters: 11  #> Residual degrees of freedom: 93  #> Log-likelihood: 19.98  #> AIC: -17.96  #> BIC: 11.13  #> RMSE: 0.2857  #> Efron's R2: -0.8222  #> Mean Absolute Error: 0.2204  #>  #> Convergence status: Successful  #> Iterations: 38  #>   # Interpretation: # - Lambda: Models asymmetry and extreme confidence #   Some conditions produce more polarized confidence (very high or very low)  # Example 4: Exponentiated Kumaraswamy alternative fit_ekw <- gkwreg(   confidence ~ verdict * conflict | # alpha     verdict + conflict | # beta     conflict, # lambda: conflict affects extremity   data = MockJurors,   family = \"ekw\",   control = gkw_control(     method = \"BFGS\",     maxit = 1500   ) ) #> Warning: NaNs produced summary(fit_ekw) #>  #> Generalized Kumaraswamy Regression Model Summary #>  #> Family: ekw  #>  #> Call: #> gkwreg(formula = confidence ~ verdict * conflict | verdict +  #>     conflict | conflict, data = MockJurors, family = \"ekw\", control = gkw_control(method = \"BFGS\",  #>     maxit = 1500)) #>  #> Residuals: #>     Min  Q1.25%  Median    Mean  Q3.75%     Max  #> -0.7253 -0.2066 -0.0576 -0.0722  0.0744  0.2647  #>  #> Coefficients: #>                        Estimate Std. Error z value Pr(>|z|) #> alpha:(Intercept)       0.45685        NaN     NaN      NaN #> alpha:verdict          -0.05041    0.12348  -0.408    0.683 #> alpha:conflict          0.09766        NaN     NaN      NaN #> alpha:verdict:conflict  0.13324    0.10132   1.315    0.189 #> beta:(Intercept)       -0.64393        NaN     NaN      NaN #> beta:verdict           -0.17246    0.12703  -1.358    0.175 #> beta:conflict          -0.07422        NaN     NaN      NaN #> lambda:(Intercept)      0.45685        NaN     NaN      NaN #> lambda:conflict         0.09766        NaN     NaN      NaN #>  #> Confidence intervals (95%): #>                             3%    98% #> alpha:(Intercept)          NaN    NaN #> alpha:verdict          -0.2924 0.1916 #> alpha:conflict             NaN    NaN #> alpha:verdict:conflict -0.0654 0.3318 #> beta:(Intercept)           NaN    NaN #> beta:verdict           -0.4214 0.0765 #> beta:conflict              NaN    NaN #> lambda:(Intercept)         NaN    NaN #> lambda:conflict            NaN    NaN #>  #> Link functions: #> alpha: log #> beta: log #> lambda: log #>  #> Fitted parameter means: #> alpha: 1.608 #> beta: 0.5339 #> gamma: 1 #> delta: 0 #> lambda: 1.589 #>  #> Model fit statistics: #> Number of observations: 104  #> Number of parameters: 9  #> Residual degrees of freedom: 95  #> Log-likelihood: 9.75  #> AIC: -1.499  #> BIC: 22.3  #> RMSE: 0.2213  #> Efron's R2: -0.09353  #> Mean Absolute Error: 0.1677  #>  #> Convergence status: Successful  #> Iterations: 5  #>   # Compare 3-parameter models AIC(fit_ekw, fit_mc) #>         df        AIC #> fit_ekw  9  -1.499307 #> fit_mc  11 -17.957086 # }"},{"path":"https://evandeilton.github.io/gkwreg/reference/ReadingSkills.html","id":null,"dir":"Reference","previous_headings":"","what":"Dyslexia and IQ Predicting Reading Accuracy ‚Äî ReadingSkills","title":"Dyslexia and IQ Predicting Reading Accuracy ‚Äî ReadingSkills","text":"Data assessing contribution non-verbal IQ children's reading skills dyslexic non-dyslexic children. classic dataset demonstrating beta regression interaction effects heteroscedasticity.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/ReadingSkills.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dyslexia and IQ Predicting Reading Accuracy ‚Äî ReadingSkills","text":"","code":"ReadingSkills"},{"path":"https://evandeilton.github.io/gkwreg/reference/ReadingSkills.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Dyslexia and IQ Predicting Reading Accuracy ‚Äî ReadingSkills","text":"data frame 44 observations 4 variables: accuracy numeric. Reading accuracy score scaled open unit interval (0, 1). Perfect scores 1 replaced 0.99. accuracy1 numeric. Unrestricted reading accuracy score (0, 1), including boundary observations. dyslexia factor. child dyslexic? Levels: (control group) yes (dyslexic group). Sum contrast coding employed. iq numeric. Non-verbal intelligence quotient transformed z-scores (mean = 0, SD = 1).","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/ReadingSkills.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Dyslexia and IQ Predicting Reading Accuracy ‚Äî ReadingSkills","text":"Data collected Pammer Kevan (2004).","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/ReadingSkills.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Dyslexia and IQ Predicting Reading Accuracy ‚Äî ReadingSkills","text":"data collected Pammer Kevan (2004) employed Smithson Verkuilen (2006) seminal beta regression paper. sample includes 19 dyslexic children 25 controls recruited primary schools Australian Capital Territory. Children's ages ranged 8 years 5 months 12 years 3 months. Mean reading accuracy 0.606 dyslexic readers 0.900 controls. study investigates whether dyslexia contributes reading accuracy even controlling IQ (average lower dyslexics). Transformation details: original reading accuracy score transformed Smithson Verkuilen (2006) fit beta regression requirements: First, original accuracy scaled using minimal maximal scores (b) can obtained test: accuracy1 = (original - )/(b - ) (b values provided). Subsequently, accuracy obtained accuracy1 replacing observations value 1 0.99 fit open interval (0, 1). data clearly show asymmetry heteroscedasticity (especially control group), making beta regression appropriate standard linear regression.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/ReadingSkills.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Dyslexia and IQ Predicting Reading Accuracy ‚Äî ReadingSkills","text":"Cribari-Neto, F., Zeileis, . (2010). Beta Regression R. Journal Statistical Software, 34(2), 1‚Äì24. doi:10.18637/jss.v034.i02 Gr√ºn, B., Kosmidis, ., Zeileis, . (2012). Extended Beta Regression R: Shaken, Stirred, Mixed, Partitioned. Journal Statistical Software, 48(11), 1‚Äì25. doi:10.18637/jss.v048.i11 Kosmidis, ., Zeileis, . (2024). Extended-Support Beta Regression (0, 1) Responses. arXiv:2409.07233. doi:10.48550/arXiv.2409.07233 Pammer, K., Kevan, . (2004). Contribution Visual Sensitivity, Phonological Processing Nonverbal IQ Children's Reading. Unpublished manuscript, Australian National University, Canberra. Smithson, M., Verkuilen, J. (2006). Better Lemon Squeezer? Maximum-Likelihood Regression Beta-Distributed Dependent Variables. Psychological Methods, 11(1), 54‚Äì71.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/ReadingSkills.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Dyslexia and IQ Predicting Reading Accuracy ‚Äî ReadingSkills","text":"","code":"# \\donttest{ require(gkwreg) require(gkwdist)  data(ReadingSkills)  # Example 1: Standard Kumaraswamy with interaction and heteroscedasticity # Mean: Dyslexia √ó IQ interaction (do groups differ in IQ effect?) # Precision: Main effects (variability differs by group and IQ level) fit_kw <- gkwreg(   accuracy ~ dyslexia * iq |     dyslexia + iq,   data = ReadingSkills,   family = \"kw\",   control = gkw_control(method = \"L-BFGS-B\", maxit = 2000) ) summary(fit_kw) #>  #> Generalized Kumaraswamy Regression Model Summary #>  #> Family: kw  #>  #> Call: #> gkwreg(formula = accuracy ~ dyslexia * iq | dyslexia + iq, data = ReadingSkills,  #>     family = \"kw\", control = gkw_control(method = \"L-BFGS-B\",  #>         maxit = 2000)) #>  #> Residuals: #>     Min  Q1.25%  Median    Mean  Q3.75%     Max  #> -0.2641 -0.0305  0.0093  0.0159  0.0601  0.2986  #>  #> Coefficients: #>                   Estimate Std. Error z value Pr(>|z|)     #> alpha:(Intercept)   1.7158     0.2387   7.187 6.61e-13 *** #> alpha:dyslexia      0.8632     0.2522   3.422 0.000621 *** #> alpha:iq            1.2727     0.2244   5.671 1.42e-08 *** #> alpha:dyslexia:iq  -1.1788     0.1920  -6.139 8.29e-10 *** #> beta:(Intercept)    2.8774     0.5252   5.479 4.29e-08 *** #> beta:dyslexia       3.5541     0.5621   6.323 2.56e-10 *** #> beta:iq             1.0895     0.3788   2.876 0.004029 **  #> --- #> Signif. codes:  0 ‚Äò***‚Äô 0.001 ‚Äò**‚Äô 0.01 ‚Äò*‚Äô 0.05 ‚Äò.‚Äô 0.1 ‚Äò ‚Äô 1 #>  #> Confidence intervals (95%): #>                        3%     98% #> alpha:(Intercept)  1.2479  2.1837 #> alpha:dyslexia     0.3689  1.3576 #> alpha:iq           0.8329  1.7125 #> alpha:dyslexia:iq -1.5551 -0.8024 #> beta:(Intercept)   1.8480  3.9068 #> beta:dyslexia      2.4525  4.6558 #> beta:iq            0.3470  1.8320 #>  #> Link functions: #> alpha: log #> beta: log #>  #> Fitted parameter means: #> alpha: 26.55 #> beta: 204.8 #> gamma: 1 #> delta: 0 #> lambda: 1 #>  #> Model fit statistics: #> Number of observations: 44  #> Number of parameters: 7  #> Residual degrees of freedom: 37  #> Log-likelihood: 68.45  #> AIC: -122.9  #> BIC: -110.4  #> RMSE: 0.1094  #> Efron's R2: 0.6179  #> Mean Absolute Error: 0.0753  #>  #> Convergence status: Successful  #> Iterations: 82  #>   # Interpretation: # - Alpha (mean): Interaction shows dyslexic children benefit less from #   higher IQ compared to controls # - Beta (precision): Controls show more variable accuracy (higher precision) #   IQ increases consistency of performance  # Example 2: Simpler model without interaction fit_kw_simple <- gkwreg(   accuracy ~ dyslexia + iq |     dyslexia + iq,   data = ReadingSkills,   family = \"kw\",   control = gkw_control(method = \"L-BFGS-B\", maxit = 2000) )  # Test if interaction is significant anova(fit_kw_simple, fit_kw) #> Analysis of Deviance Table #>  #> Model 1: accuracy ~ dyslexia + iq | dyslexia + iq #> Model 2: accuracy ~ dyslexia * iq | dyslexia + iq #>  #>               Resid. Df Resid. Dev Df Deviance   Pr(>Chi)     #> fit_kw_simple  38.00000 -124.28762                            #> fit_kw         37.00000 -136.89181  1 12.60419 0.00038488 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1  # Example 3: Exponentiated Kumaraswamy for ceiling effects # Reading accuracy often shows ceiling effects (many perfect/near-perfect scores) # Lambda parameter can model this right-skewed asymmetry fit_ekw <- gkwreg(   accuracy ~ dyslexia * iq | # alpha     dyslexia + iq | # beta     dyslexia, # lambda: ceiling effect by group   data = ReadingSkills,   family = \"ekw\",   control = gkw_control(method = \"L-BFGS-B\", maxit = 2000) ) summary(fit_ekw) #>  #> Generalized Kumaraswamy Regression Model Summary #>  #> Family: ekw  #>  #> Call: #> gkwreg(formula = accuracy ~ dyslexia * iq | dyslexia + iq | dyslexia,  #>     data = ReadingSkills, family = \"ekw\", control = gkw_control(method = \"L-BFGS-B\",  #>         maxit = 2000)) #>  #> Residuals: #>     Min  Q1.25%  Median    Mean  Q3.75%     Max  #> -0.2448 -0.0245  0.0118  0.0152  0.0686  0.2099  #>  #> Coefficients: #>                    Estimate Std. Error z value Pr(>|z|)   #> alpha:(Intercept)   -1.9375     4.4607  -0.434   0.6640   #> alpha:dyslexia       5.3101     4.6178   1.150   0.2502   #> alpha:iq             2.3149     1.0256   2.257   0.0240 * #> alpha:dyslexia:iq   -2.3821     1.0518  -2.265   0.0235 * #> beta:(Intercept)     6.0410    10.6496   0.567   0.5705   #> beta:dyslexia        6.3493    10.6379   0.597   0.5506   #> beta:iq              0.5127     0.2861   1.792   0.0732 . #> lambda:(Intercept)   2.6467     3.8056   0.695   0.4868   #> lambda:dyslexia     -3.9111     4.0166  -0.974   0.3302   #> --- #> Signif. codes:  0 ‚Äò***‚Äô 0.001 ‚Äò**‚Äô 0.01 ‚Äò*‚Äô 0.05 ‚Äò.‚Äô 0.1 ‚Äò ‚Äô 1 #>  #> Confidence intervals (95%): #>                          3%     98% #> alpha:(Intercept)  -10.6804  6.8054 #> alpha:dyslexia      -3.7406 14.3608 #> alpha:iq             0.3047  4.3251 #> alpha:dyslexia:iq   -4.4436 -0.3206 #> beta:(Intercept)   -14.8319 26.9139 #> beta:dyslexia      -14.5006 27.1991 #> beta:iq             -0.0481  1.0734 #> lambda:(Intercept)  -4.8121 10.1054 #> lambda:dyslexia    -11.7836  3.9613 #>  #> Link functions: #> alpha: log #> beta: log #> lambda: log #>  #> Fitted parameter means: #> alpha: 13.45 #> beta: 81539 #> gamma: 1 #> delta: 0 #> lambda: 400.9 #>  #> Model fit statistics: #> Number of observations: 44  #> Number of parameters: 9  #> Residual degrees of freedom: 35  #> Log-likelihood: 70.62  #> AIC: -123.2  #> BIC: -107.2  #> RMSE: 0.09657  #> Efron's R2: 0.7022  #> Mean Absolute Error: 0.07239  #>  #> Convergence status: Failed  #> Iterations: 116  #>   # Interpretation: # - Lambda varies by dyslexia status: Controls have stronger ceiling effect #   (more compression at high accuracy) than dyslexic children  # Test if ceiling effect modeling improves fit anova(fit_kw, fit_ekw) #> Analysis of Deviance Table #>  #> Model 1: accuracy ~ dyslexia * iq | dyslexia + iq #> Model 2: accuracy ~ dyslexia * iq | dyslexia + iq | dyslexia #>  #>         Resid. Df Resid. Dev Df Deviance Pr(>Chi)   #> fit_kw   37.00000 -136.89181                        #> fit_ekw  35.00000 -141.23408  2  4.34227  0.11405   #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1  # Example 4: McDonald distribution alternative # Provides different parameterization for extreme values fit_mc <- gkwreg(   accuracy ~ dyslexia * iq | # gamma     dyslexia + iq | # delta     dyslexia * iq, # lambda: interaction affects tails   data = ReadingSkills,   family = \"mc\",   control = gkw_control(method = \"L-BFGS-B\", maxit = 2000) ) summary(fit_mc) #>  #> Generalized Kumaraswamy Regression Model Summary #>  #> Family: mc  #>  #> Call: #> gkwreg(formula = accuracy ~ dyslexia * iq | dyslexia + iq | dyslexia *  #>     iq, data = ReadingSkills, family = \"mc\", control = gkw_control(method = \"L-BFGS-B\",  #>     maxit = 2000)) #>  #> Residuals: #>     Min  Q1.25%  Median    Mean  Q3.75%     Max  #> -0.1376  0.0291  0.7058  0.5174  0.9899  0.9899  #>  #> Coefficients: #>                    Estimate Std. Error z value Pr(>|z|) #> gamma:(Intercept)    7.5706        NaN     NaN      NaN #> gamma:dyslexia       8.7744        NaN     NaN      NaN #> gamma:iq             0.8618        NaN     NaN      NaN #> gamma:dyslexia:iq   -2.8365        NaN     NaN      NaN #> delta:(Intercept)  -22.1613        NaN     NaN      NaN #> delta:dyslexia      61.0429        NaN     NaN      NaN #> delta:iq            -1.2393        NaN     NaN      NaN #> lambda:(Intercept)  -5.1483        NaN     NaN      NaN #> lambda:dyslexia     -8.1465        NaN     NaN      NaN #> lambda:iq           -0.3133        NaN     NaN      NaN #> lambda:dyslexia:iq   2.2443        NaN     NaN      NaN #>  #> Confidence intervals (95%): #>                     3% 98% #> gamma:(Intercept)  NaN NaN #> gamma:dyslexia     NaN NaN #> gamma:iq           NaN NaN #> gamma:dyslexia:iq  NaN NaN #> delta:(Intercept)  NaN NaN #> delta:dyslexia     NaN NaN #> delta:iq           NaN NaN #> lambda:(Intercept) NaN NaN #> lambda:dyslexia    NaN NaN #> lambda:iq          NaN NaN #> lambda:dyslexia:iq NaN NaN #>  #> Link functions: #> gamma: log #> delta: logit #> lambda: log #>  #> Fitted parameter means: #> alpha: 1 #> beta: 1 #> gamma: 49207316 #> delta: 4.318 #> lambda: 16.66 #>  #> Model fit statistics: #> Number of observations: 44  #> Number of parameters: 11  #> Residual degrees of freedom: 33  #> Log-likelihood: 60.78  #> AIC: -99.55  #> BIC: -79.93  #> RMSE: 0.6855  #> Efron's R2: -14  #> Mean Absolute Error: 0.5327  #>  #> Convergence status: Failed  #> Iterations: 177  #>   # Compare 3-parameter models AIC(fit_ekw, fit_mc) #>         df        AIC #> fit_ekw  9 -123.23408 #> fit_mc  11  -99.55165 # }"},{"path":"https://evandeilton.github.io/gkwreg/reference/StressAnxiety.html","id":null,"dir":"Reference","previous_headings":"","what":"Dependency of Anxiety on Stress ‚Äî StressAnxiety","title":"Dependency of Anxiety on Stress ‚Äî StressAnxiety","text":"Data study examining relationship stress anxiety levels among nonclinical women Townsville, Queensland, Australia.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/StressAnxiety.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dependency of Anxiety on Stress ‚Äî StressAnxiety","text":"","code":"StressAnxiety"},{"path":"https://evandeilton.github.io/gkwreg/reference/StressAnxiety.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Dependency of Anxiety on Stress ‚Äî StressAnxiety","text":"data frame 166 observations 2 variables: stress numeric. Stress score transformed open unit interval (0, 1). Original scale ranged 0 42 Depression Anxiety Stress Scales (DASS). anxiety numeric. Anxiety score transformed open unit interval (0, 1). Original scale ranged 0 42 DASS.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/StressAnxiety.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Dependency of Anxiety on Stress ‚Äî StressAnxiety","text":"Data Smithson Verkuilen (2006) supplements. Original data source specified.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/StressAnxiety.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Dependency of Anxiety on Stress ‚Äî StressAnxiety","text":"stress anxiety assessed using Depression Anxiety Stress Scales (DASS), ranging 0 42. Smithson Verkuilen (2006) transformed scores open unit interval (without providing specific details transformation method). dataset particularly interesting demonstrating heteroscedastic relationships: mean anxiety increase stress, variability anxiety also changes systematically stress levels. makes ideal case beta regression variable dispersion.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/StressAnxiety.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Dependency of Anxiety on Stress ‚Äî StressAnxiety","text":"Smithson, M., Verkuilen, J. (2006). Better Lemon Squeezer? Maximum-Likelihood Regression Beta-Distributed Dependent Variables. Psychological Methods, 11(1), 54‚Äì71.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/StressAnxiety.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Dependency of Anxiety on Stress ‚Äî StressAnxiety","text":"","code":"# \\donttest{ require(gkwreg) require(gkwdist)  data(StressAnxiety)  # Example 1: Basic heteroscedastic relationship # Mean anxiety increases with stress # Variability in anxiety also changes with stress fit_kw <- gkwreg(   anxiety ~ stress |     stress,   data = StressAnxiety,   family = \"kw\" ) summary(fit_kw) #>  #> Generalized Kumaraswamy Regression Model Summary #>  #> Family: kw  #>  #> Call: #> gkwreg(formula = anxiety ~ stress | stress, data = StressAnxiety,  #>     family = \"kw\") #>  #> Residuals: #>     Min  Q1.25%  Median    Mean  Q3.75%     Max  #> -0.2943 -0.0394 -0.0152  0.0012  0.0231  0.2738  #>  #> Coefficients: #>                   Estimate Std. Error z value Pr(>|z|)     #> alpha:(Intercept) -0.15576    0.09639  -1.616    0.106     #> alpha:stress       0.53167    0.33774   1.574    0.115     #> beta:(Intercept)   3.67043    0.30158  12.171  < 2e-16 *** #> beta:stress       -3.96207    0.81439  -4.865 1.14e-06 *** #> --- #> Signif. codes:  0 ‚Äò***‚Äô 0.001 ‚Äò**‚Äô 0.01 ‚Äò*‚Äô 0.05 ‚Äò.‚Äô 0.1 ‚Äò ‚Äô 1 #>  #> Confidence intervals (95%): #>                        3%     98% #> alpha:(Intercept) -0.3447  0.0332 #> alpha:stress      -0.1303  1.1936 #> beta:(Intercept)   3.0793  4.2615 #> beta:stress       -5.5582 -2.3659 #>  #> Link functions: #> alpha: log #> beta: log #>  #> Fitted parameter means: #> alpha: 0.9902 #> beta: 17.4 #> gamma: 1 #> delta: 0 #> lambda: 1 #>  #> Model fit statistics: #> Number of observations: 166  #> Number of parameters: 4  #> Residual degrees of freedom: 162  #> Log-likelihood: 305.5  #> AIC: -602.9  #> BIC: -590.5  #> RMSE: 0.08686  #> Efron's R2: 0.5677  #> Mean Absolute Error: 0.05871  #>  #> Convergence status: Successful  #> Iterations: 16  #>   # Interpretation: # - Alpha: Positive relationship between stress and mean anxiety # - Beta: Precision changes with stress level #   (anxiety becomes more/less variable at different stress levels)  # Compare to homoscedastic model fit_kw_homo <- gkwreg(anxiety ~ stress,   data = StressAnxiety, family = \"kw\" ) anova(fit_kw_homo, fit_kw) #> Analysis of Deviance Table #>  #> Model 1: anxiety ~ stress #> Model 2: anxiety ~ stress | stress #>  #>             Resid. Df Resid. Dev Df Deviance Pr(>Chi)     #> fit_kw_homo 163.00000 -588.89928                          #> fit_kw      162.00000 -610.94842  1 22.04913  < 1e-04 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1  # Example 2: Nonlinear stress effects via polynomial # Stress-anxiety relationship often shows threshold or saturation effects fit_kw_poly <- gkwreg(   anxiety ~ poly(stress, 2) | # quadratic mean     poly(stress, 2), # quadratic precision   data = StressAnxiety,   family = \"kw\" ) summary(fit_kw_poly) #>  #> Generalized Kumaraswamy Regression Model Summary #>  #> Family: kw  #>  #> Call: #> gkwreg(formula = anxiety ~ poly(stress, 2) | poly(stress, 2),  #>     data = StressAnxiety, family = \"kw\") #>  #> Residuals: #>     Min  Q1.25%  Median    Mean  Q3.75%     Max  #> -0.3104 -0.0498 -0.0116 -0.0028  0.0228  0.2447  #>  #> Coefficients: #>                        Estimate Std. Error z value Pr(>|z|)     #> alpha:(Intercept)       0.01689    0.06512   0.259 0.795292     #> alpha:poly(stress, 2)1  2.43589    1.01831   2.392 0.016752 *   #> alpha:poly(stress, 2)2  2.86240    1.04517   2.739 0.006168 **  #> beta:(Intercept)        2.72015    0.17477  15.565  < 2e-16 *** #> beta:poly(stress, 2)1  -9.58460    2.55838  -3.746 0.000179 *** #> beta:poly(stress, 2)2   7.09996    2.66543   2.664 0.007728 **  #> --- #> Signif. codes:  0 ‚Äò***‚Äô 0.001 ‚Äò**‚Äô 0.01 ‚Äò*‚Äô 0.05 ‚Äò.‚Äô 0.1 ‚Äò ‚Äô 1 #>  #> Confidence intervals (95%): #>                              3%     98% #> alpha:(Intercept)       -0.1107  0.1445 #> alpha:poly(stress, 2)1   0.4400  4.4317 #> alpha:poly(stress, 2)2   0.8139  4.9109 #> beta:(Intercept)         2.3776  3.0627 #> beta:poly(stress, 2)1  -14.5989 -4.5703 #> beta:poly(stress, 2)2    1.8758 12.3241 #>  #> Link functions: #> alpha: log #> beta: log #>  #> Fitted parameter means: #> alpha: 1.082 #> beta: 24.18 #> gamma: 1 #> delta: 0 #> lambda: 1 #>  #> Model fit statistics: #> Number of observations: 166  #> Number of parameters: 6  #> Residual degrees of freedom: 160  #> Log-likelihood: 309.9  #> AIC: -607.9  #> BIC: -589.2  #> RMSE: 0.08802  #> Efron's R2: 0.5561  #> Mean Absolute Error: 0.06071  #>  #> Convergence status: Successful  #> Iterations: 20  #>   # Interpretation: # - Quadratic terms allow for: #   * Threshold effects (anxiety accelerates at high stress) #   * Saturation effects (anxiety plateaus at extreme stress)  # Test nonlinearity anova(fit_kw, fit_kw_poly) #> Analysis of Deviance Table #>  #> Model 1: anxiety ~ stress | stress #> Model 2: anxiety ~ poly(stress, 2) | poly(stress, 2) #>  #>             Resid. Df Resid. Dev Df Deviance Pr(>Chi)   #> fit_kw      162.00000 -610.94842                        #> fit_kw_poly 160.00000 -619.88378  2  8.93537 0.011474 * #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1  # Example 3: Exponentiated Kumaraswamy for extreme anxiety patterns # Some individuals may show very extreme anxiety responses to stress fit_ekw <- gkwreg(   anxiety ~ poly(stress, 2) | # alpha: quadratic mean     poly(stress, 2) | # beta: quadratic precision     stress, # lambda: linear tail effect   data = StressAnxiety,   family = \"ekw\" ) summary(fit_ekw) #>  #> Generalized Kumaraswamy Regression Model Summary #>  #> Family: ekw  #>  #> Call: #> gkwreg(formula = anxiety ~ poly(stress, 2) | poly(stress, 2) |  #>     stress, data = StressAnxiety, family = \"ekw\") #>  #> Residuals: #>     Min  Q1.25%  Median    Mean  Q3.75%     Max  #> -0.1974 -0.0324 -0.0052  0.0110  0.0310  0.2990  #>  #> Coefficients: #>                        Estimate Std. Error z value Pr(>|z|)     #> alpha:(Intercept)       -1.9135     0.5103  -3.750 0.000177 *** #> alpha:poly(stress, 2)1   5.4724     1.7206   3.180 0.001470 **  #> alpha:poly(stress, 2)2   8.3272     1.2083   6.892 5.51e-12 *** #> beta:(Intercept)         1.6775     0.1531  10.954  < 2e-16 *** #> beta:poly(stress, 2)1   -5.0750     0.9539  -5.320 1.04e-07 *** #> beta:poly(stress, 2)2    5.2634     1.5502   3.395 0.000685 *** #> lambda:(Intercept)       7.7664     2.1310   3.644 0.000268 *** #> lambda:stress          -10.2013     2.7870  -3.660 0.000252 *** #> --- #> Signif. codes:  0 ‚Äò***‚Äô 0.001 ‚Äò**‚Äô 0.01 ‚Äò*‚Äô 0.05 ‚Äò.‚Äô 0.1 ‚Äò ‚Äô 1 #>  #> Confidence intervals (95%): #>                              3%     98% #> alpha:(Intercept)       -2.9136 -0.9133 #> alpha:poly(stress, 2)1   2.1000  8.8448 #> alpha:poly(stress, 2)2   5.9591 10.6954 #> beta:(Intercept)         1.3774  1.9777 #> beta:poly(stress, 2)1   -6.9447 -3.2053 #> beta:poly(stress, 2)2    2.2251  8.3016 #> lambda:(Intercept)       3.5897 11.9430 #> lambda:stress          -15.6637 -4.7389 #>  #> Link functions: #> alpha: log #> beta: log #> lambda: log #>  #> Fitted parameter means: #> alpha: 0.3187 #> beta: 6.38 #> gamma: 1 #> delta: 0 #> lambda: 510.3 #>  #> Model fit statistics: #> Number of observations: 166  #> Number of parameters: 8  #> Residual degrees of freedom: 158  #> Log-likelihood: 337.9  #> AIC: -659.9  #> BIC: -635  #> RMSE: 0.08709  #> Efron's R2: 0.5654  #> Mean Absolute Error: 0.05688  #>  #> Convergence status: Successful  #> Iterations: 37  #>   # Interpretation: # - Lambda: Linear component captures asymmetry at extreme stress levels #   (very high stress may produce different tail behavior)  # Example 4: McDonald distribution for highly skewed anxiety # Anxiety distributions are often right-skewed (ceiling effects) fit_mc <- gkwreg(   anxiety ~ poly(stress, 2) | # gamma     poly(stress, 2) | # delta     stress, # lambda: extremity   data = StressAnxiety,   family = \"mc\",   control = gkw_control(method = \"BFGS\", maxit = 1500) ) #> Warning: NaNs produced summary(fit_mc) #>  #> Generalized Kumaraswamy Regression Model Summary #>  #> Family: mc  #>  #> Call: #> gkwreg(formula = anxiety ~ poly(stress, 2) | poly(stress, 2) |  #>     stress, data = StressAnxiety, family = \"mc\", control = gkw_control(method = \"BFGS\",  #>     maxit = 1500)) #>  #> Residuals: #>     Min  Q1.25%  Median    Mean  Q3.75%     Max  #> -0.0499 -0.0499 -0.0297  0.0315  0.0701  0.6311  #>  #> Coefficients: #>                          Estimate Std. Error z value Pr(>|z|)     #> gamma:(Intercept)      -0.2351921  0.2665143  -0.882    0.378     #> gamma:poly(stress, 2)1  0.0190891        NaN     NaN      NaN     #> gamma:poly(stress, 2)2 -0.0009618  0.7054250  -0.001    0.999     #> delta:(Intercept)       0.0375628  0.1891093   0.199    0.843     #> delta:poly(stress, 2)1 -0.0066401  1.6486664  -0.004    0.997     #> delta:poly(stress, 2)2 -0.0032370        NaN     NaN      NaN     #> lambda:(Intercept)     -0.3680521  0.0287293 -12.811   <2e-16 *** #> lambda:stress          -0.0152252        NaN     NaN      NaN     #> --- #> Signif. codes:  0 ‚Äò***‚Äô 0.001 ‚Äò**‚Äô 0.01 ‚Äò*‚Äô 0.05 ‚Äò.‚Äô 0.1 ‚Äò ‚Äô 1 #>  #> Confidence intervals (95%): #>                             3%     98% #> gamma:(Intercept)      -0.7576  0.2872 #> gamma:poly(stress, 2)1     NaN     NaN #> gamma:poly(stress, 2)2 -1.3836  1.3816 #> delta:(Intercept)      -0.3331  0.4082 #> delta:poly(stress, 2)1 -3.2380  3.2247 #> delta:poly(stress, 2)2     NaN     NaN #> lambda:(Intercept)     -0.4244 -0.3117 #> lambda:stress              NaN     NaN #>  #> Link functions: #> gamma: log #> delta: logit #> lambda: log #>  #> Fitted parameter means: #> alpha: 1 #> beta: 1 #> gamma: 0.7904 #> delta: 5.094 #> lambda: 0.6891 #>  #> Model fit statistics: #> Number of observations: 166  #> Number of parameters: 8  #> Residual degrees of freedom: 158  #> Log-likelihood: 227.8  #> AIC: -439.5  #> BIC: -414.6  #> RMSE: 0.136  #> Efron's R2: -0.05914  #> Mean Absolute Error: 0.08386  #>  #> Convergence status: Successful  #> Iterations: 6  #>   # Compare models AIC(fit_kw, fit_kw_poly, fit_ekw, fit_mc) #>             df       AIC #> fit_kw       4 -602.9484 #> fit_kw_poly  6 -607.8838 #> fit_ekw      8 -659.8696 #> fit_mc       8 -439.5397  # Visualization: Stress-Anxiety relationship plot(anxiety ~ stress,   data = StressAnxiety,   xlab = \"Stress Level\", ylab = \"Anxiety Level\",   main = \"Stress-Anxiety Relationship with Heteroscedasticity\",   pch = 19, col = rgb(0, 0, 1, 0.3) )  # Add fitted curve stress_seq <- seq(min(StressAnxiety$stress), max(StressAnxiety$stress),   length.out = 100 ) pred_mean <- predict(fit_kw, newdata = data.frame(stress = stress_seq)) lines(stress_seq, pred_mean, col = \"red\", lwd = 2)  # Add lowess smooth for comparison lines(lowess(StressAnxiety$stress, StressAnxiety$anxiety),   col = \"blue\", lwd = 2, lty = 2 ) legend(\"topleft\",   legend = c(\"Kumaraswamy fit\", \"Lowess smooth\"),   col = c(\"red\", \"blue\"), lwd = 2, lty = c(1, 2) )  # }"},{"path":"https://evandeilton.github.io/gkwreg/reference/WeatherTask.html","id":null,"dir":"Reference","previous_headings":"","what":"Weather Task with Priming and Precise and Imprecise Probabilities ‚Äî WeatherTask","title":"Weather Task with Priming and Precise and Imprecise Probabilities ‚Äî WeatherTask","text":"Data cognitive psychology experiment probabilistic learning probability judgments. Participants estimated probabilities weather events different priming precision conditions.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/WeatherTask.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Weather Task with Priming and Precise and Imprecise Probabilities ‚Äî WeatherTask","text":"","code":"WeatherTask"},{"path":"https://evandeilton.github.io/gkwreg/reference/WeatherTask.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Weather Task with Priming and Precise and Imprecise Probabilities ‚Äî WeatherTask","text":"data frame 345 observations 4 variables: agreement numeric. Probability indicated participants, average minimum maximum estimates imprecise condition. Response variable scaled (0, 1). priming factor levels two-fold (case prime) seven-fold (class prime). Indicates partition priming condition. eliciting factor levels precise imprecise (lower upper limit). Indicates whether participants gave point estimates interval estimates.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/WeatherTask.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Weather Task with Priming and Precise and Imprecise Probabilities ‚Äî WeatherTask","text":"Taken Smithson et al. (2011) supplements.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/WeatherTask.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Weather Task with Priming and Precise and Imprecise Probabilities ‚Äî WeatherTask","text":"participants study either first- second-year undergraduate students psychology, none strong background probability familiar imprecise probability theories. Task description: Participants asked: \"probability temperature Canberra airport Sunday higher 'specified temperature'?\" Experimental manipulations: Priming: Two-fold (simple binary: /) vs. seven-fold (multiple temperature categories) Eliciting: Precise (single probability estimate) vs. imprecise (lower upper bounds) study examines partition priming (number response categories) elicitation format affect probability judgments. Classical findings suggest categories (seven-fold) lead different probability assessments binary categories (two-fold).","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/WeatherTask.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Weather Task with Priming and Precise and Imprecise Probabilities ‚Äî WeatherTask","text":"Smithson, M., Merkle, E.C., Verkuilen, J. (2011). Beta Regression Finite Mixture Models Polarization Priming. Journal Educational Behavioral Statistics, 36(6), 804‚Äì831. doi:10.3102/1076998610396893 Smithson, M., Segale, C. (2009). Partition Priming Judgments Imprecise Probabilities. Journal Statistical Theory Practice, 3(1), 169‚Äì181.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/WeatherTask.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Weather Task with Priming and Precise and Imprecise Probabilities ‚Äî WeatherTask","text":"","code":"# \\donttest{ require(gkwreg) require(gkwdist)  data(WeatherTask)  # Example 1: Main effects model # Probability judgments affected by priming and elicitation format fit_kw <- gkwreg(   agreement ~ priming + eliciting,   data = WeatherTask,   family = \"kw\" ) summary(fit_kw) #>  #> Generalized Kumaraswamy Regression Model Summary #>  #> Family: kw  #>  #> Call: #> gkwreg(formula = agreement ~ priming + eliciting, data = WeatherTask,  #>     family = \"kw\") #>  #> Residuals: #>     Min  Q1.25%  Median    Mean  Q3.75%     Max  #> -0.2941 -0.1053 -0.0494 -0.0063  0.0899  0.7053  #>  #> Coefficients: #>                          Estimate Std. Error z value Pr(>|z|)     #> alpha:(Intercept)         0.39534    0.06067   6.516 7.24e-11 *** #> alpha:primingseven-fold  -0.18903    0.05241  -3.606  0.00031 *** #> alpha:elicitingimprecise  0.21471    0.05233   4.103 4.07e-05 *** #> beta:(Intercept)          1.81969    0.09799  18.571  < 2e-16 *** #> --- #> Signif. codes:  0 ‚Äò***‚Äô 0.001 ‚Äò**‚Äô 0.01 ‚Äò*‚Äô 0.05 ‚Äò.‚Äô 0.1 ‚Äò ‚Äô 1 #>  #> Confidence intervals (95%): #>                               3%     98% #> alpha:(Intercept)         0.2764  0.5143 #> alpha:primingseven-fold  -0.2918 -0.0863 #> alpha:elicitingimprecise  0.1122  0.3173 #> beta:(Intercept)          1.6276  2.0117 #>  #> Link functions: #> alpha: log #> beta: log #>  #> Fitted parameter means: #> alpha: 1.524 #> beta: 6.164 #> gamma: 1 #> delta: 0 #> lambda: 1 #>  #> Model fit statistics: #> Number of observations: 345  #> Number of parameters: 4  #> Residual degrees of freedom: 341  #> Log-likelihood: 201.6  #> AIC: -395.2  #> BIC: -379.9  #> RMSE: 0.1541  #> Efron's R2: 0.08752  #> Mean Absolute Error: 0.1253  #>  #> Convergence status: Successful  #> Iterations: 25  #>   # Interpretation: # - Alpha: Seven-fold priming may shift probability estimates #   Imprecise elicitation may produce different mean estimates  # Example 2: Interaction model with heteroscedasticity # Priming effects may differ by elicitation format # Variability may also depend on conditions fit_kw_interact <- gkwreg(   agreement ~ priming * eliciting |     priming + eliciting,   data = WeatherTask,   family = \"kw\" ) summary(fit_kw_interact) #>  #> Generalized Kumaraswamy Regression Model Summary #>  #> Family: kw  #>  #> Call: #> gkwreg(formula = agreement ~ priming * eliciting | priming +  #>     eliciting, data = WeatherTask, family = \"kw\") #>  #> Residuals: #>     Min  Q1.25%  Median    Mean  Q3.75%     Max  #> -0.2930 -0.1159 -0.0320 -0.0052  0.0910  0.6891  #>  #> Coefficients: #>                                            Estimate Std. Error z value Pr(>|z|) #> alpha:(Intercept)                           0.26198    0.08991   2.914  0.00357 #> alpha:primingseven-fold                     0.10566    0.10814   0.977  0.32850 #> alpha:elicitingimprecise                    0.21199    0.11980   1.769  0.07681 #> alpha:primingseven-fold:elicitingimprecise  0.08181    0.10438   0.784  0.43317 #> beta:(Intercept)                            1.46021    0.15558   9.385  < 2e-16 #> beta:primingseven-fold                      0.85229    0.20297   4.199 2.68e-05 #> beta:elicitingimprecise                     0.09174    0.19953   0.460  0.64566 #>                                                #> alpha:(Intercept)                          **  #> alpha:primingseven-fold                        #> alpha:elicitingimprecise                   .   #> alpha:primingseven-fold:elicitingimprecise     #> beta:(Intercept)                           *** #> beta:primingseven-fold                     *** #> beta:elicitingimprecise                        #> --- #> Signif. codes:  0 ‚Äò***‚Äô 0.001 ‚Äò**‚Äô 0.01 ‚Äò*‚Äô 0.05 ‚Äò.‚Äô 0.1 ‚Äò ‚Äô 1 #>  #> Confidence intervals (95%): #>                                                 3%    98% #> alpha:(Intercept)                           0.0858 0.4382 #> alpha:primingseven-fold                    -0.1063 0.3176 #> alpha:elicitingimprecise                   -0.0228 0.4468 #> alpha:primingseven-fold:elicitingimprecise -0.1228 0.2864 #> beta:(Intercept)                            1.1553 1.7651 #> beta:primingseven-fold                      0.4545 1.2501 #> beta:elicitingimprecise                    -0.2993 0.4828 #>  #> Link functions: #> alpha: log #> beta: log #>  #> Fitted parameter means: #> alpha: 1.566 #> beta: 7.428 #> gamma: 1 #> delta: 0 #> lambda: 1 #>  #> Model fit statistics: #> Number of observations: 345  #> Number of parameters: 7  #> Residual degrees of freedom: 338  #> Log-likelihood: 210.9  #> AIC: -407.8  #> BIC: -380.9  #> RMSE: 0.1537  #> Efron's R2: 0.09164  #> Mean Absolute Error: 0.124  #>  #> Convergence status: Successful  #> Iterations: 31  #>   # Interpretation: # - Alpha: Interaction tests if partition priming works differently #   for precise vs. imprecise probability judgments # - Beta: Precision varies by experimental condition  # Test interaction anova(fit_kw, fit_kw_interact) #> Analysis of Deviance Table #>  #> Model 1: agreement ~ priming + eliciting #> Model 2: agreement ~ priming * eliciting | priming + eliciting #>  #>                 Resid. Df Resid. Dev Df Deviance   Pr(>Chi)     #> fit_kw          341.00000 -403.23406                            #> fit_kw_interact 338.00000 -421.81480  3 18.58074 0.00033376 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1  # Example 3: McDonald distribution for polarized responses # Probability judgments often show polarization (clustering at extremes) # particularly under certain priming conditions fit_mc <- gkwreg(   agreement ~ priming * eliciting | # gamma     priming * eliciting | # delta     priming, # lambda: priming affects polarization   data = WeatherTask,   family = \"mc\",   control = gkw_control(method = \"BFGS\", maxit = 1500) ) summary(fit_mc) #>  #> Generalized Kumaraswamy Regression Model Summary #>  #> Family: mc  #>  #> Call: #> gkwreg(formula = agreement ~ priming * eliciting | priming *  #>     eliciting | priming, data = WeatherTask, family = \"mc\", control = gkw_control(method = \"BFGS\",  #>     maxit = 1500)) #>  #> Residuals: #>     Min  Q1.25%  Median    Mean  Q3.75%     Max  #> -0.2027 -0.0727 -0.0416  0.0351  0.1084  0.7564  #>  #> Coefficients: #>                                             Estimate Std. Error z value #> gamma:(Intercept)                           0.090319   0.222111   0.407 #> gamma:primingseven-fold                     0.036067   0.426063   0.085 #> gamma:elicitingimprecise                    0.054185   0.522357   0.104 #> gamma:primingseven-fold:elicitingimprecise  0.023760   0.566762   0.042 #> delta:(Intercept)                          -0.039825   0.534925  -0.074 #> delta:primingseven-fold                    -0.010793   0.644386  -0.017 #> delta:elicitingimprecise                   -0.025605   1.096937  -0.023 #> delta:primingseven-fold:elicitingimprecise -0.008725   1.274826  -0.007 #> lambda:(Intercept)                          0.165563   0.026202   6.319 #> lambda:primingseven-fold                    0.062143   0.216997   0.286 #>                                            Pr(>|z|)     #> gamma:(Intercept)                             0.684     #> gamma:primingseven-fold                       0.933     #> gamma:elicitingimprecise                      0.917     #> gamma:primingseven-fold:elicitingimprecise    0.967     #> delta:(Intercept)                             0.941     #> delta:primingseven-fold                       0.987     #> delta:elicitingimprecise                      0.981     #> delta:primingseven-fold:elicitingimprecise    0.995     #> lambda:(Intercept)                         2.64e-10 *** #> lambda:primingseven-fold                      0.775     #> --- #> Signif. codes:  0 ‚Äò***‚Äô 0.001 ‚Äò**‚Äô 0.01 ‚Äò*‚Äô 0.05 ‚Äò.‚Äô 0.1 ‚Äò ‚Äô 1 #>  #> Confidence intervals (95%): #>                                                 3%    98% #> gamma:(Intercept)                          -0.3450 0.5256 #> gamma:primingseven-fold                    -0.7990 0.8711 #> gamma:elicitingimprecise                   -0.9696 1.0780 #> gamma:primingseven-fold:elicitingimprecise -1.0871 1.1346 #> delta:(Intercept)                          -1.0883 1.0086 #> delta:primingseven-fold                    -1.2738 1.2522 #> delta:elicitingimprecise                   -2.1756 2.1244 #> delta:primingseven-fold:elicitingimprecise -2.5073 2.4899 #> lambda:(Intercept)                          0.1142 0.2169 #> lambda:primingseven-fold                   -0.3632 0.4874 #>  #> Link functions: #> gamma: log #> delta: logit #> lambda: log #>  #> Fitted parameter means: #> alpha: 1 #> beta: 1 #> gamma: 1.151 #> delta: 4.851 #> lambda: 1.216 #>  #> Model fit statistics: #> Number of observations: 345  #> Number of parameters: 10  #> Residual degrees of freedom: 335  #> Log-likelihood: 175.9  #> AIC: -331.8  #> BIC: -293.4  #> RMSE: 0.1669  #> Efron's R2: -0.07105  #> Mean Absolute Error: 0.1242  #>  #> Convergence status: Successful  #> Iterations: 7  #>   # Interpretation: # - Lambda varies by priming: Seven-fold priming may produce more #   extreme/polarized probability judgments # }"},{"path":"https://evandeilton.github.io/gkwreg/reference/anova.gkwreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Analysis of Deviance for GKw Regression Models ‚Äî anova.gkwreg","title":"Analysis of Deviance for GKw Regression Models ‚Äî anova.gkwreg","text":"Computes analysis deviance table one fitted Generalized Kumaraswamy (GKw) regression model objects. multiple models provided, likelihood ratio tests performed compare nested models.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/anova.gkwreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Analysis of Deviance for GKw Regression Models ‚Äî anova.gkwreg","text":"","code":"# S3 method for class 'gkwreg' anova(object, ..., test = c(\"Chisq\", \"none\"))"},{"path":"https://evandeilton.github.io/gkwreg/reference/anova.gkwreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Analysis of Deviance for GKw Regression Models ‚Äî anova.gkwreg","text":"object object class \"gkwreg\", typically obtained gkwreg. ... Additional objects class \"gkwreg\" model comparison. Models must nested fitted dataset. test character string specifying test statistic use. Currently \"Chisq\" (default) supported, performs likelihood ratio tests. Can also \"none\" tests.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/anova.gkwreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Analysis of Deviance for GKw Regression Models ‚Äî anova.gkwreg","text":"object class c(\"anova.gkwreg\", \"anova\", \"data.frame\"), following columns: Resid. Df Residual degrees freedom Resid. Dev Residual deviance (-2 √ó log-likelihood) Df Change degrees freedom (model comparisons) Deviance Change deviance (model comparisons) Pr(>Chi) P-value chi-squared test (test = \"Chisq\")","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/anova.gkwreg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Analysis of Deviance for GKw Regression Models ‚Äî anova.gkwreg","text":"single model provided, function returns table showing residual degrees freedom deviance. multiple models provided, function compares using likelihood ratio tests (LRT). Models automatically ordered complexity (degrees freedom). LRT statistic computed : $$LRT = 2(\\ell_1 - \\ell_0)$$ \\(\\ell_1\\) log-likelihood complex model \\(\\ell_0\\) log-likelihood simpler (nested) model. null hypothesis simpler model adequate, LRT statistic follows chi-squared distribution degrees freedom equal difference number parameters models. Important: method assumes models compared nested (.e., one model special case ) fitted data. Comparing non-nested models models fitted different datasets produce unreliable results. Use AIC BIC comparing non-nested models. deviance defined \\(-2 \\times \\text{log-likelihood}\\). models fitted maximum likelihood, smaller (negative) deviances indicate better fit. Note deviance can negative log-likelihood positive, occurs density values exceed 1 (common continuous distributions bounded intervals). matters inference change deviance models, positive complex model fits better.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/anova.gkwreg.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Analysis of Deviance for GKw Regression Models ‚Äî anova.gkwreg","text":"Wilks, S. S. (1938). large-sample distribution likelihood ratio testing composite hypotheses. Annals Mathematical Statistics, 9(1), 60‚Äì62. doi:10.1214/aoms/1177732360 Pawitan, Y. (2001). Likelihood: Statistical Modelling Inference Using Likelihood. Oxford University Press.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwreg/reference/anova.gkwreg.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Analysis of Deviance for GKw Regression Models ‚Äî anova.gkwreg","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/anova.gkwreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Analysis of Deviance for GKw Regression Models ‚Äî anova.gkwreg","text":"","code":"# \\donttest{ # Load example data data(GasolineYield)  # Fit a series of nested models fit1 <- gkwreg(yield ~ 1, data = GasolineYield, family = \"kw\") fit2 <- gkwreg(yield ~ temp, data = GasolineYield, family = \"kw\") fit3 <- gkwreg(yield ~ batch + temp, data = GasolineYield, family = \"kw\") #> Warning: NaNs produced  # ANOVA table for single model anova(fit3) #> Analysis of Deviance Table #>  #> Model: gkwreg(formula = yield ~ batch + temp, data = GasolineYield,  #> Model:     family = \"kw\") #>  #>   Resid. Df Resid. Dev #> 1  20.00000 -193.93784  # Compare nested models using likelihood ratio tests anova(fit1, fit2, fit3) #> Analysis of Deviance Table #>  #> Model 1: yield ~ 1 #> Model 2: yield ~ temp #> Model 3: yield ~ batch + temp #>  #>      Resid. Df Resid. Dev Df  Deviance Pr(>Chi)     #> fit1  30.00000  -57.02258                           #> fit2  29.00000  -80.90259  1  23.88001  < 1e-04 *** #> fit3  20.00000 -193.93784  9 113.03525  < 1e-04 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #> Model 1 vs 2: Adding temperature is highly significant (p < 0.001) #> Model 2 vs 3: Adding batch is highly significant (p < 0.001)  # Compare two models anova(fit2, fit3, test = \"Chisq\") #> Analysis of Deviance Table #>  #> Model 1: yield ~ temp #> Model 2: yield ~ batch + temp #>  #>      Resid. Df Resid. Dev Df  Deviance Pr(>Chi)     #> fit2  29.00000  -80.90259                           #> fit3  20.00000 -193.93784  9 113.03525  < 1e-04 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1  # Suppress test statistics anova(fit1, fit2, fit3, test = \"none\") #> Analysis of Deviance Table #>  #> Model 1: yield ~ 1 #> Model 2: yield ~ temp #> Model 3: yield ~ batch + temp #>  #>      Resid. Df Resid. Dev Df  Deviance #> fit1  30.00000  -57.02258              #> fit2  29.00000  -80.90259  1  23.88001 #> fit3  20.00000 -193.93784  9 113.03525 # }"},{"path":"https://evandeilton.github.io/gkwreg/reference/coef.gkwreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Coefficients from a Fitted GKw Regression Model ‚Äî coef.gkwreg","title":"Extract Coefficients from a Fitted GKw Regression Model ‚Äî coef.gkwreg","text":"Extracts estimated regression coefficients fitted Generalized Kumaraswamy (GKw) regression model object class \"gkwreg\". S3 method generic coef function.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/coef.gkwreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Coefficients from a Fitted GKw Regression Model ‚Äî coef.gkwreg","text":"","code":"# S3 method for class 'gkwreg' coef(object, ...)"},{"path":"https://evandeilton.github.io/gkwreg/reference/coef.gkwreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Coefficients from a Fitted GKw Regression Model ‚Äî coef.gkwreg","text":"object object class \"gkwreg\", typically result call gkwreg. ... Additional arguments, currently ignored method.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/coef.gkwreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Coefficients from a Fitted GKw Regression Model ‚Äî coef.gkwreg","text":"named numeric vector containing estimated regression coefficients modeled parameters. names indicate parameter (e.g., alpha, beta) corresponding predictor variable (e.g., (Intercept), x1).","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/coef.gkwreg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract Coefficients from a Fitted GKw Regression Model ‚Äî coef.gkwreg","text":"function provides standard way access estimated regression coefficients model fitted gkwreg. simply extracts coefficients component fitted model object. function coefficients alias function.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwreg/reference/coef.gkwreg.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract Coefficients from a Fitted GKw Regression Model ‚Äî coef.gkwreg","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/confint.gkwreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Confidence Intervals for Generalized Kumaraswamy Regression Parameters ‚Äî confint.gkwreg","title":"Confidence Intervals for Generalized Kumaraswamy Regression Parameters ‚Äî confint.gkwreg","text":"Computes confidence intervals model parameters fitted gkwreg objects using Wald (normal approximation) method based asymptotic theory.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/confint.gkwreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Confidence Intervals for Generalized Kumaraswamy Regression Parameters ‚Äî confint.gkwreg","text":"","code":"# S3 method for class 'gkwreg' confint(object, parm, level = 0.95, ...)"},{"path":"https://evandeilton.github.io/gkwreg/reference/confint.gkwreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Confidence Intervals for Generalized Kumaraswamy Regression Parameters ‚Äî confint.gkwreg","text":"object object class \"gkwreg\" gkwreg. parm specification parameters given confidence intervals, either vector numbers vector names. missing, parameters considered. level confidence level required. Default 0.95. ... Additional arguments (currently unused).","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/confint.gkwreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Confidence Intervals for Generalized Kumaraswamy Regression Parameters ‚Äî confint.gkwreg","text":"matrix (vector) columns giving lower upper confidence limits parameter. labeled (1-level)/2 1 - (1-level)/2 percent (default 2.5 percent 97.5 percent).","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/confint.gkwreg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Confidence Intervals for Generalized Kumaraswamy Regression Parameters ‚Äî confint.gkwreg","text":"confidence intervals computed using Wald method based asymptotic normality maximum likelihood estimators: $$CI = \\hat{\\theta} \\pm z_{\\alpha/2} \\times SE(\\hat{\\theta})$$ \\(z_{\\alpha/2}\\) appropriate normal quantile \\(SE(\\hat{\\theta})\\) standard error Hessian matrix. model must fitted hessian = TRUE (default) gkw_control. standard errors available, error raised.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwreg/reference/confint.gkwreg.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Confidence Intervals for Generalized Kumaraswamy Regression Parameters ‚Äî confint.gkwreg","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/confint.gkwreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Confidence Intervals for Generalized Kumaraswamy Regression Parameters ‚Äî confint.gkwreg","text":"","code":"# \\donttest{ data(GasolineYield) fit <- gkwreg(yield ~ batch + temp, data = GasolineYield, family = \"kw\") #> Warning: NaNs produced  # 95 percent confidence intervals confint(fit) #> Warning: some standard errors are NA or infinite; intervals may be unreliable #>                         2.5 %     97.5 % #> alpha:(Intercept)  0.61295476  0.7257544 #> alpha:batch1       0.78585088  0.8904090 #> alpha:batch2       0.53536141  0.6471869 #> alpha:batch3       0.65450034  0.7660730 #> alpha:batch4       0.41450496  0.5190080 #> alpha:batch5       0.46463077  0.5758895 #> alpha:batch6       0.39393615  0.5056346 #> alpha:batch7       0.17262525  0.2769125 #> alpha:batch8       0.14778262  0.2585841 #> alpha:batch9       0.07938588  0.2043050 #> alpha:temp                NaN        NaN #> beta:(Intercept)  28.03403986 29.7293552  # 90 percent confidence intervals confint(fit, level = 0.90) #> Warning: some standard errors are NA or infinite; intervals may be unreliable #>                           5 %       95 % #> alpha:(Intercept)  0.62202236  0.7166868 #> alpha:batch1       0.79425597  0.8820039 #> alpha:batch2       0.54435070  0.6381976 #> alpha:batch3       0.66346930  0.7571040 #> alpha:batch4       0.42290563  0.5106073 #> alpha:batch5       0.47357450  0.5669458 #> alpha:batch6       0.40291523  0.4966556 #> alpha:batch7       0.18100857  0.2685292 #> alpha:batch8       0.15668960  0.2496771 #> alpha:batch9       0.08942772  0.1942632 #> alpha:temp                NaN        NaN #> beta:(Intercept)  28.17032079 29.5930743  # Specific parameters confint(fit, parm = \"alpha:(Intercept)\") #> Warning: some standard errors are NA or infinite; intervals may be unreliable #>                       2.5 %    97.5 % #> alpha:(Intercept) 0.6129548 0.7257544 confint(fit, parm = 1:3) #> Warning: some standard errors are NA or infinite; intervals may be unreliable #>                       2.5 %    97.5 % #> alpha:(Intercept) 0.6129548 0.7257544 #> alpha:batch1      0.7858509 0.8904090 #> alpha:batch2      0.5353614 0.6471869 # }"},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-check_and_compile_TMB_code.html","id":null,"dir":"Reference","previous_headings":"","what":"Check and Compile TMB Model Code with Persistent Cache ‚Äî .check_and_compile_TMB_code","title":"Check and Compile TMB Model Code with Persistent Cache ‚Äî .check_and_compile_TMB_code","text":"utility function verifies whether TMB model shared object (./.dll) file already compiled specified DLL name. , compiles corresponding C++ file caches persistent directory across R sessions.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-check_and_compile_TMB_code.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check and Compile TMB Model Code with Persistent Cache ‚Äî .check_and_compile_TMB_code","text":"","code":".check_and_compile_TMB_code(   dll_name,   pkg_name = \"gkwreg\",   force_recompile = FALSE,   verbose = FALSE )"},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-check_and_compile_TMB_code.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check and Compile TMB Model Code with Persistent Cache ‚Äî .check_and_compile_TMB_code","text":"dll_name character string specifying base name C++ file resulting DLL. function assumes code file dll_name.cpp located inst/tmb/ directory package. pkg_name character string specifying package name. Defaults \"gkwreg\". force_recompile Logical; TRUE, forces recompilation even valid compiled file exists (default FALSE). verbose Logical; TRUE, prints detailed status messages (default TRUE).","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-check_and_compile_TMB_code.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check and Compile TMB Model Code with Persistent Cache ‚Äî .check_and_compile_TMB_code","text":"Returns (invisibly) list information compiled model, including path, normalized path, name, compilation status. step fails, error thrown.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-check_and_compile_TMB_code.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check and Compile TMB Model Code with Persistent Cache ‚Äî .check_and_compile_TMB_code","text":"function works following steps: Creates persistent cache directory storing compiled TMB models. Checks compiled file specified DLL already exists cache directory whether --date compared source code. valid compiled file exists, loads directly. , function locates corresponding C++ file inside package, compiles , stores result cache directory. Provides diagnostic messages regarding compilation status exported symbols.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-convert_links_to_int.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert Link Function Names to TMB Integers ‚Äî .convert_links_to_int","title":"Convert Link Function Names to TMB Integers ‚Äî .convert_links_to_int","text":"Convert Link Function Names TMB Integers","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-convert_links_to_int.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert Link Function Names to TMB Integers ‚Äî .convert_links_to_int","text":"","code":".convert_links_to_int(link_list)"},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-convert_links_to_int.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert Link Function Names to TMB Integers ‚Äî .convert_links_to_int","text":"link_list List link function names","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-convert_links_to_int.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert Link Function Names to TMB Integers ‚Äî .convert_links_to_int","text":"List link function integers TMB","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-extract_model_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Model Data for GKw Regression ‚Äî .extract_model_data","title":"Extract Model Data for GKw Regression ‚Äî .extract_model_data","text":"Extract Model Data GKw Regression","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-extract_model_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Model Data for GKw Regression ‚Äî .extract_model_data","text":"","code":".extract_model_data(   formula_list,   data,   subset,   weights,   na.action,   offset,   contrasts,   original_call )"},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-extract_model_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Model Data for GKw Regression ‚Äî .extract_model_data","text":"formula_list List formulas parameter. data Data frame containing variables. subset Optional subset specification. weights Optional weights. na.action Function handle missing values. offset Optional offset. contrasts List contrasts factors. original_call original function call.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-extract_model_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Model Data for GKw Regression ‚Äî .extract_model_data","text":"list model data including frames, matrices, etc.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-format_coefficient_names.html","id":null,"dir":"Reference","previous_headings":"","what":"Format Coefficient Names Based on Family and Model Matrices ‚Äî .format_coefficient_names","title":"Format Coefficient Names Based on Family and Model Matrices ‚Äî .format_coefficient_names","text":"Format Coefficient Names Based Family Model Matrices","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-format_coefficient_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Format Coefficient Names Based on Family and Model Matrices ‚Äî .format_coefficient_names","text":"","code":".format_coefficient_names(param_names, model_data, param_positions)"},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-format_coefficient_names.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Format Coefficient Names Based on Family and Model Matrices ‚Äî .format_coefficient_names","text":"param_names Names parameters family model_data Model data list including matrices param_positions Parameter position mapping family","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-format_coefficient_names.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Format Coefficient Names Based on Family and Model Matrices ‚Äî .format_coefficient_names","text":"Vector formatted coefficient names","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-get_family_param_info.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Parameter Information for a GKw Family Distribution ‚Äî .get_family_param_info","title":"Get Parameter Information for a GKw Family Distribution ‚Äî .get_family_param_info","text":"Get Parameter Information GKw Family Distribution","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-get_family_param_info.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Parameter Information for a GKw Family Distribution ‚Äî .get_family_param_info","text":"","code":".get_family_param_info(family)"},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-get_family_param_info.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Parameter Information for a GKw Family Distribution ‚Äî .get_family_param_info","text":"family GKw family distribution name.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-get_family_param_info.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Parameter Information for a GKw Family Distribution ‚Äî .get_family_param_info","text":"list parameter information.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-prepare_tmb_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare TMB Data for GKw Regression ‚Äî .prepare_tmb_data","title":"Prepare TMB Data for GKw Regression ‚Äî .prepare_tmb_data","text":"Prepare TMB Data GKw Regression","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-prepare_tmb_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare TMB Data for GKw Regression ‚Äî .prepare_tmb_data","text":"","code":".prepare_tmb_data(   model_data,   family,   param_names,   fixed,   link_ints,   link_scale_list,   y,   param_positions )"},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-prepare_tmb_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare TMB Data for GKw Regression ‚Äî .prepare_tmb_data","text":"model_data List model data. family Family name. param_names Names parameters. fixed List fixed parameters coefficients. link_ints List link function integers. link_scale_list List link scale values. y Response variable. param_positions Parameter position mapping family.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-prepare_tmb_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare TMB Data for GKw Regression ‚Äî .prepare_tmb_data","text":"list TMB data.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-prepare_tmb_params.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare TMB Parameters for GKw Regression ‚Äî .prepare_tmb_params","title":"Prepare TMB Parameters for GKw Regression ‚Äî .prepare_tmb_params","text":"Prepare TMB Parameters GKw Regression","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-prepare_tmb_params.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare TMB Parameters for GKw Regression ‚Äî .prepare_tmb_params","text":"","code":".prepare_tmb_params(model_data, family, param_names, fixed, param_positions)"},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-prepare_tmb_params.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare TMB Parameters for GKw Regression ‚Äî .prepare_tmb_params","text":"model_data List model data. family Family name. param_names Names parameters. fixed List fixed parameters. param_positions Parameter position mapping family.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-prepare_tmb_params.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare TMB Parameters for GKw Regression ‚Äî .prepare_tmb_params","text":"list TMB parameters.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-process_fixed.html","id":null,"dir":"Reference","previous_headings":"","what":"Process Fixed Parameters for GKw Regression ‚Äî .process_fixed","title":"Process Fixed Parameters for GKw Regression ‚Äî .process_fixed","text":"Process Fixed Parameters GKw Regression","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-process_fixed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process Fixed Parameters for GKw Regression ‚Äî .process_fixed","text":"","code":".process_fixed(fixed, param_names, fixed_params)"},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-process_fixed.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process Fixed Parameters for GKw Regression ‚Äî .process_fixed","text":"fixed List fixed parameters coefficients. param_names Names parameters specified family. fixed_params List fixed parameters family definition.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-process_fixed.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process Fixed Parameters for GKw Regression ‚Äî .process_fixed","text":"list processed fixed parameters coefficients.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-process_formula_parts.html","id":null,"dir":"Reference","previous_headings":"","what":"Process Formula Parts from a Formula Object ‚Äî .process_formula_parts","title":"Process Formula Parts from a Formula Object ‚Äî .process_formula_parts","text":"Process Formula Parts Formula Object","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-process_formula_parts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process Formula Parts from a Formula Object ‚Äî .process_formula_parts","text":"","code":".process_formula_parts(formula_obj, param_names, fixed_params, data)"},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-process_formula_parts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process Formula Parts from a Formula Object ‚Äî .process_formula_parts","text":"formula_obj Formula object created Formula package. param_names Names parameters specified family. fixed_params List fixed parameters. data Data frame containing variables.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-process_formula_parts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process Formula Parts from a Formula Object ‚Äî .process_formula_parts","text":"list formula objects parameter.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-process_link.html","id":null,"dir":"Reference","previous_headings":"","what":"Process Link Functions for GKw Regression ‚Äî .process_link","title":"Process Link Functions for GKw Regression ‚Äî .process_link","text":"Process Link Functions GKw Regression","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-process_link.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process Link Functions for GKw Regression ‚Äî .process_link","text":"","code":".process_link(link, param_names, fixed_params)"},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-process_link.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process Link Functions for GKw Regression ‚Äî .process_link","text":"link character string list character strings specifying link functions. param_names Names parameters specified family. fixed_params List fixed parameters.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-process_link.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process Link Functions for GKw Regression ‚Äî .process_link","text":"list link functions.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-process_link_scale.html","id":null,"dir":"Reference","previous_headings":"","what":"Process Link Scales for GKw Regression ‚Äî .process_link_scale","title":"Process Link Scales for GKw Regression ‚Äî .process_link_scale","text":"Process Link Scales GKw Regression","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-process_link_scale.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process Link Scales for GKw Regression ‚Äî .process_link_scale","text":"","code":".process_link_scale(link_scale, link_list, param_names, fixed_params)"},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-process_link_scale.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process Link Scales for GKw Regression ‚Äî .process_link_scale","text":"link_scale numeric value list specifying scales link functions. link_list List link functions parameter. param_names Names parameters specified family. fixed_params List fixed parameters.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-process_link_scale.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process Link Scales for GKw Regression ‚Äî .process_link_scale","text":"list link scales.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-validate_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate Data for GKw Regression ‚Äî .validate_data","title":"Validate Data for GKw Regression ‚Äî .validate_data","text":"Validate Data GKw Regression","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-validate_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate Data for GKw Regression ‚Äî .validate_data","text":"","code":".validate_data(data, n_params)"},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-validate_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate Data for GKw Regression ‚Äî .validate_data","text":"data Numeric vector validate. n_params Number parameters selected model.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/dot-validate_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate Data for GKw Regression ‚Äî .validate_data","text":"validated data.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/family.gkwreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Family from GKw Regression Model ‚Äî family.gkwreg","title":"Extract Family from GKw Regression Model ‚Äî family.gkwreg","text":"Extracts family specification fitted Generalized Kumaraswamy regression model object.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/family.gkwreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Family from GKw Regression Model ‚Äî family.gkwreg","text":"","code":"# S3 method for class 'gkwreg' family(object, ...)"},{"path":"https://evandeilton.github.io/gkwreg/reference/family.gkwreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Family from GKw Regression Model ‚Äî family.gkwreg","text":"object object class \"gkwreg\". ... Currently used.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/family.gkwreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Family from GKw Regression Model ‚Äî family.gkwreg","text":"character string indicating family used model.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwreg/reference/family.gkwreg.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract Family from GKw Regression Model ‚Äî family.gkwreg","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/family.gkwreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Family from GKw Regression Model ‚Äî family.gkwreg","text":"","code":"# \\donttest{ data(GasolineYield) fit <- gkwreg(yield ~ batch + temp, data = GasolineYield, family = \"kw\") #> Warning: NaNs produced family(fit) #> [1] \"kw\" # }"},{"path":"https://evandeilton.github.io/gkwreg/reference/fitted.gkwreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Fitted Values from a Generalized Kumaraswamy Regression Model ‚Äî fitted.gkwreg","title":"Extract Fitted Values from a Generalized Kumaraswamy Regression Model ‚Äî fitted.gkwreg","text":"Extracts fitted mean values (predicted expected values response) fitted Generalized Kumaraswamy (GKw) regression model object class \"gkwreg\". S3 method generic fitted.values function.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/fitted.gkwreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Fitted Values from a Generalized Kumaraswamy Regression Model ‚Äî fitted.gkwreg","text":"","code":"# S3 method for class 'gkwreg' fitted(object, family = NULL, ...)"},{"path":"https://evandeilton.github.io/gkwreg/reference/fitted.gkwreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Fitted Values from a Generalized Kumaraswamy Regression Model ‚Äî fitted.gkwreg","text":"object object class \"gkwreg\", typically result call gkwreg. family Character string specifying distribution family fitted mean values calculated. NULL (default), family stored within fitted object used. Specifying different family (e.g., \"beta\") trigger recalculation fitted means based family's mean structure, using original model's estimated coefficients mapped relevant parameters. Available options match gkwreg: \"gkw\", \"bkw\", \"kkw\", \"ekw\", \"mc\", \"kw\", \"beta\". ... Additional arguments, currently ignored method.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/fitted.gkwreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Fitted Values from a Generalized Kumaraswamy Regression Model ‚Äî fitted.gkwreg","text":"numeric vector containing fitted mean values. values typically bounded 0 1, corresponding scale original response variable. length vector corresponds number observations used model fit (considering subset na.action).","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/fitted.gkwreg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract Fitted Values from a Generalized Kumaraswamy Regression Model ‚Äî fitted.gkwreg","text":"function retrieves calculates fitted values, represent estimated conditional mean response variable given covariates (\\(E(Y | X)\\)). function attempts retrieve fitted values efficiently using following priority: Directly fitted.values component stored object, available complete. includes logic handle potentially incomplete stored values via interpolation (approx) large datasets sample might stored. recalculating mean using stored parameter vectors observation (object$parameter_vectors) internal function (calculateMeans), available. fitted component within TMB report (object$tmb_object$report()), available, potentially using interpolation . fallback, calling predict(object, type = \"response\", family = family). Specifying family different one used fit model always force recalculation using predict method (step 4).","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwreg/reference/fitted.gkwreg.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract Fitted Values from a Generalized Kumaraswamy Regression Model ‚Äî fitted.gkwreg","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/fitted.gkwreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Fitted Values from a Generalized Kumaraswamy Regression Model ‚Äî fitted.gkwreg","text":"","code":"# \\donttest{ require(gkwreg) require(gkwdist)  # Example 1: Basic usage with FoodExpenditure data data(FoodExpenditure) FoodExpenditure$prop <- FoodExpenditure$food / FoodExpenditure$income  fit_kw <- gkwreg(prop ~ income + persons | income,   data = FoodExpenditure,   family = \"kw\" )  # Extract fitted values fitted_vals <- fitted(fit_kw)  # Visualize fit quality plot(FoodExpenditure$prop, fitted_vals,   xlab = \"Observed Proportion\",   ylab = \"Fitted Values\",   main = \"Observed vs Fitted: Food Expenditure\",   pch = 19, col = rgb(0, 0, 1, 0.5) ) abline(0, 1, col = \"red\", lwd = 2)   # Calculate R-squared analogue cor(FoodExpenditure$prop, fitted_vals)^2 #> [1] 0.4596754  # Example 2: Comparing fitted values across families data(GasolineYield)  fit_ekw <- gkwreg(yield ~ batch + temp | temp | batch,   data = GasolineYield,   family = \"ekw\" )  # Fitted values under different family assumptions fitted_ekw <- fitted(fit_ekw) fitted_kw <- fitted(fit_ekw, family = \"kw\") #> Using different family (kw) than what was used to fit the model (ekw). Recalculating fitted values... fitted_beta <- fitted(fit_ekw, family = \"beta\") #> Using different family (beta) than what was used to fit the model (ekw). Recalculating fitted values...  # Compare differences comparison <- data.frame(   EKW = fitted_ekw,   KW = fitted_kw,   Beta = fitted_beta,   Diff_EKW_KW = fitted_ekw - fitted_kw,   Diff_EKW_Beta = fitted_ekw - fitted_beta ) head(comparison) #>          EKW         KW       Beta Diff_EKW_KW Diff_EKW_Beta #> 1 0.12232728 0.12232728 0.12232728           0             0 #> 2 0.00010000 0.00010000 0.00010000           0             0 #> 3 0.35297443 0.35297443 0.35297443           0             0 #> 4 0.46181798 0.46181798 0.46181798           0             0 #> 5 0.06734871 0.06734871 0.06734871           0             0 #> 6 0.12862292 0.12862292 0.12862292           0             0  # Visualize differences par(mfrow = c(1, 2)) plot(fitted_ekw, fitted_kw,   xlab = \"EKW Fitted\", ylab = \"KW Fitted\",   main = \"EKW vs KW Family Assumptions\",   pch = 19, col = \"darkblue\" ) abline(0, 1, col = \"red\", lty = 2)  plot(fitted_ekw, fitted_beta,   xlab = \"EKW Fitted\", ylab = \"Beta Fitted\",   main = \"EKW vs Beta Family Assumptions\",   pch = 19, col = \"darkgreen\" ) abline(0, 1, col = \"red\", lty = 2)  par(mfrow = c(1, 1))  # Example 3: Diagnostic plot with confidence bands data(ReadingSkills)  fit_mc <- gkwreg(   accuracy ~ dyslexia * iq | dyslexia + iq | dyslexia,   data = ReadingSkills,   family = \"mc\" )  fitted_vals <- fitted(fit_mc)  # Residual plot residuals_resp <- ReadingSkills$accuracy - fitted_vals  plot(fitted_vals, residuals_resp,   xlab = \"Fitted Values\",   ylab = \"Raw Residuals\",   main = \"Residual Plot: Reading Accuracy\",   pch = 19, col = ReadingSkills$dyslexia,   ylim = range(residuals_resp) * 1.2 ) abline(h = 0, col = \"red\", lwd = 2, lty = 2) lowess_fit <- lowess(fitted_vals, residuals_resp) lines(lowess_fit, col = \"blue\", lwd = 2) legend(\"topright\",   legend = c(\"Control\", \"Dyslexic\", \"Zero Line\", \"Lowess\"),   col = c(\"black\", \"red\", \"red\", \"blue\"),   pch = c(19, 19, NA, NA),   lty = c(NA, NA, 2, 1),   lwd = c(NA, NA, 2, 2) )   # Example 4: Large dataset efficiency check set.seed(2024) n <- 5000 x1 <- rnorm(n) x2 <- runif(n, -2, 2) alpha <- exp(0.3 + 0.5 * x1) beta <- exp(1.2 - 0.4 * x2) y <- rkw(n, alpha, beta) large_data <- data.frame(y = y, x1 = x1, x2 = x2)  fit_large <- gkwreg(y ~ x1 | x2,   data = large_data,   family = \"kw\" )  # Time the extraction system.time({   fitted_large <- fitted(fit_large) }) #>    user  system elapsed  #>       0       0       0   # Verify extraction length(fitted_large) #> [1] 5000 summary(fitted_large) #>     Min.  1st Qu.   Median     Mean  3rd Qu.     Max.  #> 0.003856 0.207005 0.322890 0.330228 0.440560 0.848744  # }"},{"path":"https://evandeilton.github.io/gkwreg/reference/formula.gkwreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Formula from GKw Regression Model ‚Äî formula.gkwreg","title":"Extract Formula from GKw Regression Model ‚Äî formula.gkwreg","text":"Extracts model formula fitted Generalized Kumaraswamy regression model object. Properly handles formulas 5 parts.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/formula.gkwreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Formula from GKw Regression Model ‚Äî formula.gkwreg","text":"","code":"# S3 method for class 'gkwreg' formula(x, ...)"},{"path":"https://evandeilton.github.io/gkwreg/reference/formula.gkwreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Formula from GKw Regression Model ‚Äî formula.gkwreg","text":"x object class \"gkwreg\". ... Currently used.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/formula.gkwreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Formula from GKw Regression Model ‚Äî formula.gkwreg","text":"formula used fit model. multi-part formulas, returns object class \"Formula\".","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwreg/reference/formula.gkwreg.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract Formula from GKw Regression Model ‚Äî formula.gkwreg","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/formula.gkwreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Formula from GKw Regression Model ‚Äî formula.gkwreg","text":"","code":"# \\donttest{ data(GasolineYield)  # Simple formula fit1 <- gkwreg(yield ~ batch + temp, data = GasolineYield, family = \"kw\") #> Warning: NaNs produced formula(fit1) #> yield ~ batch + temp #> <environment: 0x56406b46b728>  # Two-part formula fit2 <- gkwreg(yield ~ temp | batch, data = GasolineYield, family = \"kw\") #> Warning: NaNs produced formula(fit2) #> yield ~ temp | batch #> <environment: 0x56406b46b728>  # Five-part formula fit3 <- gkwreg(yield ~ temp | batch | temp | 1 | 1,   data = GasolineYield, family = \"gkw\" ) formula(fit3) #> yield ~ temp | batch | temp | 1 | 1 #> <environment: 0x56406b46b728> # }"},{"path":"https://evandeilton.github.io/gkwreg/reference/getCall.gkwreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Call from GKw Regression Model ‚Äî getCall.gkwreg","title":"Get Call from GKw Regression Model ‚Äî getCall.gkwreg","text":"Extracts call used fit Generalized Kumaraswamy regression model.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/getCall.gkwreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Call from GKw Regression Model ‚Äî getCall.gkwreg","text":"","code":"# S3 method for class 'gkwreg' getCall(x, ...)"},{"path":"https://evandeilton.github.io/gkwreg/reference/getCall.gkwreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Call from GKw Regression Model ‚Äî getCall.gkwreg","text":"x object class \"gkwreg\". ... Currently used.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/getCall.gkwreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Call from GKw Regression Model ‚Äî getCall.gkwreg","text":"matched call.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwreg/reference/getCall.gkwreg.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Get Call from GKw Regression Model ‚Äî getCall.gkwreg","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/getCall.gkwreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Call from GKw Regression Model ‚Äî getCall.gkwreg","text":"","code":"# \\donttest{ data(GasolineYield) fit <- gkwreg(yield ~ batch + temp, data = GasolineYield, family = \"kw\") #> Warning: NaNs produced getCall(fit) #> gkwreg(formula = yield ~ batch + temp, data = GasolineYield,  #>     family = \"kw\") # }"},{"path":"https://evandeilton.github.io/gkwreg/reference/gkw_control.html","id":null,"dir":"Reference","previous_headings":"","what":"Control Parameters for Generalized Kumaraswamy Regression ‚Äî gkw_control","title":"Control Parameters for Generalized Kumaraswamy Regression ‚Äî gkw_control","text":"Auxiliary function controlling gkwreg() fitting process. function consolidates technical/advanced fitting options one place, keeping main gkwreg() interface clean user-friendly. Follows design pattern glm.control, betareg.control, similar control functions R.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/gkw_control.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Control Parameters for Generalized Kumaraswamy Regression ‚Äî gkw_control","text":"","code":"gkw_control(   method = c(\"nlminb\", \"BFGS\", \"Nelder-Mead\", \"CG\", \"SANN\", \"L-BFGS-B\"),   start = NULL,   fixed = NULL,   hessian = TRUE,   maxit = 500,   reltol = sqrt(.Machine$double.eps),   abstol = 0,   trace = 0,   silent = TRUE,   eval.max = 500,   iter.max = 300,   step.min = 1e-08,   step.max = 1,   x.tol = 1.5e-08,   rel.tol = sqrt(.Machine$double.eps),   alpha = 1,   beta = 0.5,   gamma = 2,   warn.1d.NelderMead = TRUE,   type = 1,   temp = 10,   tmax = 10,   lmm = 5,   factr = 1e+07,   pgtol = 0,   REPORT = NULL,   fnscale = 1,   parscale = NULL,   ndeps = NULL,   ... )  # S3 method for class 'gkw_control' print(x, ...)"},{"path":"https://evandeilton.github.io/gkwreg/reference/gkw_control.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Control Parameters for Generalized Kumaraswamy Regression ‚Äî gkw_control","text":"method Character string specifying optimization algorithm. Options: \"nlminb\" (default), \"BFGS\", \"Nelder-Mead\", \"CG\", \"SANN\", \"L-BFGS-B\". \"nlminb\", uses nlminb; otherwise uses optim specified method. start Optional named list starting values regression coefficients. Names match parameter names (alpha, beta, gamma, delta, lambda). NULL (default), starting values determined automatically. fixed Optional named list parameters hold fixed specific values estimation. Currently experimental. Default NULL. hessian Logical. TRUE (default), compute Hessian matrix via sdreport obtain standard errors variance-covariance matrix. Set FALSE faster fitting standard errors needed. maxit Integer. Maximum number iterations optimizer. Default 500 derivative-based methods, 10000 SANN. Increase difficult optimization problems. reltol Numeric. Relative convergence tolerance optimizer. Default sqrt(.Machine$double.eps) approx. 1.5e-8. Smaller values require tighter convergence may increase computation time. Used Nelder-Mead, BFGS, CG methods. abstol Numeric. Absolute convergence tolerance. Default 0. Used optimization methods additional stopping criterion. trace Integer. Controls verbosity optimizer. 0: Silent (default) 1: Print iteration progress 2+: Print detailed diagnostic information (6 L-BFGS-B) Ignored silent = TRUE. silent Logical. TRUE (default), suppress progress messages TMB compilation optimization. Set FALSE debugging monitor long-running fits. eval.max Integer. Maximum number function evaluations (nlminb ). Default 500. Increase difficult optimization problems. iter.max Integer. Maximum number iterations (nlminb ). Default 300. Usually less eval.max. step.min Numeric. Minimum step length (nlminb ). Default 1e-8. Controls small steps can become stopping. step.max Numeric. Maximum step length (nlminb ). Default 1. Useful preventing overshooting difficult optimization problems. x.tol Numeric. Tolerance parameter convergence (nlminb ). Default 1.5e-8. Optimizer stops parameter changes smaller . rel.tol Numeric. Relative tolerance function value (nlminb ). Default sqrt(.Machine$double.eps). Alternative specification relative tolerance. alpha Numeric. Reflection factor Nelder-Mead method. Default 1.0. used method = \"Nelder-Mead\". beta Numeric. Contraction factor Nelder-Mead method. Default 0.5. used method = \"Nelder-Mead\". gamma Numeric. Expansion factor Nelder-Mead method. Default 2.0. used method = \"Nelder-Mead\". warn.1d.NelderMead Logical. Whether warn Nelder-Mead used one-dimensional optimization. Default TRUE. type Integer. Update formula CG method. Options: 1: Fletcher-Reeves update 2: Polak-Ribiere update 3: Beale-Sorenson update Default 1. used method = \"CG\". temp Numeric. Starting temperature SANN method. Default 10. used method = \"SANN\". tmax Integer. Number function evaluations temperature SANN method. Default 10. used method = \"SANN\". lmm Integer. Number BFGS updates retained L-BFGS-B method. Default 5. used method = \"L-BFGS-B\". factr Numeric. Convergence tolerance factor L-BFGS-B method. Convergence occurs reduction objective within factor machine tolerance. Default 1e7 (tolerance ~1e-8). used method = \"L-BFGS-B\". pgtol Numeric. Tolerance projected gradient L-BFGS-B method. Default 0 (check suppressed). used method = \"L-BFGS-B\". REPORT Integer. Frequency progress reports BFGS, L-BFGS-B SANN methods trace > 0. Default 10 BFGS/L-BFGS-B, 100 SANN. fnscale Numeric. Overall scaling applied function value gradient optimization. Default 1. negative, turns problem maximization problem. parscale Numeric vector. Scaling values parameters. Optimization performed par/parscale. Default rep(1, n_params). ndeps Numeric vector. Step sizes finite-difference approximation gradient. Default 1e-3. ... Additional arguments passed optimizer. Allows fine-grained control without formally adding parameters. Advanced users . x object class \"gkw_control\".","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/gkw_control.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Control Parameters for Generalized Kumaraswamy Regression ‚Äî gkw_control","text":"object class \"gkw_control\", list containing control parameters validated default-filled values. object passed gkwreg() via control argument.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/gkw_control.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Control Parameters for Generalized Kumaraswamy Regression ‚Äî gkw_control","text":"function provides centralized way set technical parameters model fitting. serves several purposes: Clean interface: gkwreg() fewer arguments Organized documentation: technical options documented Input validation: Parameters validated fitting Extensibility: New options can added without changing gkwreg() Backward compatibility: Old code continues working Method-specific parameters: optimization method accepts different control parameters: Nelder-Mead: alpha, beta, gamma, maxit, reltol, abstol, trace, REPORT, warn.1d.NelderMead BFGS: maxit, reltol, abstol, trace, REPORT CG: type, maxit, reltol, abstol, trace SANN: temp, tmax, maxit, trace, REPORT L-BFGS-B: lmm, factr, pgtol, trace, REPORT use gkw_control(): users never need adjust settings. Use gkw_control() : Optimization fails converge (increase maxit, adjust tolerances) Debugging fit problems (set silent = FALSE, trace = 1) Comparing optimizers (try method = \"BFGS\" vs \"nlminb\") Fine-tuning performance (disable hessian SEs needed) Using custom starting values (start = list(...)) Recommended practices: Start defaults, adjust needed Increase maxit adjusting tolerances Use trace = 1 diagnose convergence issues Disable hessian speed point estimates needed Try different methods one fails (BFGS often robust) L-BFGS-B bounds, adjust factr pgtol needed","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/gkw_control.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Control Parameters for Generalized Kumaraswamy Regression ‚Äî gkw_control","text":"Nocedal, J., & Wright, S. J. (2006). Numerical Optimization (2nd ed.). Springer. Belisle, C. J. P. (1992). Convergence theorems class simulated annealing algorithms R^d. Journal Applied Probability, 29, 885-895. Byrd, R. H., Lu, P., Nocedal, J. Zhu, C. (1995). limited memory algorithm bound constrained optimization. SIAM Journal Scientific Computing, 16, 1190-1208.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwreg/reference/gkw_control.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Control Parameters for Generalized Kumaraswamy Regression ‚Äî gkw_control","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/gkw_control.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Control Parameters for Generalized Kumaraswamy Regression ‚Äî gkw_control","text":"","code":"# \\donttest{ # Default control (used automatically if not specified) ctrl <- gkw_control() print(ctrl) #> Generalized Kumaraswamy Control Parameters #> =========================================== #>  #> Optimization: #>   Method:             nlminb  #>   Max evaluations:    500  #>   Max iterations:     300  #>   Relative tolerance: 1.490116e-08  #>   Absolute tolerance: 0e+00  #>  #> Output: #>   Compute Hessian:    TRUE  #>   Silent mode:        TRUE   # Increase iterations for difficult problem ctrl_robust <- gkw_control(maxit = 1000, trace = 1)  # Try alternative optimizer ctrl_bfgs <- gkw_control(method = \"BFGS\")  # Fast fitting without standard errors ctrl_fast <- gkw_control(hessian = FALSE)  # Verbose debugging ctrl_debug <- gkw_control(silent = FALSE, trace = 2)  # Custom starting values ctrl_start <- gkw_control(   start = list(     alpha = c(0.5, 0.2),     beta = c(1.0, -0.3)   ) )  # Configure Nelder-Mead with custom reflection/contraction ctrl_nm <- gkw_control(   method = \"Nelder-Mead\",   alpha = 1.5,   beta = 0.75 )  # Configure L-BFGS-B for bounded optimization ctrl_lbfgsb <- gkw_control(   method = \"L-BFGS-B\",   factr = 1e6,   lmm = 10 )  # Configure SANN for rough surfaces ctrl_sann <- gkw_control(   method = \"SANN\",   temp = 20,   tmax = 20,   maxit = 20000 ) # }"},{"path":"https://evandeilton.github.io/gkwreg/reference/gkwreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit Generalized Kumaraswamy Regression Models ‚Äî gkwreg","title":"Fit Generalized Kumaraswamy Regression Models ‚Äî gkwreg","text":"Fits regression models using Generalized Kumaraswamy (GKw) family distributions modeling response variables strictly bounded interval (0, 1). function provides unified interface fitting seven nested submodels GKw family, allowing flexible modeling proportions, rates, bounded continuous outcomes regression distributional parameters. Maximum Likelihood Estimation performed via automatic differentiation using TMB (Template Model Builder) package, ensuring computational efficiency numerical accuracy. interface follows standard R regression modeling conventions similar lm, glm, betareg, making immediately familiar R users.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/gkwreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit Generalized Kumaraswamy Regression Models ‚Äî gkwreg","text":"","code":"gkwreg(   formula,   data,   family = c(\"gkw\", \"bkw\", \"kkw\", \"ekw\", \"mc\", \"kw\", \"beta\"),   link = NULL,   link_scale = NULL,   subset = NULL,   weights = NULL,   offset = NULL,   na.action = getOption(\"na.action\"),   contrasts = NULL,   control = gkw_control(),   model = TRUE,   x = FALSE,   y = TRUE,   ... )"},{"path":"https://evandeilton.github.io/gkwreg/reference/gkwreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit Generalized Kumaraswamy Regression Models ‚Äî gkwreg","text":"formula object class Formula (one can coerced class). formula uses extended syntax specify potentially different linear predictors distribution parameter: y ~ model_alpha | model_beta | model_gamma | model_delta | model_lambda : y response variable (must open interval (0, 1)) model_alpha specifies predictors \\(\\alpha\\) parameter model_beta specifies predictors \\(\\beta\\) parameter model_gamma specifies predictors \\(\\gamma\\) parameter model_delta specifies predictors \\(\\delta\\) parameter model_lambda specifies predictors \\(\\lambda\\) parameter part omitted specified ~ 1, intercept-model used parameter. Parts corresponding fixed parameters (determined family) automatically ignored. See Details Examples proper usage. data data frame containing variables specified formula. Standard R subsetting missing value handling apply. family character string specifying distribution family Generalized Kumaraswamy hierarchy. Must one : \"gkw\" Generalized Kumaraswamy (default). Five parameters: \\(\\alpha, \\beta, \\gamma, \\delta, \\lambda\\). flexible, suitable data show complex behavior captured simpler families. \"bkw\" Beta-Kumaraswamy. Four parameters: \\(\\alpha, \\beta, \\gamma, \\delta\\) (fixes \\(\\lambda = 1\\)). Combines Beta Kumaraswamy flexibility. \"kkw\" Kumaraswamy-Kumaraswamy. Four parameters: \\(\\alpha, \\beta, \\delta, \\lambda\\) (fixes \\(\\gamma = 1\\)). Alternative four-parameter generalization. \"ekw\" Exponentiated Kumaraswamy. Three parameters: \\(\\alpha, \\beta, \\lambda\\) (fixes \\(\\gamma = 1, \\delta = 0\\)). Adds flexibility standard Kumaraswamy. \"mc\" McDonald (Beta Power). Three parameters: \\(\\gamma, \\delta, \\lambda\\) (fixes \\(\\alpha = 1, \\beta = 1\\)). Generalization Beta distribution. \"kw\" Kumaraswamy. Two parameters: \\(\\alpha, \\beta\\) (fixes \\(\\gamma = 1, \\delta = 0, \\lambda = 1\\)). Computationally efficient alternative Beta closed-form CDF. \"beta\" Beta distribution. Two parameters: \\(\\gamma, \\delta\\) (fixes \\(\\alpha = 1, \\beta = 1, \\lambda = 1\\)). Standard choice proportions rates, corresponds shape1 = \\(\\gamma\\), shape2 = \\(\\delta\\). See Details guidance family selection. link Link function(s) distributional parameters. Can specified : Single character string: link relevant parameters. Example: link = \"log\" applies log link parameters. Named list: Parameter-specific links fine control. Example: link = list(alpha = \"log\", beta = \"log\", delta = \"logit\") Default links (used link = NULL): \"log\" \\(\\alpha, \\beta, \\gamma, \\lambda\\) (positive parameters) \"logit\" \\(\\delta\\) (parameter (0, 1)) Available link functions: \"log\" Logarithmic link. Maps \\((0, \\infty) \\(-\\infty, \\infty)\\). Ensures positivity. common shape parameters. \"logit\" Logistic link. Maps \\((0, 1) \\(-\\infty, \\infty)\\). Standard probability-type parameters like \\(\\delta\\). \"probit\" Probit link using normal CDF. Maps \\((0, 1) \\(-\\infty, \\infty)\\). Alternative logit, symmetric tails. \"cloglog\" Complementary log-log. Maps \\((0, 1) \\(-\\infty, \\infty)\\). Asymmetric, useful skewed probabilities. \"cauchy\" Cauchy link using Cauchy CDF. Maps \\((0, 1) \\(-\\infty, \\infty)\\). Heavy-tailed alternative probit. \"identity\" Identity link (transformation). Use caution; guarantee parameter constraints. \"sqrt\" Square root link. Maps \\(x \\\\sqrt{x}\\). Variance-stabilizing contexts. \"inverse\" Inverse link. Maps \\(x \\1/x\\). Useful rate-type parameters. \"inverse-square\" Inverse squared link. Maps \\(x \\1/x^2\\). link_scale Numeric scale factor(s) controlling transformation intensity link functions. Can : Single numeric: scale parameters. Named list: Parameter-specific scales fine-tuning. Example: link_scale = list(alpha = 10, beta = 10, delta = 1) Default scales (used link_scale = NULL): 10 \\(\\alpha, \\beta, \\gamma, \\lambda\\) 1 \\(\\delta\\) Larger values produce gradual transformations; smaller values produce extreme transformations. probability-type links (logit, probit), smaller scales (e.g., 0.5-2) create steeper response curves, larger scales (e.g., 5-20) create gentler curves. Adjust convergence issues arise need different response sensitivities. subset Optional vector specifying subset observations used fitting. Can logical vector, integer indices, expression evaluating one . Standard R subsetting rules apply. weights Optional numeric vector prior weights (e.g., frequency weights) observations. non-negative. Currently experimental; use caution validate results. offset Optional numeric vector matrix specifying priori known component included linear predictor(s). vector, applied first parameter's predictor. matrix, columns correspond parameters order (\\(\\alpha, \\beta, \\gamma, \\delta, \\lambda\\)). Offsets added linear predictor applying link function. na.action function specifying handle missing values (NAs). Options include: na.fail Stop error NAs present (default via getOption(\"na.action\")) na.omit Remove observations NAs na.exclude Like na.omit preserves original length residuals/fitted values See na.action details. contrasts Optional list specifying contrasts factor variables model. Format: named list names factor variable names values contrast specifications. See contrasts contrasts.arg argument model.matrix. control list control parameters gkw_control specifying technical details fitting process. includes: Optimization algorithm (method) Starting values (start) Fixed parameters (fixed) Convergence tolerances (maxit, reltol, abstol) Hessian computation (hessian) Verbosity (silent, trace) Default gkw_control() uses sensible defaults problems. See gkw_control complete documentation options. users never need modify control parameters. model Logical. TRUE (default), model frame (data frame containing variables used fitting) returned component model result. Useful prediction diagnostics. Set FALSE reduce object size. x Logical. TRUE, list model matrices (one modeled parameter) returned component x. Default FALSE. Set TRUE need direct access design matrices custom calculations. y Logical. TRUE (default), response vector (processing na.action subset) returned component y. Useful residual calculations diagnostics. ... Additional arguments. Currently used backward compatibility deprecated arguments earlier versions. Using deprecated arguments triggers informative warnings migration guidance. Examples deprecated arguments: plot, conf.level, method, start, fixed, hessian, silent, optimizer.control. now passed via control argument.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/gkwreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit Generalized Kumaraswamy Regression Models ‚Äî gkwreg","text":"object class \"gkwreg\", list containing following components. Standard S3 methods available class (see Methods section). Model Specification: call matched function call formula Formula object used family Character string: distribution family used link Named list: link functions parameter link_scale Named list: link scale values parameter param_names Character vector: names parameters family fixed_params Named list: parameters fixed family definition control gkw_control object used fitting Parameter Estimates: coefficients Named numeric vector: estimated regression coefficients (link scale). Names follow pattern \"parameter:predictor\", e.g., \"alpha:(Intercept)\", \"alpha:x1\", \"beta:(Intercept)\", \"beta:x2\". fitted_parameters Named list: mean values distribution parameter (\\(\\alpha, \\beta, \\gamma, \\delta, \\lambda\\)) averaged across observations parameter_vectors Named list: observation-specific parameter values. Contains vectors alphaVec, betaVec, gammaVec, deltaVec, lambdaVec, length nobs Fitted Values Residuals: fitted.values Numeric vector: fitted mean values \\(E[Y|X]\\) observation residuals Numeric vector: response residuals (observed - fitted) observation Inference: vcov Variance-covariance matrix coefficient estimates. present control$hessian = TRUE. NULL otherwise. se Numeric vector: standard errors coefficients. present control$hessian = TRUE. NULL otherwise. Model Fit Statistics: loglik Numeric: maximized log-likelihood value aic Numeric: Akaike Information Criterion (AIC = -2loglik + 2npar) bic Numeric: Bayesian Information Criterion (BIC = -2*loglik + log(nobs)*npar) deviance Numeric: deviance (-2 * loglik) df.residual Integer: residual degrees freedom (nobs - npar) nobs Integer: number observations used fit npar Integer: total number estimated parameters Diagnostic Statistics: rmse Numeric: Root Mean Squared Error response residuals efron_r2 Numeric: Efron's pseudo R-squared (1 - SSE/SST, SSE = sum squared errors, SST = total sum squares) mean_absolute_error Numeric: Mean Absolute Error response residuals Optimization Details: convergence Logical: TRUE optimizer converged successfully, FALSE otherwise message Character: convergence message optimizer iterations Integer: number iterations used optimizer method Character: optimization method used (e.g., \"nlminb\", \"BFGS\") Optional Components (returned requested via model, x, y): model Data frame: model frame (model = TRUE) x Named list: model matrices parameter (x = TRUE) y Numeric vector: response variable (y = TRUE) Internal: tmb_object raw object returned MakeADFun. Contains TMB automatic differentiation function environment. Primarily internal use advanced debugging.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwreg/reference/gkwreg.html","id":"distribution-family-selection","dir":"Reference","previous_headings":"","what":"Distribution Family Selection","title":"Fit Generalized Kumaraswamy Regression Models ‚Äî gkwreg","text":"Generalized Kumaraswamy family provides flexible hierarchy modeling bounded responses. Selection guided : 1. Start Simple: Begin two-parameter families (\"kw\" \"beta\") unless strong reasons use complex models. 2. Model Comparison: Use information criteria (AIC, BIC) likelihood ratio tests compare nested models: 3. Family Characteristics: Beta: Traditional choice, well-understood, good symmetric moderately skewed data Kumaraswamy (kw): Computationally efficient alternative Beta, closed-form CDF, similar flexibility Exponentiated Kumaraswamy (ekw): Adds flexibility extreme values heavy tails Beta-Kumaraswamy (bkw), Kumaraswamy-Kumaraswamy (kkw): Four-parameter alternatives three parameters insufficient McDonald (mc): Beta generalization via power parameter, useful J-shaped distributions Kumaraswamy-Kumaraswamy (kkw): flexible, use simpler families inadequate. extends kw Generalized Kumaraswamy (gkw): flexible, use simpler families inadequate 4. Avoid Overfitting: different parameters better model. Use cross-validation hold-validation assess predictive performance.","code":"# Fit sequence of nested models   fit_kw   <- gkwreg(y ~ x, data, family = \"kw\")   fit_ekw  <- gkwreg(y ~ x, data, family = \"ekw\")   fit_gkw  <- gkwreg(y ~ x, data, family = \"gkw\")    # Compare via AIC   AIC(fit_kw, fit_ekw, fit_gkw)    # Formal test (nested models only)   anova(fit_kw, fit_ekw, fit_gkw)"},{"path":"https://evandeilton.github.io/gkwreg/reference/gkwreg.html","id":"formula-specification","dir":"Reference","previous_headings":"","what":"Formula Specification","title":"Fit Generalized Kumaraswamy Regression Models ‚Äî gkwreg","text":"extended formula syntax allows different predictors parameter: Basic Examples: Important Notes: Formula parts correspond parameters order: \\(\\alpha\\), \\(\\beta\\), \\(\\gamma\\), \\(\\delta\\), \\(\\lambda\\) Unused parts (due family constraints) automatically ignored Use . include predictors: y ~ . | . Standard R formula features work: interactions (x1:x2), polynomials (poly(x, 2)), transformations (log(x)), etc.","code":"# Same predictors for both parameters (two-parameter family)   y ~ x1 + x2   # Equivalent to: y ~ x1 + x2 | x1 + x2    # Different predictors per parameter   y ~ x1 + x2 | x3 + x4   # alpha depends on x1, x2   # beta depends on x3, x4    # Intercept-only for some parameters   y ~ x1 | 1   # alpha depends on x1   # beta has only intercept    # Complex specification (five-parameter family)   y ~ x1 | x2 | x3 | x4 | x5   # alpha ~ x1, beta ~ x2, gamma ~ x3, delta ~ x4, lambda ~ x5"},{"path":"https://evandeilton.github.io/gkwreg/reference/gkwreg.html","id":"link-functions-and-scales","dir":"Reference","previous_headings":"","what":"Link Functions and Scales","title":"Fit Generalized Kumaraswamy Regression Models ‚Äî gkwreg","text":"Link functions map range distributional parameters real line, ensuring parameter constraints satisfied optimization. Choosing Links: Defaults usually best: automatic choices (log shape parameters, logit delta) work well cases Alternative links: Consider theoretical reasons (e.g., probit latent variable interpretation) convergence issues Identity link: Avoid unless constraints elsewhere; can lead invalid parameter values optimization Link Scales: link_scale parameter controls transformation intensity. Think \"sensitivity\" parameter: Larger values (e.g., 20): Gentler response predictor changes Smaller values (e.g., 2): Steeper response predictor changes Default (10): Balanced, works well cases Adjust : Convergence difficulties arise need steep gentle response curves Predictors unusual scales (large small)","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/gkwreg.html","id":"optimization-and-convergence","dir":"Reference","previous_headings":"","what":"Optimization and Convergence","title":"Fit Generalized Kumaraswamy Regression Models ‚Äî gkwreg","text":"default optimizer (method = \"nlminb\") works well problems. convergence issues occur: 1. Check Data: Ensure response strictly (0, 1) Check extreme outliers influential points Verify predictors perfectly collinear Consider rescaling predictors similar ranges 2. Try Alternative Optimizers: 3. Adjust Tolerances: 4. Provide Starting Values: 5. Simplify Model: Use simpler family (e.g., \"kw\" instead \"gkw\") Reduce number predictors Use intercept-parameters","code":"# BFGS often more robust for difficult problems   fit <- gkwreg(y ~ x, data,                 control = gkw_control(method = \"BFGS\"))    # Nelder-Mead for non-smooth objectives   fit <- gkwreg(y ~ x, data,                 control = gkw_control(method = \"Nelder-Mead\")) # Increase iterations and loosen tolerance   fit <- gkwreg(y ~ x, data,                 control = gkw_control(maxit = 1000, reltol = 1e-6)) # Fit simpler model first, use as starting values   fit_simple <- gkwreg(y ~ 1, data, family = \"kw\")   start_vals <- list(     alpha = c(coef(fit_simple)[1], rep(0, ncol(X_alpha) - 1)),     beta  = c(coef(fit_simple)[2], rep(0, ncol(X_beta) - 1))   )   fit_complex <- gkwreg(y ~ x1 + x2 | x3 + x4, data, family = \"kw\",                          control = gkw_control(start = start_vals))"},{"path":"https://evandeilton.github.io/gkwreg/reference/gkwreg.html","id":"standard-errors-and-inference","dir":"Reference","previous_headings":"","what":"Standard Errors and Inference","title":"Fit Generalized Kumaraswamy Regression Models ‚Äî gkwreg","text":"default, standard errors computed via Hessian matrix MLE. provides valid asymptotic standard errors standard regularity conditions. Standard Errors May Unreliable: Small sample sizes (n < 30-50 per parameter) Parameters near boundaries Highly collinear predictors Mis-specified models Alternatives: Bootstrap confidence intervals (robust, computationally expensive) Profile likelihood intervals via confint(..., type = \"profile\") (yet implemented) Cross-validation predictive performance assessment skip Hessian computation (faster, SEs):","code":"fit <- gkwreg(y ~ x, data,                 control = gkw_control(hessian = FALSE))"},{"path":"https://evandeilton.github.io/gkwreg/reference/gkwreg.html","id":"model-diagnostics","dir":"Reference","previous_headings":"","what":"Model Diagnostics","title":"Fit Generalized Kumaraswamy Regression Models ‚Äî gkwreg","text":"Always check model adequacy using diagnostic plots: Key diagnostics: Residual plots: Check patterns, heteroscedasticity Half-normal plot: Assess distributional adequacy Cook's distance: Identify influential observations Predicted vs observed: Overall fit quality See plot.gkwreg detailed interpretation guidance.","code":"fit <- gkwreg(y ~ x, data, family = \"kw\")   plot(fit)  # Six diagnostic plots"},{"path":"https://evandeilton.github.io/gkwreg/reference/gkwreg.html","id":"computational-considerations","dir":"Reference","previous_headings":"","what":"Computational Considerations","title":"Fit Generalized Kumaraswamy Regression Models ‚Äî gkwreg","text":"Performance Tips: GKw family: computationally expensive (~2-5x slower kw/beta) Beta/Kw families: Fastest, use adequate Large datasets (n > 10,000): Consider sampling exploratory analysis TMB uses automatic differentiation: Fast gradient/Hessian computation Disable Hessian (hessian = FALSE) faster fitting without SEs Memory Usage: Set model = FALSE, x = FALSE, y = FALSE reduce object size (limits post-fitting capabilities) Hessian matrix scales O(p¬≤) p = number parameters","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/gkwreg.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Fit Generalized Kumaraswamy Regression Models ‚Äî gkwreg","text":"following S3 methods available objects class \"gkwreg\": Basic Methods: print.gkwreg: Print basic model information summary.gkwreg: Detailed model summary coefficient tables, tests, fit statistics coef.gkwreg: Extract coefficients vcov.gkwreg: Extract variance-covariance matrix logLik: Extract log-likelihood AIC, BIC: Information criteria Prediction Fitted Values: fitted.gkwreg: Extract fitted values residuals.gkwreg: Extract residuals (multiple types available) predict.gkwreg: Predict new data Inference: confint.gkwreg: Confidence intervals parameters anova.gkwreg: Compare nested models via likelihood ratio tests Diagnostics: plot.gkwreg: Comprehensive diagnostic plots (6 types)","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/gkwreg.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fit Generalized Kumaraswamy Regression Models ‚Äî gkwreg","text":"Generalized Kumaraswamy Distribution: Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation, 81(7), 883-898. doi:10.1080/00949650903530745 Kumaraswamy Distribution: Kumaraswamy, P. (1980). generalized probability density function double-bounded random processes. Journal Hydrology, 46(1-2), 79-88. doi:10.1016/0022-1694(80)90036-0 Jones, M. C. (2009). Kumaraswamy's distribution: beta-type distribution tractability advantages. Statistical Methodology, 6(1), 70-81. doi:10.1016/j.stamet.2008.04.001 Beta Regression: Ferrari, S. L. P., & Cribari-Neto, F. (2004). Beta regression modelling rates proportions. Journal Applied Statistics, 31(7), 799-815. doi:10.1080/0266476042000214501 Smithson, M., & Verkuilen, J. (2006). better lemon squeezer? Maximum-likelihood regression beta-distributed dependent variables. Psychological Methods, 11(1), 54-71. doi:10.1037/1082-989X.11.1.54 Template Model Builder (TMB): Kristensen, K., Nielsen, ., Berg, C. W., Skaug, H., & Bell, B. M. (2016). TMB: Automatic Differentiation Laplace Approximation. Journal Statistical Software, 70(5), 1-21. doi:10.18637/jss.v070.i05 Related Software: Zeileis, ., & Croissant, Y. (2010). Extended Model Formulas R: Multiple Parts Multiple Responses. Journal Statistical Software, 34(1), 1-13. doi:10.18637/jss.v034.i01","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwreg/reference/gkwreg.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fit Generalized Kumaraswamy Regression Models ‚Äî gkwreg","text":"Lopes, J. E. Maintainer: Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/gkwreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit Generalized Kumaraswamy Regression Models ‚Äî gkwreg","text":"","code":"# \\donttest{ # SECTION 1: Basic Usage - Getting Started # Load packages and data library(gkwreg) library(gkwdist) data(GasolineYield)  # Example 1.1: Simplest possible model (intercept-only, all defaults) fit_basic <- gkwreg(yield ~ 1, data = GasolineYield, family = \"kw\") summary(fit_basic) #>  #> Generalized Kumaraswamy Regression Model Summary #>  #> Family: kw  #>  #> Call: #> gkwreg(formula = yield ~ 1, data = GasolineYield, family = \"kw\") #>  #> Residuals: #>     Min  Q1.25%  Median    Mean  Q3.75%     Max  #> -0.1688 -0.0803 -0.0188 -0.0002  0.0737  0.2602  #>  #> Coefficients: #>                   Estimate Std. Error z value Pr(>|z|)     #> alpha:(Intercept)   0.6342     0.1538   4.124 3.73e-05 *** #> beta:(Intercept)    2.7951     0.4319   6.472 9.68e-11 *** #> --- #> Signif. codes:  0 ‚Äò***‚Äô 0.001 ‚Äò**‚Äô 0.01 ‚Äò*‚Äô 0.05 ‚Äò.‚Äô 0.1 ‚Äò ‚Äô 1 #>  #> Confidence intervals (95%): #>                       3%    98% #> alpha:(Intercept) 0.3328 0.9356 #> beta:(Intercept)  1.9486 3.6416 #>  #> Link functions: #> alpha: log #> beta: log #>  #> Fitted parameter means: #> alpha: 1.886 #> beta: 16.35 #> gamma: 1 #> delta: 0 #> lambda: 1 #>  #> Model fit statistics: #> Number of observations: 32  #> Number of parameters: 2  #> Residual degrees of freedom: 30  #> Log-likelihood: 28.51  #> AIC: -53.02  #> BIC: -50.09  #> RMSE: 0.1055  #> Efron's R2: -4.747e-06  #> Mean Absolute Error: 0.09088  #>  #> Convergence status: Successful  #> Iterations: 11  #>   # Example 1.2: Model with predictors (uses all defaults) # Default: family = \"gkw\", method = \"nlminb\", hessian = TRUE fit_default <- gkwreg(yield ~ batch + temp, data = GasolineYield) #> Warning: NaNs produced summary(fit_default) #>  #> Generalized Kumaraswamy Regression Model Summary #>  #> Family: gkw  #>  #> Call: #> gkwreg(formula = yield ~ batch + temp, data = GasolineYield) #>  #> Residuals: #>     Min  Q1.25%  Median    Mean  Q3.75%     Max  #> -0.0267 -0.0110 -0.0010 -0.0010  0.0079  0.0268  #>  #> Coefficients: #>                      Estimate Std. Error  z value Pr(>|z|)     #> alpha:(Intercept)  -3.269e+00        NaN      NaN      NaN     #> alpha:batch1        9.197e-01  3.191e-02   28.825  < 2e-16 *** #> alpha:batch2        6.780e-01  3.414e-02   19.857  < 2e-16 *** #> alpha:batch3        7.823e-01  3.414e-02   22.913  < 2e-16 *** #> alpha:batch4        5.590e-01  3.189e-02   17.525  < 2e-16 *** #> alpha:batch5        5.629e-01  3.410e-02   16.508  < 2e-16 *** #> alpha:batch6        5.411e-01  3.409e-02   15.873  < 2e-16 *** #> alpha:batch7        3.106e-01  3.191e-02    9.732  < 2e-16 *** #> alpha:batch8        2.546e-01  3.410e-02    7.465 8.34e-14 *** #> alpha:batch9        1.988e-01  3.809e-02    5.219 1.80e-07 *** #> alpha:temp          5.407e-03  1.367e-06 3955.503  < 2e-16 *** #> beta:(Intercept)    2.650e+00        NaN      NaN      NaN     #> gamma:(Intercept)   2.028e+01  1.089e+01    1.862   0.0627 .   #> delta:(Intercept)  -1.216e-01        NaN      NaN      NaN     #> lambda:(Intercept) -8.038e+00        NaN      NaN      NaN     #> --- #> Signif. codes:  0 ‚Äò***‚Äô 0.001 ‚Äò**‚Äô 0.01 ‚Äò*‚Äô 0.05 ‚Äò.‚Äô 0.1 ‚Äò ‚Äô 1 #>  #> Confidence intervals (95%): #>                         3%     98% #> alpha:(Intercept)      NaN     NaN #> alpha:batch1        0.8572  0.9822 #> alpha:batch2        0.6111  0.7449 #> alpha:batch3        0.7154  0.8492 #> alpha:batch4        0.4964  0.6215 #> alpha:batch5        0.4961  0.6298 #> alpha:batch6        0.4743  0.6079 #> alpha:batch7        0.2480  0.3731 #> alpha:batch8        0.1877  0.3214 #> alpha:batch9        0.1242  0.2735 #> alpha:temp          0.0054  0.0054 #> beta:(Intercept)       NaN     NaN #> gamma:(Intercept)  -1.0709 41.6327 #> delta:(Intercept)      NaN     NaN #> lambda:(Intercept)     NaN     NaN #>  #> Link functions: #> alpha: log #> beta: log #> gamma: log #> delta: logit #> lambda: log #>  #> Fitted parameter means: #> alpha: 0.4028 #> beta: 14.16 #> gamma: 642490773 #> delta: 4.696 #> lambda: 0.0003225 #>  #> Model fit statistics: #> Number of observations: 32  #> Number of parameters: 15  #> Residual degrees of freedom: 17  #> Log-likelihood: 96.48  #> AIC: -163  #> BIC: -141  #> RMSE: 0.0139  #> Efron's R2: 0.9826  #> Mean Absolute Error: 0.01111  #>  #> Convergence status: Failed  #> Iterations: 118  #>   # Example 1.3: Kumaraswamy model (two-parameter family) # Default link functions: log for both alpha and beta fit_kw <- gkwreg(yield ~ batch + temp, data = GasolineYield, family = \"kw\") #> Warning: NaNs produced summary(fit_kw) #>  #> Generalized Kumaraswamy Regression Model Summary #>  #> Family: kw  #>  #> Call: #> gkwreg(formula = yield ~ batch + temp, data = GasolineYield,  #>     family = \"kw\") #>  #> Residuals: #>     Min  Q1.25%  Median    Mean  Q3.75%     Max  #> -0.0281 -0.0030  0.0037  0.0010  0.0100  0.0174  #>  #> Coefficients: #>                    Estimate Std. Error z value Pr(>|z|)     #> alpha:(Intercept)  0.669355   0.028776  23.261  < 2e-16 *** #> alpha:batch1       0.838130   0.026673  31.422  < 2e-16 *** #> alpha:batch2       0.591274   0.028527  20.727  < 2e-16 *** #> alpha:batch3       0.710287   0.028463  24.955  < 2e-16 *** #> alpha:batch4       0.466756   0.026659  17.508  < 2e-16 *** #> alpha:batch5       0.520260   0.028383  18.330  < 2e-16 *** #> alpha:batch6       0.449785   0.028495  15.785  < 2e-16 *** #> alpha:batch7       0.224769   0.026604   8.449  < 2e-16 *** #> alpha:batch8       0.203183   0.028266   7.188 6.56e-13 *** #> alpha:batch9       0.141845   0.031868   4.451 8.54e-06 *** #> alpha:temp         0.005282        NaN     NaN      NaN     #> beta:(Intercept)  28.881698   0.432486  66.781  < 2e-16 *** #> --- #> Signif. codes:  0 ‚Äò***‚Äô 0.001 ‚Äò**‚Äô 0.01 ‚Äò*‚Äô 0.05 ‚Äò.‚Äô 0.1 ‚Äò ‚Äô 1 #>  #> Confidence intervals (95%): #>                        3%     98% #> alpha:(Intercept)  0.6130  0.7258 #> alpha:batch1       0.7859  0.8904 #> alpha:batch2       0.5354  0.6472 #> alpha:batch3       0.6545  0.7661 #> alpha:batch4       0.4145  0.5190 #> alpha:batch5       0.4646  0.5759 #> alpha:batch6       0.3939  0.5056 #> alpha:batch7       0.1726  0.2769 #> alpha:batch8       0.1478  0.2586 #> alpha:batch9       0.0794  0.2043 #> alpha:temp            NaN     NaN #> beta:(Intercept)  28.0340 29.7294 #>  #> Link functions: #> alpha: log #> beta: log #>  #> Fitted parameter means: #> alpha: 18.47 #> beta: 3.489e+12 #> gamma: 1 #> delta: 0 #> lambda: 1 #>  #> Model fit statistics: #> Number of observations: 32  #> Number of parameters: 12  #> Residual degrees of freedom: 20  #> Log-likelihood: 96.97  #> AIC: -169.9  #> BIC: -152.3  #> RMSE: 0.01266  #> Efron's R2: 0.9856  #> Mean Absolute Error: 0.01018  #>  #> Convergence status: Failed  #> Iterations: 68  #>   par(mfrow = c(3, 2)) plot(fit_kw, ask = FALSE) #> Simulating envelope ( 100 iterations): .......... Done!   # Example 1.4: Beta model for comparison # Default links: log for gamma and delta fit_beta <- gkwreg(yield ~ batch + temp, data = GasolineYield, family = \"beta\")  # Compare models using AIC/BIC AIC(fit_kw, fit_beta) #>          df        AIC #> fit_kw   12 -169.93784 #> fit_beta 12  -66.52315 BIC(fit_kw, fit_beta) #>          df        BIC #> fit_kw   12 -152.34901 #> fit_beta 12  -48.93432  # SECTION 2: Using gkw_control() for Customization  # Example 2.1: Change optimization method to BFGS fit_bfgs <- gkwreg(   yield ~ batch + temp,   data = GasolineYield,   family = \"kw\",   control = gkw_control(method = \"BFGS\") ) summary(fit_bfgs) #>  #> Generalized Kumaraswamy Regression Model Summary #>  #> Family: kw  #>  #> Call: #> gkwreg(formula = yield ~ batch + temp, data = GasolineYield,  #>     family = \"kw\", control = gkw_control(method = \"BFGS\")) #>  #> Residuals: #>     Min  Q1.25%  Median    Mean  Q3.75%     Max  #> -0.4270 -0.3404 -0.2601 -0.2400 -0.1571  0.0346  #>  #> Coefficients: #>                     Estimate Std. Error z value Pr(>|z|) #> alpha:(Intercept) -2.642e-06  1.244e+00   0.000    1.000 #> alpha:batch1      -1.481e-07  7.956e-01   0.000    1.000 #> alpha:batch2      -2.952e-07  7.610e-01   0.000    1.000 #> alpha:batch3      -2.558e-07  7.878e-01   0.000    1.000 #> alpha:batch4      -3.067e-07  6.980e-01   0.000    1.000 #> alpha:batch5      -1.339e-07  7.555e-01   0.000    1.000 #> alpha:batch6      -1.890e-07  7.388e-01   0.000    1.000 #> alpha:batch7      -5.561e-07  6.586e-01   0.000    1.000 #> alpha:batch8      -2.938e-07  6.854e-01   0.000    1.000 #> alpha:batch9      -1.461e-07  7.854e-01   0.000    1.000 #> alpha:temp        -7.717e-04  3.133e-03  -0.246    0.805 #> beta:(Intercept)   2.530e-06  5.131e-01   0.000    1.000 #>  #> Confidence intervals (95%): #>                        3%    98% #> alpha:(Intercept) -2.4382 2.4382 #> alpha:batch1      -1.5593 1.5593 #> alpha:batch2      -1.4916 1.4916 #> alpha:batch3      -1.5441 1.5441 #> alpha:batch4      -1.3680 1.3680 #> alpha:batch5      -1.4808 1.4808 #> alpha:batch6      -1.4479 1.4479 #> alpha:batch7      -1.2908 1.2908 #> alpha:batch8      -1.3433 1.3433 #> alpha:batch9      -1.5394 1.5394 #> alpha:temp        -0.0069 0.0054 #> beta:(Intercept)  -1.0057 1.0057 #>  #> Link functions: #> alpha: log #> beta: log #>  #> Fitted parameter means: #> alpha: 0.775 #> beta: 0.999 #> gamma: 1 #> delta: 0 #> lambda: 1 #>  #> Model fit statistics: #> Number of observations: 32  #> Number of parameters: 12  #> Residual degrees of freedom: 20  #> Log-likelihood: 4.18  #> AIC: 15.64  #> BIC: 33.23  #> RMSE: 0.2662  #> Efron's R2: -5.362  #> Mean Absolute Error: 0.2422  #>  #> Convergence status: Successful  #> Iterations: 12  #>   # Example 2.2: Increase iterations and enable verbose output fit_verbose <- gkwreg(   yield ~ batch + temp,   data = GasolineYield,   family = \"kw\",   control = gkw_control(     method = \"nlminb\",     maxit = 1000,     silent = FALSE, # Show optimization progress     trace = 1 # Print iteration details   ) ) #> Using TMB model: kwreg #> Checking TMB model status for  kwreg ... #> Found TMB source file:  /home/runner/work/_temp/Library/gkwreg/tmb/kwreg.cpp  #> Found cached TMB model:  /home/runner/.cache/gkwreg/tmb_cache/R4.5/2.1.1/kwreg.so  #> Successfully loaded cached TMB model. #> Optimizing with nlminb... #> outer mgc:  7535.888  #>   0:     0.0000000:  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000 #> outer mgc:  1043.999  #>   1:    -5.4751175: -4.63847e-06 -2.59943e-07 -5.18250e-07 -4.49143e-07 -5.38512e-07 -2.35055e-07 -3.31849e-07 -9.76418e-07 -5.15872e-07 -2.56583e-07 -0.00135487 4.44139e-06 #> outer mgc:  248.2347  #>   2:    -5.6372510: -0.000220415 4.16287e-05 -6.57121e-05 -4.96481e-05 -2.17994e-05 4.41064e-05 1.14631e-05 -0.000146966 -2.99241e-05 1.37058e-05 -0.00157060 0.00131183 #> outer mgc:  473.1837  #>   3:    -17.969328: -0.136724 0.0277276 -0.0411281 -0.0307797 -0.0132258 0.0285480 0.00773975 -0.0933782 -0.0190868 0.00856339 0.000220983 0.807421 #> outer mgc:  9403.659  #>   4:    -26.755529: -1.05462 0.724290 -0.0972976 0.0815258 -0.00801223 0.221600 0.0531230 -0.597665 -0.396572 -0.204538 0.00463826  1.75768 #> outer mgc:  2886.778  #>   5:    -37.161577: -1.99422 0.532895 0.375388 0.595205 0.184898 0.118380 0.0752171 0.0400090 -0.446348 -0.559931 0.00739496  2.61648 #> outer mgc:  7.749627  #>   6:    -37.319116: -1.99422 0.532895 0.375388 0.595205 0.184898 0.118380 0.0752172 0.0400089 -0.446347 -0.559931 0.00728617  2.61648 #> outer mgc:  550.0578  #>   7:    -41.464061: -2.02667 0.914794  1.02259 0.900567 0.498035 0.229685 0.432451 0.250005 0.606057 -0.140198 0.00692665  3.32846 #> outer mgc:  5344.69  #>   8:    -45.753042: -1.76430  1.27538  1.24545  1.16880 0.977965 0.907505 0.936306 0.774485  1.02539 0.611458 0.00552332  4.00061 #> outer mgc:  1670.43  #>   9:    -47.955163: -1.64864  1.22488  1.11887  1.24717 0.859116 0.813747 0.957285 0.611050 0.863210 0.747015 0.00532993  4.07981 #> outer mgc:  9795.288  #>  10:    -51.767663: -1.40959  1.20843 0.839361 0.870775 0.757785 0.725397 0.685794 0.396577 0.539655 0.627278 0.00501252  4.22953 #> outer mgc:  2710.496  #>  11:    -53.248253: -1.12767  1.06051 0.668602 0.815387 0.477102 0.862767 0.718959 0.248646 0.338869 0.171931 0.00481642  4.46311 #> outer mgc:  16842.91  #>  12:    -53.429246: -1.03560 0.930350 0.552767 0.812949 0.558985 0.739392 0.653578 0.201404 0.199360 0.0828970 0.00510502  4.64797 #> outer mgc:  1617.054  #>  13:    -56.920478: -1.04556 0.887457 0.544651 0.761934 0.449875 0.698924 0.597230 0.252503 0.149860 0.124954 0.00497747  4.71163 #> outer mgc:  2975.096  #>  14:    -57.122716: -1.05628 0.887144 0.621162 0.746286 0.377752 0.704226 0.517575 0.263577 0.114298 0.184229 0.00515212  4.80920 #> outer mgc:  5629.443  #>  15:    -59.508340: -1.16932 0.831867 0.647262 0.740311 0.473678 0.698786 0.442163 0.126740 0.190201 0.212037 0.00583191  5.38867 #> outer mgc:  4395.124  #>  16:    -63.076455: -1.15522 0.976613 0.645814 0.760813 0.523103 0.518533 0.436436 0.149771 0.199569 0.171118 0.00602373  5.96632 #> outer mgc:  196.8215  #>  17:    -63.160743: -1.15522 0.976613 0.645814 0.760813 0.523103 0.518533 0.436436 0.149771 0.199569 0.171118 0.00598723  5.96632 #> outer mgc:  18.42406  #>  18:    -63.161178: -1.15521 0.976604 0.645809 0.760798 0.523100 0.518521 0.436445 0.149773 0.199566 0.171117 0.00598550  5.96635 #> outer mgc:  461.7689  #>  19:    -63.890234: -1.12318 0.928341 0.620142 0.679521 0.504704 0.446154 0.489708 0.158607 0.181216 0.166103 0.00601617  6.12062 #> outer mgc:  791.2478  #>  20:    -66.036596: -0.800206 0.769772 0.518142 0.643273 0.495658 0.295760 0.349990 0.156598 0.120672 0.0735364 0.00553780  6.68285 #> outer mgc:  8171.629  #>  21:    -69.640060: -0.668180 0.830978 0.522586 0.674831 0.529395 0.393655 0.415273 0.236722 0.179303 0.125246 0.00532357  7.36258 #> outer mgc:  1565.565  #>  22:    -70.355079: -0.626741 0.844078 0.585063 0.678075 0.561437 0.412512 0.448970 0.234407 0.160557 0.127507 0.00518349  7.51316 #> outer mgc:  16132.41  #>  23:    -70.925305: -0.656731 0.855902 0.591969 0.712135 0.557942 0.437277 0.462929 0.267301 0.186961 0.131086 0.00519836  7.67594 #> outer mgc:  992.5871  #>  24:    -72.287011: -0.656650 0.866594 0.616989 0.732895 0.565204 0.457702 0.481938 0.284546 0.196027 0.134163 0.00530147  7.84613 #> outer mgc:  10629.38  #>  25:    -75.105520: -0.494803 0.937004 0.806321 0.861938 0.579462 0.628636 0.624693 0.384401 0.289508 0.186246 0.00521692  9.70792 #> outer mgc:  18969.12  #>  26:    -76.692255: -0.333361 0.887587 0.734577 0.783233 0.508464 0.600339 0.566039 0.306909 0.258688 0.197094 0.00500158  10.0584 #> outer mgc:  6260.027  #>  27:    -79.259103: -0.369687 0.862439 0.670965 0.759088 0.497862 0.596401 0.509338 0.276911 0.163088 0.176222 0.00526577  10.4567 #> outer mgc:  16287.87  #>  28:    -81.053798: -0.376928 0.870388 0.626177 0.705981 0.497203 0.570252 0.452039 0.237364 0.224924 0.150962 0.00537596  10.8617 #> outer mgc:  12963.16  #>  29:    -82.151851: -0.364627 0.880116 0.606015 0.722805 0.507469 0.549036 0.458418 0.233001 0.224630 0.156515 0.00551800  11.2830 #> outer mgc:  8317.292  #>  30:    -83.329837: -0.312697 0.874169 0.594294 0.739479 0.490313 0.514716 0.475484 0.229621 0.224870 0.172911 0.00546802  11.6999 #> outer mgc:  16486.14  #>  31:    -84.986835: -0.192865 0.853400 0.595130 0.717311 0.477081 0.490337 0.460508 0.235518 0.216189 0.162595 0.00536386  12.5363 #> outer mgc:  16178.4  #>  32:    -86.555130: -0.103660 0.852072 0.593116 0.723514 0.494456 0.507035 0.475202 0.234153 0.220827 0.171784 0.00526956  13.3773 #> outer mgc:  29858.1  #>  33:    -88.596572: -0.0142778 0.872344 0.620063 0.744182 0.474163 0.523267 0.479167 0.257521 0.213986 0.146453 0.00535175  15.0663 #> outer mgc:  4090.948  #>  34:    -88.615340: -0.000990117 0.902580 0.704435 0.787394 0.558575 0.568736 0.517017 0.339891 0.253565 0.244840 0.00543371  16.7473 #> outer mgc:  6187  #>  35:    -90.392362: 0.0985384 0.859188 0.666724 0.747058 0.538160 0.535854 0.494613 0.299087 0.221230 0.165105 0.00537535  17.5781 #> outer mgc:  23677.04  #>  36:    -90.601186: 0.285604 0.888612 0.601393 0.700915 0.510188 0.513569 0.451882 0.236701 0.192324 0.123306 0.00521226  19.2551 #> outer mgc:  5588.834  #>  37:    -92.504039: 0.314495 0.858162 0.577322 0.696464 0.473482 0.521344 0.444638 0.208070 0.197319 0.121994 0.00516530  19.3876 #> outer mgc:  3309.011  #>  38:    -93.042484: 0.316922 0.850751 0.574503 0.695607 0.469865 0.519612 0.445518 0.208463 0.198603 0.125129 0.00518065  19.5362 #> outer mgc:  3996.388  #>  39:    -93.550654: 0.320696 0.843080 0.584565 0.705608 0.469072 0.517989 0.444761 0.205085 0.200705 0.126715 0.00520644  19.8338 #> outer mgc:  17352.93  #>  40:    -93.849294: 0.332284 0.837333 0.584783 0.707135 0.467210 0.521063 0.448395 0.208314 0.202877 0.128243 0.00522856  20.1314 #> outer mgc:  3406.866  #>  41:    -94.407020: 0.332577 0.839173 0.587505 0.710933 0.467005 0.525668 0.458377 0.222651 0.205102 0.130060 0.00524213  20.4289 #> outer mgc:  3404.875  #>  42:    -94.965671: 0.338916 0.840802 0.596147 0.710362 0.473492 0.511103 0.456749 0.226911 0.203994 0.151337 0.00533729  21.2777 #> outer mgc:  11745.73  #>  43:    -95.316480: 0.385958 0.835928 0.593772 0.718096 0.472879 0.514803 0.454766 0.233790 0.209386 0.152955 0.00531950  22.1256 #> outer mgc:  29124.52  #>  44:    -95.424095: 0.420780 0.842716 0.608497 0.718265 0.475043 0.523532 0.473657 0.236527 0.216087 0.158017 0.00532031  22.9738 #> outer mgc:  26418.78  #>  45:    -95.903337: 0.450111 0.857225 0.610560 0.733602 0.486467 0.535142 0.464887 0.241710 0.218040 0.154498 0.00532283  23.8221 #> outer mgc:  7283.197  #>  46:    -96.130127: 0.482701 0.846683 0.602675 0.722989 0.477554 0.529472 0.454392 0.235030 0.210303 0.152475 0.00525428  24.0048 #> outer mgc:  494.6936  #>  47:    -96.419391: 0.517818 0.839957 0.588197 0.712568 0.469754 0.516728 0.450185 0.224012 0.204821 0.138567 0.00526935  24.7520 #> outer mgc:  15965.16  #>  48:    -96.538039: 0.550106 0.835039 0.586860 0.706279 0.466407 0.518103 0.446995 0.221504 0.199669 0.138062 0.00527778  25.4999 #> outer mgc:  15035.23  #>  49:    -96.659029: 0.557190 0.845172 0.599211 0.713725 0.475066 0.523385 0.461327 0.230085 0.209577 0.142689 0.00531771  26.2480 #> outer mgc:  13654.05  #>  50:    -96.710983: 0.582373 0.845661 0.596600 0.717695 0.467337 0.516892 0.457804 0.228834 0.201823 0.146313 0.00530960  26.7742 #> outer mgc:  16630.47  #>  51:    -96.746448: 0.612350 0.835148 0.589214 0.710119 0.466439 0.522173 0.443317 0.223075 0.203412 0.146457 0.00526603  27.1797 #> outer mgc:  3072.007  #>  52:    -96.856384: 0.631715 0.834711 0.589074 0.709364 0.467874 0.521535 0.445097 0.223563 0.205437 0.144518 0.00525973  27.5865 #> outer mgc:  4230.451  #>  53:    -96.912783: 0.623173 0.838381 0.591610 0.710755 0.468407 0.522126 0.450084 0.225335 0.202044 0.142104 0.00528501  27.6159 #> outer mgc:  3805.817  #>  54:    -96.927773: 0.626148 0.839393 0.592823 0.710694 0.467787 0.521028 0.450433 0.226023 0.203564 0.141800 0.00528611  27.7168 #> outer mgc:  3257.209  #>  55:    -96.941109: 0.633749 0.839524 0.592890 0.711687 0.468601 0.520714 0.452107 0.226012 0.204398 0.142931 0.00528369  27.9185 #> outer mgc:  5399.752  #>  56:    -96.954800: 0.648820 0.839071 0.592266 0.711177 0.467603 0.520225 0.451020 0.225369 0.204035 0.142116 0.00528449  28.3220 #> outer mgc:  224.6027  #>  57:    -96.966822: 0.664026 0.838383 0.591529 0.710223 0.467173 0.519846 0.450386 0.225434 0.203586 0.141624 0.00528047  28.7170 #> outer mgc:  146.4833  #>  58:    -96.967123: 0.669865 0.838045 0.591562 0.710659 0.466305 0.520487 0.449849 0.224041 0.203408 0.141808 0.00528374  28.9084 #> outer mgc:  374.0698  #>  59:    -96.967791: 0.669428 0.838139 0.591266 0.710285 0.466759 0.520268 0.449782 0.224774 0.203184 0.141869 0.00528248  28.8842 #> outer mgc:  44.61837  #>  60:    -96.968025: 0.669355 0.838130 0.591274 0.710287 0.466757 0.520260 0.449785 0.224769 0.203183 0.141846 0.00528232  28.8817 #> outer mgc:  0.7084324  #>  61:    -96.968092: 0.669355 0.838130 0.591274 0.710287 0.466757 0.520260 0.449785 0.224769 0.203183 0.141846 0.00528233  28.8817 #> outer mgc:  0.3502188  #>  62:    -96.968570: 0.669355 0.838130 0.591274 0.710287 0.466756 0.520260 0.449785 0.224769 0.203183 0.141845 0.00528233  28.8817 #> outer mgc:  0.8368422  #>  63:    -96.968835: 0.669355 0.838130 0.591274 0.710287 0.466756 0.520260 0.449785 0.224769 0.203183 0.141845 0.00528233  28.8817 #> outer mgc:  0.3118328  #>  64:    -96.968888: 0.669355 0.838130 0.591274 0.710287 0.466756 0.520260 0.449785 0.224769 0.203183 0.141845 0.00528233  28.8817 #> outer mgc:  0.2403267  #>  65:    -96.968895: 0.669355 0.838130 0.591274 0.710287 0.466756 0.520260 0.449785 0.224769 0.203183 0.141845 0.00528233  28.8817 #> outer mgc:  0.2102557  #>  66:    -96.968907: 0.669355 0.838130 0.591274 0.710287 0.466756 0.520260 0.449785 0.224769 0.203183 0.141845 0.00528233  28.8817 #> outer mgc:  0.2102834  #>  67:    -96.968921: 0.669355 0.838130 0.591274 0.710287 0.466756 0.520260 0.449785 0.224769 0.203183 0.141845 0.00528233  28.8817 #>  68:    -96.968921: 0.669355 0.838130 0.591274 0.710287 0.466756 0.520260 0.449785 0.224769 0.203183 0.141845 0.00528233  28.8817 #> Computing standard errors... #> outer mgc:  0.2102834  #> outer mgc:  8544.888  #> outer mgc:  8765.638  #> outer mgc:  817.9471  #> outer mgc:  839.1499  #> outer mgc:  616.154  #> outer mgc:  632.1673  #> outer mgc:  731.8943  #> outer mgc:  750.9136  #> outer mgc:  1002.228  #> outer mgc:  1028.472  #> outer mgc:  944.0016  #> outer mgc:  968.1295  #> outer mgc:  808.8363  #> outer mgc:  830.0275  #> outer mgc:  1123.334  #> outer mgc:  1152.555  #> outer mgc:  985.8035  #> outer mgc:  1011.37  #> outer mgc:  573.5439  #> outer mgc:  588.3154  #> outer mgc:  433797.8  #> outer mgc:  1600371818  #> outer mgc:  303.2448  #> outer mgc:  302.9147  #> outer mgc:  1  #> Warning: NaNs produced  # Example 2.3: Fast fitting without standard errors # Useful for model exploration or large datasets fit_fast <- gkwreg(   yield ~ batch + temp,   data = GasolineYield,   family = \"kw\",   control = gkw_control(hessian = FALSE) ) # Note: Cannot compute confint() without hessian coef(fit_fast) # Point estimates still available #> alpha:(Intercept)      alpha:batch1      alpha:batch2      alpha:batch3  #>       0.669354582       0.838129953       0.591274162       0.710286670  #>      alpha:batch4      alpha:batch5      alpha:batch6      alpha:batch7  #>       0.466756485       0.520260130       0.449785399       0.224768871  #>      alpha:batch8      alpha:batch9        alpha:temp  beta:(Intercept)  #>       0.203183370       0.141845437       0.005282329      28.881697539   # Example 2.4: Custom convergence tolerances fit_tight <- gkwreg(   yield ~ batch + temp,   data = GasolineYield,   family = \"kw\",   control = gkw_control(     reltol = 1e-10, # Tighter convergence     maxit = 2000 # More iterations allowed   ) ) #> Warning: NaNs produced  # SECTION 3: Advanced Formula Specifications  # Example 3.1: Different predictors for different parameters # alpha depends on batch, beta depends on temp fit_diff <- gkwreg(   yield ~ batch | temp,   data = GasolineYield,   family = \"kw\" ) summary(fit_diff) #>  #> Generalized Kumaraswamy Regression Model Summary #>  #> Family: kw  #>  #> Call: #> gkwreg(formula = yield ~ batch | temp, data = GasolineYield,  #>     family = \"kw\") #>  #> Residuals: #>     Min  Q1.25%  Median    Mean  Q3.75%     Max  #> -0.0989 -0.0202  0.0005 -0.0107  0.0118  0.0214  #>  #> Coefficients: #>                   Estimate Std. Error z value Pr(>|z|)     #> alpha:(Intercept)  1.87901    0.28895   6.503 7.88e-11 *** #> alpha:batch1       0.86250    0.05725  15.065  < 2e-16 *** #> alpha:batch2       0.60762    0.05805  10.467  < 2e-16 *** #> alpha:batch3       0.75688    0.05780  13.094  < 2e-16 *** #> alpha:batch4       0.51389    0.05697   9.020  < 2e-16 *** #> alpha:batch5       0.51861    0.06066   8.550  < 2e-16 *** #> alpha:batch6       0.49730    0.05962   8.341  < 2e-16 *** #> alpha:batch7       0.25266    0.05741   4.401 1.08e-05 *** #> alpha:batch8       0.20427    0.06037   3.384 0.000715 *** #> alpha:batch9       0.20760    0.06847   3.032 0.002431 **  #> beta:(Intercept)  51.59713   14.83203   3.479 0.000504 *** #> beta:temp         -0.10060    0.02919  -3.447 0.000567 *** #> --- #> Signif. codes:  0 ‚Äò***‚Äô 0.001 ‚Äò**‚Äô 0.01 ‚Äò*‚Äô 0.05 ‚Äò.‚Äô 0.1 ‚Äò ‚Äô 1 #>  #> Confidence intervals (95%): #>                        3%     98% #> alpha:(Intercept)  1.3127  2.4453 #> alpha:batch1       0.7503  0.9747 #> alpha:batch2       0.4938  0.7214 #> alpha:batch3       0.6436  0.8702 #> alpha:batch4       0.4022  0.6256 #> alpha:batch5       0.3997  0.6375 #> alpha:batch6       0.3804  0.6141 #> alpha:batch7       0.1401  0.3652 #> alpha:batch8       0.0859  0.3226 #> alpha:batch9       0.0734  0.3418 #> beta:(Intercept)  22.5269 80.6674 #> beta:temp         -0.1578 -0.0434 #>  #> Link functions: #> alpha: log #> beta: log #>  #> Fitted parameter means: #> alpha: 10.71 #> beta: 1.34e+12 #> gamma: 1 #> delta: 0 #> lambda: 1 #>  #> Model fit statistics: #> Number of observations: 32  #> Number of parameters: 12  #> Residual degrees of freedom: 20  #> Log-likelihood: 80.49  #> AIC: -137  #> BIC: -119.4  #> RMSE: 0.03448  #> Efron's R2: 0.8933  #> Mean Absolute Error: 0.02283  #>  #> Convergence status: Failed  #> Iterations: 48  #>   # Example 3.2: Intercept-only for one parameter # alpha varies with predictors, beta is constant fit_partial <- gkwreg(   yield ~ batch + temp | 1,   data = GasolineYield,   family = \"kw\" ) #> Warning: NaNs produced  # Example 3.3: Complex model with interactions fit_interact <- gkwreg(   yield ~ batch * temp | temp + I(temp^2),   data = GasolineYield,   family = \"kw\" )  # SECTION 4: Working with Different Families  # Example 4.1: Fit multiple families and compare families <- c(\"beta\", \"kw\", \"ekw\", \"bkw\", \"gkw\") fits <- lapply(families, function(fam) {   gkwreg(yield ~ batch + temp, data = GasolineYield, family = fam) }) #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced names(fits) <- families  # Compare via information criteria comparison <- data.frame(   Family = families,   LogLik = sapply(fits, logLik),   AIC = sapply(fits, AIC),   BIC = sapply(fits, BIC),   npar = sapply(fits, function(x) x$npar) ) print(comparison) #>      Family   LogLik        AIC        BIC npar #> beta   beta 45.26157  -66.52315  -48.93432   12 #> kw       kw 96.96892 -169.93784 -152.34901   12 #> ekw     ekw 97.30482 -168.60963 -149.55507   13 #> bkw     bkw 96.41788 -164.83575 -144.31545   14 #> gkw     gkw 96.48016 -162.96031 -140.97427   15  # Example 4.2: Formal nested model testing fit_kw <- gkwreg(yield ~ batch + temp, GasolineYield, family = \"kw\") #> Warning: NaNs produced fit_ekw <- gkwreg(yield ~ batch + temp, GasolineYield, family = \"ekw\") #> Warning: NaNs produced fit_gkw <- gkwreg(yield ~ batch + temp, GasolineYield, family = \"gkw\") #> Warning: NaNs produced anova(fit_kw, fit_ekw, fit_gkw) #> Warning: negative deviance change detected; models may not be nested #> Analysis of Deviance Table #>  #> Model 1: yield ~ batch + temp #> Model 2: yield ~ batch + temp #> Model 3: yield ~ batch + temp #>  #>         Resid. Df Resid. Dev Df Deviance Pr(>Chi)   #> fit_kw   20.00000 -193.93784                        #> fit_ekw  19.00000 -194.60963  1  0.67179  0.41243   #> fit_gkw  17.00000 -192.96031  2 -1.64932            #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1  # SECTION 5: Link Functions and Scales  # Example 5.1: Custom link functions fit_links <- gkwreg(   yield ~ batch + temp,   data = GasolineYield,   family = \"kw\",   link = list(alpha = \"sqrt\", beta = \"log\") )  # Example 5.2: Custom link scales # Smaller scale = steeper response curve fit_scale <- gkwreg(   yield ~ batch + temp,   data = GasolineYield,   family = \"kw\",   link_scale = list(alpha = 5, beta = 15) ) #> Warning: NaNs produced  # Example 5.3: Uniform link for all parameters fit_uniform <- gkwreg(   yield ~ batch + temp,   data = GasolineYield,   family = \"kw\",   link = \"log\" # Single string applied to all ) #> Warning: NaNs produced  # SECTION 6: Prediction and Inference  # Fit model for prediction examples fit <- gkwreg(yield ~ batch + temp, GasolineYield, family = \"kw\") #> Warning: NaNs produced  # Example 6.1: Confidence intervals at different levels confint(fit, level = 0.95) # 95% CI #> Warning: some standard errors are NA or infinite; intervals may be unreliable #>                         2.5 %     97.5 % #> alpha:(Intercept)  0.61295476  0.7257544 #> alpha:batch1       0.78585088  0.8904090 #> alpha:batch2       0.53536141  0.6471869 #> alpha:batch3       0.65450034  0.7660730 #> alpha:batch4       0.41450496  0.5190080 #> alpha:batch5       0.46463077  0.5758895 #> alpha:batch6       0.39393615  0.5056346 #> alpha:batch7       0.17262525  0.2769125 #> alpha:batch8       0.14778262  0.2585841 #> alpha:batch9       0.07938588  0.2043050 #> alpha:temp                NaN        NaN #> beta:(Intercept)  28.03403986 29.7293552 confint(fit, level = 0.90) # 90% CI #> Warning: some standard errors are NA or infinite; intervals may be unreliable #>                           5 %       95 % #> alpha:(Intercept)  0.62202236  0.7166868 #> alpha:batch1       0.79425597  0.8820039 #> alpha:batch2       0.54435070  0.6381976 #> alpha:batch3       0.66346930  0.7571040 #> alpha:batch4       0.42290563  0.5106073 #> alpha:batch5       0.47357450  0.5669458 #> alpha:batch6       0.40291523  0.4966556 #> alpha:batch7       0.18100857  0.2685292 #> alpha:batch8       0.15668960  0.2496771 #> alpha:batch9       0.08942772  0.1942632 #> alpha:temp                NaN        NaN #> beta:(Intercept)  28.17032079 29.5930743 confint(fit, level = 0.99) # 99% CI #> Warning: some standard errors are NA or infinite; intervals may be unreliable #>                         0.5 %     99.5 % #> alpha:(Intercept)  0.59523265  0.7434765 #> alpha:batch1       0.76942360  0.9068363 #> alpha:batch2       0.51779235  0.6647560 #> alpha:batch3       0.63697100  0.7836023 #> alpha:batch4       0.39808634  0.5354266 #> alpha:batch5       0.44715076  0.5933695 #> alpha:batch6       0.37638704  0.5231838 #> alpha:batch7       0.15624054  0.2932972 #> alpha:batch8       0.13037444  0.2759923 #> alpha:batch9       0.05975966  0.2239312 #> alpha:temp                NaN        NaN #> beta:(Intercept)  27.76768651 29.9957086  # SECTION 7: Diagnostic Plots and Model Checking  fit <- gkwreg(yield ~ batch + temp, GasolineYield, family = \"kw\") #> Warning: NaNs produced  # Example 7.1: All diagnostic plots (default) par(mfrow = c(3, 2)) plot(fit, ask = FALSE) #> Simulating envelope ( 100 iterations): .......... Done!   # Example 7.2: Select specific plots par(mfrow = c(3, 1)) plot(fit, which = c(2, 4, 5)) # Cook's distance, Residuals, Half-normal #> Simulating envelope ( 100 iterations): .......... Done!   # Example 7.3: Using ggplot2 for modern graphics plot(fit, use_ggplot = TRUE, arrange_plots = TRUE) #> Simulating envelope ( 100 iterations): .......... Done! #> Warning: Removed 1 row containing missing values or values outside the scale range #> (`geom_segment()`).   # Example 7.4: Customized half-normal plot par(mfrow = c(1, 1)) plot(fit,   which = 5,   type = \"quantile\",   nsim = 200, # More simulations for smoother envelope   level = 0.95 ) # 95% confidence envelope #> Simulating envelope ( 200 iterations): .......... Done!   # Example 7.5: Extract diagnostic data programmatically diagnostics <- plot(fit, save_diagnostics = TRUE) #> Simulating envelope ( 100 iterations): .......... Done! head(diagnostics$data) # Residuals, Cook's distance, etc. #>   index y_obs     fitted    resid abs_resid  cook_dist  leverage  linpred #> 1     1 0.122 0.10936630 1.873101  1.873101 0.08026648 0.3755669 2.590362 #> 2     2 0.223 0.21750086 1.873101  1.873101 0.08500820 0.3853667 2.960125 #> 3     3 0.347 0.34756539 1.873101  1.873101 0.09289227 0.4005540 3.329888 #> 4     4 0.457 0.46044933 1.873101  1.873101 0.08854416 0.3923400 3.657392 #> 5     5 0.080 0.07061219 1.873101  1.873101 0.08716616 0.3896549 2.412176 #> 6     6 0.131 0.14042911 1.873101  1.873101 0.08129922 0.3777472 2.702704  # SECTION 8: Real Data Example - Food Expenditure  # Load and prepare data data(FoodExpenditure, package = \"betareg\") food_data <- FoodExpenditure food_data$prop <- food_data$food / food_data$income  # Example 8.1: Basic model fit_food <- gkwreg(   prop ~ persons | income,   data = food_data,   family = \"kw\" ) summary(fit_food) #>  #> Generalized Kumaraswamy Regression Model Summary #>  #> Family: kw  #>  #> Call: #> gkwreg(formula = prop ~ persons | income, data = food_data, family = \"kw\") #>  #> Residuals: #>     Min  Q1.25%  Median    Mean  Q3.75%     Max  #> -0.1668 -0.0417  0.0098 -0.0047  0.0396  0.1527  #>  #> Coefficients: #>                   Estimate Std. Error z value Pr(>|z|)     #> alpha:(Intercept)  1.26876    0.14206   8.931  < 2e-16 *** #> alpha:persons      0.07210    0.01895   3.805 0.000142 *** #> beta:(Intercept)   3.21312    0.63879   5.030  4.9e-07 *** #> beta:income        0.03623    0.00922   3.930  8.5e-05 *** #> --- #> Signif. codes:  0 ‚Äò***‚Äô 0.001 ‚Äò**‚Äô 0.01 ‚Äò*‚Äô 0.05 ‚Äò.‚Äô 0.1 ‚Äò ‚Äô 1 #>  #> Confidence intervals (95%): #>                       3%    98% #> alpha:(Intercept) 0.9903 1.5472 #> alpha:persons     0.0350 0.1092 #> beta:(Intercept)  1.9611 4.4651 #> beta:income       0.0182 0.0543 #>  #> Link functions: #> alpha: log #> beta: log #>  #> Fitted parameter means: #> alpha: 4.638 #> beta: 244.4 #> gamma: 1 #> delta: 0 #> lambda: 1 #>  #> Model fit statistics: #> Number of observations: 38  #> Number of parameters: 4  #> Residual degrees of freedom: 34  #> Log-likelihood: 46.34  #> AIC: -84.69  #> BIC: -78.14  #> RMSE: 0.07442  #> Efron's R2: 0.4465  #> Mean Absolute Error: 0.05784  #>  #> Convergence status: Successful  #> Iterations: 18  #>   # Example 8.2: Compare with Beta regression fit_food_beta <- gkwreg(   prop ~ persons | income,   data = food_data,   family = \"beta\" )  # Which fits better? AIC(fit_food, fit_food_beta) #>               df       AIC #> fit_food       4 -84.68830 #> fit_food_beta  4 -70.28298  # Example 8.3: Model diagnostics par(mfrow = c(3, 1)) plot(fit_food, which = c(2, 5, 6)) #> Simulating envelope ( 100 iterations): .......... Done!   # Example 8.4: Interpretation via effects # How does proportion spent on food change with income? income_seq <- seq(min(food_data$income), max(food_data$income), length = 50) pred_data <- data.frame(   persons = median(food_data$persons),   income = income_seq ) pred_food <- predict(fit_food, newdata = pred_data, type = \"response\")  par(mfrow = c(1, 1)) plot(food_data$income, food_data$prop,   xlab = \"Income\", ylab = \"Proportion Spent on Food\",   main = \"Food Expenditure Pattern\" ) lines(income_seq, pred_food, col = \"red\", lwd = 2)   # SECTION 9: Simulation Studies  # Example 9.1: Simple Kumaraswamy simulation set.seed(123) n <- 500 x1 <- runif(n, -2, 2) x2 <- rnorm(n)  # True model: log(alpha) = 0.8 + 0.3*x1, log(beta) = 1.2 - 0.2*x2 eta_alpha <- 0.8 + 0.3 * x1 eta_beta <- 1.2 - 0.2 * x2 alpha_true <- exp(eta_alpha) beta_true <- exp(eta_beta)  # Generate response y <- rkw(n, alpha = alpha_true, beta = beta_true) sim_data <- data.frame(y = y, x1 = x1, x2 = x2)  # Fit and check parameter recovery fit_sim <- gkwreg(y ~ x1 | x2, data = sim_data, family = \"kw\")  # Compare estimated vs true coefficients cbind(   True = c(0.8, 0.3, 1.2, -0.2),   Estimated = coef(fit_sim),   SE = fit_sim$se ) #>                   True  Estimated         SE #> alpha:(Intercept)  0.8  0.8013394 0.04562729 #> alpha:x1           0.3  0.3011747 0.02418262 #> beta:(Intercept)   1.2  1.1896310 0.07482055 #> beta:x2           -0.2 -0.2419618 0.04607844  # Example 9.2: Complex simulation with all five parameters set.seed(2203) n <- 2000 x <- runif(n, -1, 1)  # True parameters alpha <- exp(0.5 + 0.3 * x) beta <- exp(1.0 - 0.2 * x) gamma <- exp(0.7 + 0.4 * x) delta <- plogis(0.0 + 0.5 * x) # logit scale lambda <- exp(-0.3 + 0.2 * x)  # Generate from GKw y <- rgkw(n,   alpha = alpha, beta = beta, gamma = gamma,   delta = delta, lambda = lambda ) sim_data2 <- data.frame(y = y, x = x)  # Fit GKw model fit_gkw <- gkwreg(   y ~ x | x | x | x | x,   data = sim_data2,   family = \"gkw\",   control = gkw_control(method = \"L-BFGS-B\", maxit = 2000) ) #> Warning: NaNs produced summary(fit_gkw) #>  #> Generalized Kumaraswamy Regression Model Summary #>  #> Family: gkw  #>  #> Call: #> gkwreg(formula = y ~ x | x | x | x | x, data = sim_data2, family = \"gkw\",  #>     control = gkw_control(method = \"L-BFGS-B\", maxit = 2000)) #>  #> Residuals: #>     Min  Q1.25%  Median    Mean  Q3.75%     Max  #> -0.3454 -0.0940  0.0202  0.0333  0.1498  0.6354  #>  #> Coefficients: #>                    Estimate Std. Error z value Pr(>|z|) #> alpha:(Intercept)    1.0631        NaN     NaN      NaN #> alpha:x              0.7712     0.5214   1.479    0.139 #> beta:(Intercept)    -0.4671        NaN     NaN      NaN #> beta:x              -0.5548        NaN     NaN      NaN #> gamma:(Intercept)    1.1156        NaN     NaN      NaN #> gamma:x              1.2780        NaN     NaN      NaN #> delta:(Intercept)   -0.1703        NaN     NaN      NaN #> delta:x              0.6593        NaN     NaN      NaN #> lambda:(Intercept)  -1.0784        NaN     NaN      NaN #> lambda:x            -0.9428     0.7850  -1.201    0.230 #>  #> Confidence intervals (95%): #>                         3%    98% #> alpha:(Intercept)      NaN    NaN #> alpha:x            -0.2508 1.7932 #> beta:(Intercept)       NaN    NaN #> beta:x                 NaN    NaN #> gamma:(Intercept)      NaN    NaN #> gamma:x                NaN    NaN #> delta:(Intercept)      NaN    NaN #> delta:x                NaN    NaN #> lambda:(Intercept)     NaN    NaN #> lambda:x           -2.4813 0.5957 #>  #> Link functions: #> alpha: log #> beta: log #> gamma: log #> delta: logit #> lambda: log #>  #> Fitted parameter means: #> alpha: 3.16 #> beta: 0.6624 #> gamma: 3.881 #> delta: 4.574 #> lambda: 0.3954 #>  #> Model fit statistics: #> Number of observations: 2000  #> Number of parameters: 10  #> Residual degrees of freedom: 1990  #> Log-likelihood: 861.1  #> AIC: -1702  #> BIC: -1646  #> RMSE: 0.1707  #> Efron's R2: 0.3329  #> Mean Absolute Error: 0.1374  #>  #> Convergence status: Failed  #> Iterations: 115  #>   # SECTION 10: Handling Convergence Issues  # Example 10.1: Try different optimizers methods <- c(\"nlminb\", \"BFGS\", \"Nelder-Mead\", \"CG\") fits_methods <- lapply(methods, function(m) {   tryCatch(     gkwreg(yield ~ batch + temp, GasolineYield,       family = \"kw\",       control = gkw_control(method = m, silent = TRUE)     ),     error = function(e) NULL   ) }) #> Warning: NaNs produced #> Warning: NaNs produced names(fits_methods) <- methods  # Check which converged converged <- sapply(fits_methods, function(f) {   if (is.null(f)) {     return(FALSE)   }   f$convergence }) print(converged) #>      nlminb        BFGS Nelder-Mead          CG  #>       FALSE        TRUE        TRUE       FALSE   # Example 10.2: Verbose mode for debugging fit_debug <- gkwreg(   yield ~ batch + temp,   data = GasolineYield,   family = \"kw\",   control = gkw_control(     method = \"BFGS\",     silent = TRUE,     trace = 0, # 2, Maximum verbosity     maxit = 1000   ) )  # SECTION 11: Memory and Performance Optimization  # Example 11.1: Minimal object for large datasets fit_minimal <- gkwreg(   yield ~ batch + temp,   data = GasolineYield,   family = \"kw\",   model = FALSE, # Don't store model frame   x = FALSE, # Don't store design matrices   y = FALSE, # Don't store response   control = gkw_control(hessian = FALSE) # Skip Hessian )  # Much smaller object object.size(fit_minimal) #> 745256 bytes  # Trade-off: Limited post-fitting capabilities # Can still use: coef(), logLik(), AIC(), BIC() # Cannot use: predict(), some diagnostics  # Example 11.2: Fast exploratory analysis # Fit many models quickly without standard errors formulas <- list(   yield ~ batch,   yield ~ temp,   yield ~ batch + temp,   yield ~ batch * temp )  fast_fits <- lapply(formulas, function(f) {   gkwreg(f, GasolineYield,     family = \"kw\",     control = gkw_control(hessian = FALSE),     model = FALSE, x = FALSE, y = FALSE   ) })  # Compare models via AIC sapply(fast_fits, AIC) #> [1]  -42.93436  -74.90259 -169.93784 -180.04162  # Refit best model with full inference best_formula <- formulas[[which.min(sapply(fast_fits, AIC))]] fit_final <- gkwreg(best_formula, GasolineYield, family = \"kw\") #> Warning: NaNs produced summary(fit_final) #>  #> Generalized Kumaraswamy Regression Model Summary #>  #> Family: kw  #>  #> Call: #> gkwreg(formula = best_formula, data = GasolineYield, family = \"kw\") #>  #> Residuals: #>      Min   Q1.25%   Median     Mean   Q3.75%      Max  #> -33.0040 -32.9155 -32.8540 -32.8354 -32.7615 -32.5750  #>  #> Coefficients: #>                    Estimate Std. Error z value Pr(>|z|)     #> alpha:(Intercept)  1.819446   0.007857   231.6   <2e-16 *** #> alpha:batch1       0.013261        NaN     NaN      NaN     #> alpha:batch2      -0.263197        NaN     NaN      NaN     #> alpha:batch3      -0.430252        NaN     NaN      NaN     #> alpha:batch4      -0.443577        NaN     NaN      NaN     #> alpha:batch5      -0.991915        NaN     NaN      NaN     #> alpha:batch6      -0.506689        NaN     NaN      NaN     #> alpha:batch7      -0.781482        NaN     NaN      NaN     #> alpha:batch8      -0.986533        NaN     NaN      NaN     #> alpha:batch9      -0.354264        NaN     NaN      NaN     #> alpha:temp         0.002835        NaN     NaN      NaN     #> alpha:batch1:temp  0.002022        NaN     NaN      NaN     #> alpha:batch2:temp  0.002119        NaN     NaN      NaN     #> alpha:batch3:temp  0.003146        NaN     NaN      NaN     #> alpha:batch4:temp  0.002343        NaN     NaN      NaN     #> alpha:batch5:temp  0.003943        NaN     NaN      NaN     #> alpha:batch6:temp  0.002479        NaN     NaN      NaN     #> alpha:batch7:temp  0.002634        NaN     NaN      NaN     #> alpha:batch8:temp  0.003084        NaN     NaN      NaN     #> alpha:batch9:temp  0.001238        NaN     NaN      NaN     #> beta:(Intercept)  35.498475   0.184273   192.6   <2e-16 *** #> --- #> Signif. codes:  0 ‚Äò***‚Äô 0.001 ‚Äò**‚Äô 0.01 ‚Äò*‚Äô 0.05 ‚Äò.‚Äô 0.1 ‚Äò ‚Äô 1 #>  #> Confidence intervals (95%): #>                        3%     98% #> alpha:(Intercept)  1.8040  1.8348 #> alpha:batch1          NaN     NaN #> alpha:batch2          NaN     NaN #> alpha:batch3          NaN     NaN #> alpha:batch4          NaN     NaN #> alpha:batch5          NaN     NaN #> alpha:batch6          NaN     NaN #> alpha:batch7          NaN     NaN #> alpha:batch8          NaN     NaN #> alpha:batch9          NaN     NaN #> alpha:temp            NaN     NaN #> alpha:batch1:temp     NaN     NaN #> alpha:batch2:temp     NaN     NaN #> alpha:batch3:temp     NaN     NaN #> alpha:batch4:temp     NaN     NaN #> alpha:batch5:temp     NaN     NaN #> alpha:batch6:temp     NaN     NaN #> alpha:batch7:temp     NaN     NaN #> alpha:batch8:temp     NaN     NaN #> alpha:batch9:temp     NaN     NaN #> beta:(Intercept)  35.1373 35.8596 #>  #> Link functions: #> alpha: log #> beta: log #>  #> Fitted parameter means: #> alpha: 22.47 #> beta: 2.608e+15 #> gamma: 1 #> delta: 0 #> lambda: 1 #>  #> Model fit statistics: #> Number of observations: 32  #> Number of parameters: 21  #> Residual degrees of freedom: 11  #> Log-likelihood: 111  #> AIC: -180  #> BIC: -149.3  #> RMSE: 32.84  #> Efron's R2: -96802  #> Mean Absolute Error: 32.84  #>  #> Convergence status: Failed  #> Iterations: 227  #>   # SECTION 12: Model Selection and Comparison  # Example 12.1: Nested model testing fit1 <- gkwreg(yield ~ 1, GasolineYield, family = \"kw\") fit2 <- gkwreg(yield ~ batch, GasolineYield, family = \"kw\") fit3 <- gkwreg(yield ~ batch + temp, GasolineYield, family = \"kw\") #> Warning: NaNs produced  # Likelihood ratio tests anova(fit1, fit2, fit3) #> Analysis of Deviance Table #>  #> Model 1: yield ~ 1 #> Model 2: yield ~ batch #> Model 3: yield ~ batch + temp #>  #>      Resid. Df Resid. Dev Df  Deviance Pr(>Chi)     #> fit1  30.00000  -57.02258                           #> fit2  21.00000  -64.93436  9   7.91178  0.54306     #> fit3  20.00000 -193.93784  1 129.00348  < 1e-04 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1  # Example 12.2: Information criteria table models <- list(   \"Intercept only\" = fit1,   \"Batch effect\" = fit2,   \"Batch + Temp\" = fit3 )  ic_table <- data.frame(   Model = names(models),   df = sapply(models, function(m) m$npar),   LogLik = sapply(models, logLik),   AIC = sapply(models, AIC),   BIC = sapply(models, BIC),   Delta_AIC = sapply(models, AIC) - min(sapply(models, AIC)) ) print(ic_table) #>                         Model df   LogLik        AIC        BIC Delta_AIC #> Intercept only Intercept only  2 28.51129  -53.02258  -50.09111  116.9153 #> Batch effect     Batch effect 11 32.46718  -42.93436  -26.81126  127.0035 #> Batch + Temp     Batch + Temp 12 96.96892 -169.93784 -152.34901    0.0000  # Example 12.3: Cross-validation for predictive performance # 5-fold cross-validation set.seed(2203) n <- nrow(GasolineYield) folds <- sample(rep(1:5, length.out = n))  cv_rmse <- sapply(1:5, function(fold) {   train <- GasolineYield[folds != fold, ]   test <- GasolineYield[folds == fold, ]    fit_train <- gkwreg(yield ~ batch + temp, train,     family = \"kw\"   )   pred_test <- predict(fit_train, newdata = test, type = \"response\")    sqrt(mean((test$yield - pred_test)^2)) }) #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced  cat(\"Cross-validated RMSE:\", mean(cv_rmse), \"\\n\") #> Cross-validated RMSE: 0.09019904  # }"},{"path":"https://evandeilton.github.io/gkwreg/reference/logLik.gkwreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Log-Likelihood from Generalized Kumaraswamy Regression Models ‚Äî logLik.gkwreg","title":"Extract Log-Likelihood from Generalized Kumaraswamy Regression Models ‚Äî logLik.gkwreg","text":"Extracts log-likelihood value fitted Generalized Kumaraswamy (GKw) regression model object.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/logLik.gkwreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Log-Likelihood from Generalized Kumaraswamy Regression Models ‚Äî logLik.gkwreg","text":"","code":"# S3 method for class 'gkwreg' logLik(object, ...)"},{"path":"https://evandeilton.github.io/gkwreg/reference/logLik.gkwreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Log-Likelihood from Generalized Kumaraswamy Regression Models ‚Äî logLik.gkwreg","text":"object object class \"gkwreg\", typically obtained gkwreg. ... Currently used.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/logLik.gkwreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Log-Likelihood from Generalized Kumaraswamy Regression Models ‚Äî logLik.gkwreg","text":"object class \"logLik\" containing log-likelihood value following attributes: df Number estimated parameters nobs Number observations","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/logLik.gkwreg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract Log-Likelihood from Generalized Kumaraswamy Regression Models ‚Äî logLik.gkwreg","text":"log-likelihood extracted fitted model object returned object class \"logLik\" appropriate attributes number parameters (df) observations (nobs). attributes required information criteria calculations. GKw regression model parameter vector \\(\\theta\\), log-likelihood defined : $$\\ell(\\theta \\mid y) = \\sum_{=1}^n \\log f(y_i; \\alpha_i, \\beta_i, \\gamma_i, \\delta_i, \\lambda_i)$$ \\(f(\\cdot)\\) probability density function specified GKw family distribution, parameters may depend covariates link functions.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwreg/reference/logLik.gkwreg.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract Log-Likelihood from Generalized Kumaraswamy Regression Models ‚Äî logLik.gkwreg","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/logLik.gkwreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Log-Likelihood from Generalized Kumaraswamy Regression Models ‚Äî logLik.gkwreg","text":"","code":"# \\donttest{ # Load example data data(GasolineYield)  # Fit a Kumaraswamy regression model fit <- gkwreg(yield ~ batch + temp, data = GasolineYield, family = \"kw\") #> Warning: NaNs produced  # Extract log-likelihood ll <- logLik(fit) print(ll) #> 'log Lik.' 96.96892 (df=12)  # Access attributes cat(\"Log-likelihood:\", as.numeric(ll), \"\\n\") #> Log-likelihood: 96.96892  cat(\"Parameters:\", attr(ll, \"df\"), \"\\n\") #> Parameters: 12  cat(\"Observations:\", attr(ll, \"nobs\"), \"\\n\") #> Observations: 32  # }"},{"path":"https://evandeilton.github.io/gkwreg/reference/lrtest.html","id":null,"dir":"Reference","previous_headings":"","what":"Likelihood Ratio Test for Nested GKw Models ‚Äî lrtest","title":"Likelihood Ratio Test for Nested GKw Models ‚Äî lrtest","text":"Performs likelihood ratio test compare two nested Generalized Kumaraswamy regression models.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/lrtest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Likelihood Ratio Test for Nested GKw Models ‚Äî lrtest","text":"","code":"lrtest(object, object2)"},{"path":"https://evandeilton.github.io/gkwreg/reference/lrtest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Likelihood Ratio Test for Nested GKw Models ‚Äî lrtest","text":"object fitted model object class \"gkwreg\" (restricted model). object2 fitted model object class \"gkwreg\" (full model).","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/lrtest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Likelihood Ratio Test for Nested GKw Models ‚Äî lrtest","text":"list class \"htest\" containing: statistic LRT test statistic parameter Degrees freedom test p.value P-value chi-squared distribution method Description test data.name Names compared models","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/lrtest.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Likelihood Ratio Test for Nested GKw Models ‚Äî lrtest","text":"function performs likelihood ratio test (LRT) compare two nested models. test statistic : $$LRT = 2(\\ell_{\\text{full}} - \\ell_{\\text{restricted}})$$ follows chi-squared distribution degrees freedom equal difference number parameters. models must nested (one special case ) fitted data test valid.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwreg/reference/lrtest.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Likelihood Ratio Test for Nested GKw Models ‚Äî lrtest","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/lrtest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Likelihood Ratio Test for Nested GKw Models ‚Äî lrtest","text":"","code":"# \\donttest{ data(GasolineYield)  # Fit nested models fit_restricted <- gkwreg(yield ~ temp, data = GasolineYield, family = \"kw\") fit_full <- gkwreg(yield ~ batch + temp, data = GasolineYield, family = \"kw\") #> Warning: NaNs produced  # Likelihood ratio test lrtest(fit_restricted, fit_full) #>  #> \tLikelihood Ratio Test for Nested GKw Models #>  #> data:  fit_restricted vs fit_full #> LRT = 113.04, df = 9, p-value < 2.2e-16 #>  # }"},{"path":"https://evandeilton.github.io/gkwreg/reference/model.frame.gkwreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Model Frame from GKw Regression Model ‚Äî model.frame.gkwreg","title":"Extract Model Frame from GKw Regression Model ‚Äî model.frame.gkwreg","text":"Extracts model frame fitted Generalized Kumaraswamy regression model object.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/model.frame.gkwreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Model Frame from GKw Regression Model ‚Äî model.frame.gkwreg","text":"","code":"# S3 method for class 'gkwreg' model.frame(formula, ...)"},{"path":"https://evandeilton.github.io/gkwreg/reference/model.frame.gkwreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Model Frame from GKw Regression Model ‚Äî model.frame.gkwreg","text":"formula object class \"gkwreg\". ... Currently used.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/model.frame.gkwreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Model Frame from GKw Regression Model ‚Äî model.frame.gkwreg","text":"data frame containing variables used fitting model.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwreg/reference/model.frame.gkwreg.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract Model Frame from GKw Regression Model ‚Äî model.frame.gkwreg","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/model.frame.gkwreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Model Frame from GKw Regression Model ‚Äî model.frame.gkwreg","text":"","code":"# \\donttest{ data(GasolineYield) fit <- gkwreg(yield ~ batch + temp, data = GasolineYield, family = \"kw\") #> Warning: NaNs produced head(model.frame(fit)) #>   yield batch temp #> 1 0.122     1  205 #> 2 0.223     1  275 #> 3 0.347     1  345 #> 4 0.457     1  407 #> 5 0.080     2  218 #> 6 0.131     2  273 # }"},{"path":"https://evandeilton.github.io/gkwreg/reference/model.matrix.gkwreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Model Matrix from GKw Regression Model ‚Äî model.matrix.gkwreg","title":"Extract Model Matrix from GKw Regression Model ‚Äî model.matrix.gkwreg","text":"Extracts model matrix (design matrix) fitted Generalized Kumaraswamy regression model object.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/model.matrix.gkwreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Model Matrix from GKw Regression Model ‚Äî model.matrix.gkwreg","text":"","code":"# S3 method for class 'gkwreg' model.matrix(object, ...)"},{"path":"https://evandeilton.github.io/gkwreg/reference/model.matrix.gkwreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Model Matrix from GKw Regression Model ‚Äî model.matrix.gkwreg","text":"object object class \"gkwreg\". ... Currently used.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/model.matrix.gkwreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Model Matrix from GKw Regression Model ‚Äî model.matrix.gkwreg","text":"design matrix.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwreg/reference/model.matrix.gkwreg.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract Model Matrix from GKw Regression Model ‚Äî model.matrix.gkwreg","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/model.matrix.gkwreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Model Matrix from GKw Regression Model ‚Äî model.matrix.gkwreg","text":"","code":"# \\donttest{ data(GasolineYield) fit <- gkwreg(yield ~ batch + temp, data = GasolineYield, family = \"kw\") #> Warning: NaNs produced head(model.matrix(fit)) #>   (Intercept) batch1 batch2 batch3 batch4 batch5 batch6 batch7 batch8 batch9 #> 1           1      1      0      0      0      0      0      0      0      0 #> 2           1      1      0      0      0      0      0      0      0      0 #> 3           1      1      0      0      0      0      0      0      0      0 #> 4           1      1      0      0      0      0      0      0      0      0 #> 5           1      0      1      0      0      0      0      0      0      0 #> 6           1      0      1      0      0      0      0      0      0      0 #>   temp #> 1  205 #> 2  275 #> 3  345 #> 4  407 #> 5  218 #> 6  273 # }"},{"path":"https://evandeilton.github.io/gkwreg/reference/nobs.gkwreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Number of Observations for GKw Regression Models ‚Äî nobs.gkwreg","title":"Number of Observations for GKw Regression Models ‚Äî nobs.gkwreg","text":"Extracts number observations fitted Generalized Kumaraswamy regression model.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/nobs.gkwreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Number of Observations for GKw Regression Models ‚Äî nobs.gkwreg","text":"","code":"# S3 method for class 'gkwreg' nobs(object, ...)"},{"path":"https://evandeilton.github.io/gkwreg/reference/nobs.gkwreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Number of Observations for GKw Regression Models ‚Äî nobs.gkwreg","text":"object object class \"gkwreg\", typically obtained gkwreg. ... Currently used.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/nobs.gkwreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Number of Observations for GKw Regression Models ‚Äî nobs.gkwreg","text":"Integer representing number observations used model fitting.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwreg/reference/nobs.gkwreg.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Number of Observations for GKw Regression Models ‚Äî nobs.gkwreg","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/nobs.gkwreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Number of Observations for GKw Regression Models ‚Äî nobs.gkwreg","text":"","code":"# \\donttest{ data(GasolineYield) fit <- gkwreg(yield ~ batch + temp, data = GasolineYield, family = \"kw\") #> Warning: NaNs produced nobs(fit) #> [1] 32 # }"},{"path":"https://evandeilton.github.io/gkwreg/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator ‚Äî %>%","title":"Pipe operator ‚Äî %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator ‚Äî %>%","text":"","code":"lhs %>% rhs"},{"path":"https://evandeilton.github.io/gkwreg/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator ‚Äî %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator ‚Äî %>%","text":"result calling rhs(lhs).","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/plot.gkwreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Diagnostic Plots for Generalized Kumaraswamy Regression Models ‚Äî plot.gkwreg","title":"Diagnostic Plots for Generalized Kumaraswamy Regression Models ‚Äî plot.gkwreg","text":"Produces comprehensive set diagnostic plots assessing adequacy fitted Generalized Kumaraswamy (GKw) regression model (objects class \"gkwreg\"). function offers flexible plot selection, multiple residual types, support base R graphics ggplot2 extensive customization options. Designed thorough model evaluation including residual analysis, influence diagnostics, goodness--fit assessment.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/plot.gkwreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Diagnostic Plots for Generalized Kumaraswamy Regression Models ‚Äî plot.gkwreg","text":"","code":"# S3 method for class 'gkwreg' plot(   x,   which = 1:6,   type = c(\"quantile\", \"pearson\", \"deviance\"),   family = NULL,   caption = NULL,   main = \"\",   sub.caption = \"\",   ask = NULL,   use_ggplot = FALSE,   arrange_plots = FALSE,   nsim = 100,   level = 0.9,   sample_size = NULL,   theme_fn = NULL,   save_diagnostics = FALSE,   ... )"},{"path":"https://evandeilton.github.io/gkwreg/reference/plot.gkwreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Diagnostic Plots for Generalized Kumaraswamy Regression Models ‚Äî plot.gkwreg","text":"x object class \"gkwreg\", typically result call gkwreg. Integer vector specifying diagnostic plots produce. subset plots required, specify subset numbers 1:6. Defaults 1:6 (plots). plots correspond : Residuals vs. Observation Indices: Checks temporal patterns, trends, autocorrelation residuals across observation order. Cook's Distance Plot: Identifies influential observations disproportionate impact model estimates. Points exceeding 4/n threshold warrant investigation. Generalized Leverage vs. Fitted Values: Identifies high leverage points unusual predictor combinations. Points exceeding 2p/n threshold may influential. Residuals vs. Linear Predictor: Checks non-linearity predictor-response relationship heteroscedasticity (non-constant variance). Half-Normal Plot Simulated Envelope: Assesses normality residuals (particularly useful quantile residuals) comparing observed residuals simulated quantiles. Points outside envelope indicate potential model misspecification. Predicted vs. Observed Values: Overall goodness--fit check showing model prediction accuracy systematic bias. type Character string indicating type residuals used plotting. Defaults \"quantile\". Valid options : \"quantile\": Randomized quantile residuals (Dunn & Smyth, 1996). Recommended bounded responses approximately N(0,1) model correctly specified. interpretable standard diagnostic tools. \"pearson\": Pearson residuals (response residual standardized estimated standard deviation). Useful checking variance function identifying heteroscedasticity patterns. \"deviance\": Deviance residuals. Related log-likelihood contribution observation. Sum squared deviance residuals equals model deviance. family Character string specifying distribution family assumptions use calculating residuals diagnostics. NULL (default), family stored within fitted object used. Specifying different family can useful diagnostic comparisons across competing model specifications. Available options match gkwreg: \"gkw\", \"bkw\", \"kkw\", \"ekw\", \"mc\", \"kw\", \"beta\". caption Titles diagnostic plots. Can specified three ways: NULL (default): Uses standard default captions plots. Character vector (backward compatibility): vector 6 strings corresponding plots 1-6. Must provide 6 titles even customizing . Named list (recommended): list plot numbers names (e.g., list(\"3\" = \"Custom Title\")). specified plots customized; others use defaults. allows partial customization without repeating titles. Default captions : \"Residuals vs. Observation Indices\" \"Cook's Distance Plot\" \"Generalized Leverage vs. Fitted Values\" \"Residuals vs. Linear Predictor\" \"Half-Normal Plot Residuals\" \"Predicted vs. Observed Values\" main Character string prepended individual plot captions (caption argument). Useful adding common prefix plot titles. Defaults \"\" (prefix). sub.caption Character string used common subtitle positioned plots (especially multiple plots arranged). NULL (default), automatically generates subtitle model call (deparse(x$call)). Set \"\" suppress subtitle entirely. ask Logical. TRUE (using base R graphics multiple plots interactive device), user prompted displaying plot. NULL (default), automatically determined: TRUE plots requested fit current screen layout session interactive; FALSE otherwise. Explicitly set FALSE disable prompting TRUE force prompting. use_ggplot Logical. TRUE, plots generated using ggplot2 package, providing modern, publication-quality graphics extensive theming capabilities. FALSE (default), uses base R graphics, faster require additional dependencies. Requires ggplot2 package installed set TRUE. arrange_plots Logical. relevant use_ggplot = TRUE multiple plots requested (length() > 1). TRUE, attempts arrange generated ggplot objects grid layout using either gridExtra ggpubr package (requires one installed). FALSE (default), plots displayed individually sequence. Ignored using base R graphics. nsim Integer. Number simulations used generate confidence envelope half-normal plot (= 5). Higher values provide accurate envelopes increase computation time. Defaults 100, typically provides adequate precision. Must positive integer. Typical range: 50-500. level Numeric. confidence level (0 1) simulated envelope half-normal plot (= 5). Defaults 0.90 (90\\ falling outside envelope suggest potential model inadequacy outliers. sample_size Integer NULL. specified integer less total number observations (x$nobs), random sample size used calculating diagnostics plotting. can significantly speed plot generation large datasets (n > 10,000) minimal impact diagnostic interpretation. Defaults NULL (use observations). Recommended values: 1000-5000 large datasets. theme_fn function. relevant use_ggplot = TRUE. Specifies ggplot2 theme function apply plots consistent styling (e.g., ggplot2::theme_bw, ggplot2::theme_classic, ggplot2::theme_minimal). NULL (default), automatically uses ggplot2::theme_minimal use_ggplot = TRUE. Can also custom theme function. Ignored using base R graphics. save_diagnostics Logical. TRUE, function invisibly returns list containing calculated diagnostic measures (residuals, leverage, Cook's distance, fitted values, etc.) instead model object. Useful programmatic access diagnostic values custom analysis reporting. FALSE (default), function invisibly returns original model object x. function primarily called side effect generating plots. ... Additional graphical parameters passed underlying plotting functions. base R graphics, standard par() parameters col, pch, cex, lwd, etc. ggplot2, typically ignored can used specific geom customizations advanced usage. Always specified last follow R best practices.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/plot.gkwreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Diagnostic Plots for Generalized Kumaraswamy Regression Models ‚Äî plot.gkwreg","text":"Invisibly returns either: original fitted model object x (save_diagnostics = FALSE, default). allows piping chaining operations. list containing diagnostic measures (save_diagnostics = TRUE), including: data: Data frame observation indices, observed values, fitted values, residuals, Cook's distance, leverage, linear predictors model_info: List model metadata (n, p, thresholds, family, type, etc.) half_normal: Data frame half-normal plot data envelope (includes 5) function primarily called side effect generating diagnostic plots. invisible return allows:","code":"# Silent plotting plot(model)  # Or capture for further use diag <- plot(model, save_diagnostics = TRUE) head(diag$data)"},{"path":"https://evandeilton.github.io/gkwreg/reference/plot.gkwreg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Diagnostic Plots for Generalized Kumaraswamy Regression Models ‚Äî plot.gkwreg","text":"Diagnostic plots essential evaluating assumptions adequacy fitted regression models. function provides comprehensive suite standard diagnostic tools adapted specifically gkwreg objects, model bounded responses (0,1) interval.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/plot.gkwreg.html","id":"residual-types-and-interpretation","dir":"Reference","previous_headings":"","what":"Residual Types and Interpretation","title":"Diagnostic Plots for Generalized Kumaraswamy Regression Models ‚Äî plot.gkwreg","text":"choice residual type (type) important depends diagnostic goal: Quantile Residuals (type = \"quantile\"): Recommended default bounded response models. residuals constructed approximately N(0,1) correctly specified model, making standard diagnostic tools (QQ-plots, hypothesis tests) directly applicable. particularly effective detecting model misspecification distributional family systematic bias. Pearson Residuals (type = \"pearson\"): Standardized residuals account mean-variance relationship. Useful assessing whether assumed variance function appropriate. plots show patterns non-constant spread, suggests variance model may misspecified. Deviance Residuals (type = \"deviance\"): Based contribution observation model deviance. Often symmetric distributions Pearson residuals useful identifying observations fit poorly according likelihood criterion.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/plot.gkwreg.html","id":"individual-plot-interpretations","dir":"Reference","previous_headings":"","what":"Individual Plot Interpretations","title":"Diagnostic Plots for Generalized Kumaraswamy Regression Models ‚Äî plot.gkwreg","text":"Plot 1 - Residuals vs. Observation Indices: Purpose: Detect temporal patterns autocorrelation look : Random scatter around zero. systematic patterns (trends, cycles, clusters) suggest autocorrelation omitted time-varying predictors. Action: patterns detected, consider adding time-related predictors modeling autocorrelation structure. Plot 2 - Cook's Distance: Purpose: Identify influential observations affecting coefficient estimates look : Points exceeding 4/n reference line high influence. observations, removed, substantially change model estimates. Action: Investigate high-influence points data entry errors, outliers, legitimately unusual cases. Consider sensitivity analysis. Plot 3 - Leverage vs. Fitted Values: Purpose: Identify observations unusual predictor combinations look : Points exceeding 2p/n reference line high leverage. unusual predictor space may may influential. Action: High leverage points deserve scrutiny problematic also large residuals (check Plots 1, 4). Plot 4 - Residuals vs. Linear Predictor: Purpose: Detect non-linearity heteroscedasticity look : Random scatter around zero constant spread. Curved patterns suggest non-linear relationships. Funnel shapes indicate heteroscedasticity (non-constant variance). Action: non-linearity, add polynomial terms use splines. heteroscedasticity, consider alternative link functions variance models. Plot 5 - Half-Normal Plot Envelope: Purpose: Assess overall distributional adequacy look : Points follow reference line stay within simulated envelope. Systematic deviations indicate distributional misspecification. Isolated points outside envelope suggest outliers. Action: many points fall outside envelope, try different distributional family check outliers data quality issues. Plot 6 - Predicted vs. Observed: Purpose: Overall model fit prediction accuracy look : Points cluster around 45-degree line. Systematic deviations indicate - -prediction. Large scatter indicates poor predictive performance. Action: Poor fit suggests missing predictors, incorrect functional form, inappropriate distributional family.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/plot.gkwreg.html","id":"using-caption-customization","dir":"Reference","previous_headings":"","what":"Using Caption Customization","title":"Diagnostic Plots for Generalized Kumaraswamy Regression Models ‚Äî plot.gkwreg","text":"new named list interface caption allows elegant partial customization: vector interface remains fully supported backward compatibility.","code":"# OLD WAY (still supported): Must repeat all 6 titles plot(model, caption = c(   \"Residuals vs. Observation Indices\",   \"Cook's Distance Plot\",   \"MY CUSTOM TITLE FOR PLOT 3\",  # Only want to change this   \"Residuals vs. Linear Predictor\",   \"Half-Normal Plot of Residuals\",   \"Predicted vs. Observed Values\" ))  # NEW WAY: Specify only what changes plot(model, caption = list(   \"3\" = \"MY CUSTOM TITLE FOR PLOT 3\" )) # Plots 1,2,4,5,6 automatically use defaults  # Customize multiple plots plot(model, caption = list(   \"1\" = \"Time Series of Residuals\",   \"5\" = \"Distributional Assessment\" ))"},{"path":"https://evandeilton.github.io/gkwreg/reference/plot.gkwreg.html","id":"null-defaults-and-intelligent-behavior","dir":"Reference","previous_headings":"","what":"NULL Defaults and Intelligent Behavior","title":"Diagnostic Plots for Generalized Kumaraswamy Regression Models ‚Äî plot.gkwreg","text":"Several arguments default NULL, triggering intelligent automatic behavior: sub.caption = NULL: Automatically generates subtitle model call ask = NULL: Automatically prompts needed (multiple plots interactive device) theme_fn = NULL: Automatically uses theme_minimal use_ggplot = TRUE can override explicitly setting values:","code":"plot(model, sub.caption = \"\")           # Disable subtitle plot(model, ask = FALSE)                # Never prompt plot(model, theme_fn = theme_classic)   # Custom theme"},{"path":"https://evandeilton.github.io/gkwreg/reference/plot.gkwreg.html","id":"performance-considerations","dir":"Reference","previous_headings":"","what":"Performance Considerations","title":"Diagnostic Plots for Generalized Kumaraswamy Regression Models ‚Äî plot.gkwreg","text":"large datasets (n > 10,000): Use sample_size work random subset (e.g., sample_size = 2000) Reduce nsim half-normal plot (e.g., nsim = 50) Use base R graphics (use_ggplot = FALSE) faster rendering Skip computationally intensive plots: = c(1,2,4,6) (excludes half-normal plot)","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/plot.gkwreg.html","id":"graphics-systems","dir":"Reference","previous_headings":"","what":"Graphics Systems","title":"Diagnostic Plots for Generalized Kumaraswamy Regression Models ‚Äî plot.gkwreg","text":"Base R Graphics (use_ggplot = FALSE): Faster rendering, especially large datasets external dependencies beyond base R Traditional R look feel Interactive ask prompting supported Customize via ... parameters (standard par() settings) ggplot2 Graphics (use_ggplot = TRUE): Modern, publication-quality aesthetics Consistent theming via theme_fn Grid arrangement support via arrange_plots Requires ggplot2 package (optionally gridExtra ggpubr arrangements) interactive ask prompting (ggplot limitation)","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/plot.gkwreg.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Diagnostic Plots for Generalized Kumaraswamy Regression Models ‚Äî plot.gkwreg","text":"Dunn, P. K., & Smyth, G. K. (1996). Randomized Quantile Residuals. Journal Computational Graphical Statistics, 5(3), 236-244. doi:10.1080/10618600.1996.10474708 Cook, R. D. (1977). Detection Influential Observation Linear Regression. Technometrics, 19(1), 15-18. doi:10.1080/00401706.1977.10489493 Atkinson, . C. (1985). Plots, Transformations Regression. Oxford University Press.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwreg/reference/plot.gkwreg.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Diagnostic Plots for Generalized Kumaraswamy Regression Models ‚Äî plot.gkwreg","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/plot.gkwreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Diagnostic Plots for Generalized Kumaraswamy Regression Models ‚Äî plot.gkwreg","text":"","code":"# \\donttest{ # EXAMPLE 1: Basic Usage with Default Settings  # Simulate data library(gkwdist)  set.seed(123) n <- 200 x1 <- runif(n, -2, 2) x2 <- rnorm(n)  # True model parameters alpha_true <- exp(0.7 + 0.3 * x1) beta_true <- exp(1.2 - 0.2 * x2)  # Generate response y <- rkw(n, alpha = alpha_true, beta = beta_true) df <- data.frame(y = y, x1 = x1, x2 = x2)  # Fit model model <- gkwreg(y ~ x1 | x2, data = df, family = \"kw\")  # Generate all diagnostic plots with defaults par(mfrow = c(3, 2)) plot(model, ask = FALSE) #> Simulating envelope ( 100 iterations): .......... Done!   # EXAMPLE 2: Selective Plots with Custom Residual Type  # Focus on key diagnostic plots only par(mfrow = c(3, 1)) plot(model,   which = c(2, 4, 5), # Cook's distance, Resid vs LinPred, Half-normal   type = \"pearson\" ) # Use Pearson residuals #> Simulating envelope ( 100 iterations): .......... Done!   # Check for influential points (plot 2) and non-linearity (plot 4) par(mfrow = c(2, 1)) plot(model,   which = c(2, 4),   type = \"deviance\" )   # EXAMPLE 3: Caption Customization - New Named List Interface  # Customize only specific plot titles (RECOMMENDED NEW WAY) par(mfrow = c(3, 1)) plot(model,   which = c(1, 4, 6),   caption = list(     \"1\" = \"Time Pattern Check\",     \"4\" = \"Linearity Assessment\",     \"6\" = \"Predictive Accuracy\"   ) )   # Customize subtitle and main title par(mfrow = c(2, 1)) plot(model,   which = c(1, 5),   main = \"Model Diagnostics\",   sub.caption = \"Kumaraswamy Regression - Training Data\",   caption = list(\"5\" = \"Normality Check with 95% Envelope\") ) #> Simulating envelope ( 100 iterations): .......... Done!   # Suppress subtitle entirely par(mfrow = c(3, 2)) plot(model, sub.caption = \"\") #> Simulating envelope ( 100 iterations): .......... Done!   # EXAMPLE 4: Backward Compatible Caption (Vector Interface)  # OLD WAY - still fully supported par(mfrow = c(3, 2)) plot(model,   which = 1:6,   caption = c(     \"Residual Pattern Analysis\",     \"Influence Diagnostics\",     \"Leverage Assessment\",     \"Linearity Check\",     \"Distributional Fit\",     \"Prediction Quality\"   ) ) #> Simulating envelope ( 100 iterations): .......... Done!   # EXAMPLE 5: ggplot2 Graphics with Theming  # Modern publication-quality plots plot(model,   use_ggplot = TRUE,   arrange_plots = TRUE ) #> Simulating envelope ( 100 iterations): .......... Done!   # With custom theme plot(model,   use_ggplot = TRUE,   theme_fn = ggplot2::theme_bw,   arrange_plots = TRUE ) #> Simulating envelope ( 100 iterations): .......... Done!   # With classic theme and custom colors (via ...) plot(model,   use_ggplot = TRUE,   theme_fn = ggplot2::theme_classic,   arrange_plots = TRUE ) #> Simulating envelope ( 100 iterations): .......... Done!   # EXAMPLE 6: Arranged Multi-Panel ggplot2 Display  # Requires gridExtra or ggpubr package plot(model,   which = 1:4,   use_ggplot = TRUE,   arrange_plots = TRUE, # Arrange in grid   theme_fn = ggplot2::theme_minimal )   # Focus plots in 2x2 grid plot(model,   which = c(2, 3, 4, 6),   use_ggplot = TRUE,   arrange_plots = TRUE,   caption = list(     \"2\" = \"Influential Cases\",     \"3\" = \"High Leverage Points\"   ) )   # EXAMPLE 7: Half-Normal Plot Customization  # Higher precision envelope (more simulations) par(mfrow = c(1, 2)) plot(model,   which = 5,   nsim = 500, # More accurate envelope   level = 0.95 ) # 95% confidence level #> Simulating envelope ( 500 iterations): .......... Done!  # Quick envelope for large datasets plot(model,   which = 5,   nsim = 500, # Faster computation   level = 0.90 ) #> Simulating envelope ( 500 iterations): .......... Done!   # EXAMPLE 8: Different Residual Types Comparison  # Compare different residual types par(mfrow = c(2, 2)) plot(model, which = 4, type = \"quantile\", main = \"Quantile\") plot(model, which = 4, type = \"pearson\", main = \"Pearson\") plot(model, which = 4, type = \"deviance\", main = \"Deviance\") par(mfrow = c(1, 1))   # Quantile residuals for half-normal plot (recommended) plot(model, which = 5, type = \"quantile\") #> Simulating envelope ( 100 iterations): .......... Done!   # EXAMPLE 9: Family Comparison Diagnostics  # Compare diagnostics under different distributional assumptions # Helps assess if alternative family would fit better par(mfrow = c(2, 2)) plot(model,   which = c(5, 6),   family = \"kw\", # Original family   main = \"Kumaraswamy\" ) #> Simulating envelope ( 100 iterations): .......... Done!  plot(model,   which = c(5, 6),   family = \"beta\", # Alternative family   main = \"Beta\" ) #> Using different family (beta) than what was used to fit the model (kw) for diagnostics. #> Using different family (beta) than what was used to fit the model (kw). Recalculating fitted values... #> Simulating envelope ( 100 iterations): .......... Done!  par(mfrow = c(1, 1))  # EXAMPLE 10: Large Dataset - Performance Optimization  # Simulate large dataset set.seed(456) n_large <- 50000 x1_large <- runif(n_large, -2, 2) x2_large <- rnorm(n_large) alpha_large <- exp(0.5 + 0.2 * x1_large) beta_large <- exp(1.0 - 0.1 * x2_large) y_large <- rkw(n_large, alpha = alpha_large, beta = beta_large) df_large <- data.frame(y = y_large, x1 = x1_large, x2 = x2_large)  model_large <- gkwreg(y ~ x1 | x2, data = df_large, family = \"kw\")  # Optimized plotting for large dataset par(mfrow = c(2, 2), mar = c(3, 3, 2, 2)) plot(model_large,   which = c(1, 2, 4, 6), # Skip computationally intensive plot 5   sample_size = 2000, # Use random sample of 2000 observations   ask = FALSE ) # Don't prompt   # If half-normal plot needed, reduce simulations par(mfrow = c(1, 1)) plot(model_large,   which = 5,   sample_size = 1000, # Smaller sample   nsim = 50 ) # Fewer simulations #> Simulating envelope ( 50 iterations): .......... Done!   # EXAMPLE 11: Saving Diagnostic Data for Custom Analysis  # Extract diagnostic measures without plotting par(mfrow = c(1, 1)) diag_data <- plot(model_large,   which = 1:6,   save_diagnostics = TRUE ) #> Simulating envelope ( 100 iterations): .......... Done!  # Examine structure str(diag_data) #> List of 3 #>  $ data       :'data.frame':\t50000 obs. of  8 variables: #>   ..$ index    : int [1:50000] 1 2 3 4 5 6 7 8 9 10 ... #>   ..$ y_obs    : num [1:50000] 0.185 0.272 0.771 0.135 0.833 ... #>   ..$ fitted   : num [1:50000] 0.329 0.352 0.472 0.506 0.498 ... #>   ..$ resid    : num [1:50000] -0.45 -0.196 1.363 -1.821 1.697 ... #>   ..$ abs_resid: num [1:50000] 0.45 0.196 1.363 1.821 1.697 ... #>   ..$ cook_dist: num [1:50000] 3.66e-04 6.51e-05 1.08e-02 3.33e-03 9.21e-03 ... #>   ..$ leverage : num [1:50000] 0.00716 0.00669 0.02227 0.00401 0.01253 ... #>   ..$ linpred  : num [1:50000] 0.165 0.262 0.681 0.776 0.725 ... #>  $ model_info :List of 8 #>   ..$ n                 : int 50000 #>   ..$ p                 : num 4 #>   ..$ cook_threshold    : num 8e-05 #>   ..$ leverage_threshold: num 0.00016 #>   ..$ family            : chr \"kw\" #>   ..$ type              : chr \"quantile\" #>   ..$ param_info        :List of 4 #>   .. ..$ names    : chr [1:2] \"alpha\" \"beta\" #>   .. ..$ n        : num 2 #>   .. ..$ fixed    :List of 3 #>   .. .. ..$ gamma : num 1 #>   .. .. ..$ delta : num 0 #>   .. .. ..$ lambda: num 1 #>   .. ..$ positions:List of 2 #>   .. .. ..$ alpha: num 1 #>   .. .. ..$ beta : num 2 #>   ..$ level             : num 0.9 #>  $ half_normal:'data.frame':\t50000 obs. of  5 variables: #>   ..$ index      : int [1:50000] 1 2 3 4 5 6 7 8 9 10 ... #>   ..$ theoretical: num [1:50000] 1.25e-05 3.76e-05 6.27e-05 8.77e-05 1.13e-04 ... #>   ..$ observed   : num [1:50000] 3.04e-05 3.62e-05 7.93e-05 9.25e-05 1.07e-04 ... #>   ..$ lower      : num [1:50000] 7.54e-07 8.56e-06 1.97e-05 3.05e-05 4.20e-05 ... #>   ..$ upper      : num [1:50000] 6.62e-05 1.18e-04 1.43e-04 1.70e-04 2.02e-04 ...  # Access diagnostic measures head(diag_data$data) # Residuals, Cook's distance, leverage, etc. #>   index     y_obs    fitted      resid abs_resid    cook_dist    leverage #> 1     1 0.1850315 0.3293218 -0.4500848 0.4500848 3.660713e-04 0.007162107 #> 2     2 0.2724554 0.3517257 -0.1964963 0.1964963 6.513023e-05 0.006691892 #> 3     3 0.7706749 0.4715884  1.3630349 1.3630349 1.076532e-02 0.022271859 #> 4     4 0.1350742 0.5059801 -1.8211089 1.8211089 3.331286e-03 0.004006455 #> 5     5 0.8325809 0.4979620  1.6974135 1.6974135 9.205032e-03 0.012525889 #> 6     6 0.4941673 0.3895391  0.5363847 0.5363847 8.755918e-04 0.011945865 #>     linpred #> 1 0.1652265 #> 2 0.2621458 #> 3 0.6807510 #> 4 0.7762421 #> 5 0.7251742 #> 6 0.3594552  # Identify influential observations influential <- which(diag_data$data$cook_dist > diag_data$model_info$cook_threshold) cat(\"Influential observations:\", head(influential), \"\\n\") #> Influential observations: 1 3 4 5 6 7   # High leverage points high_lev <- which(diag_data$data$leverage > diag_data$model_info$leverage_threshold) cat(\"High leverage points:\", head(high_lev), \"\\n\") #> High leverage points: 1 2 3 4 5 6   # Custom diagnostic plot using saved data plot(diag_data$data$fitted, diag_data$data$resid,   xlab = \"Fitted Values\", ylab = \"Residuals\",   main = \"Custom Diagnostic Plot\",   col = ifelse(diag_data$data$cook_dist >     diag_data$model_info$cook_threshold, \"red\", \"black\"),   pch = 16 ) abline(h = 0, col = \"gray\", lty = 2) legend(\"topright\", legend = \"Influential\", col = \"red\", pch = 16)   # EXAMPLE 12: Interactive Plotting Control  # ask = TRUE Force prompting between plots (useful for presentations) # Disable prompting (batch processing) par(mfrow = c(3, 2)) plot(model,   which = 1:6,   ask = FALSE ) # Never prompts #> Simulating envelope ( 100 iterations): .......... Done!   # EXAMPLE 13: Base R Graphics Customization via ...  # Customize point appearance par(mfrow = c(2, 2)) plot(model,   which = c(1, 4, 6),   pch = 16, # Filled circles   col = \"steelblue\", # Blue points   cex = 0.8 ) # Smaller points  # Multiple customizations plot(model,   which = 2,   pch = 21, # Circles with border   col = \"black\", # Border color   bg = \"lightblue\", # Fill color   cex = 1.2, # Larger points   lwd = 2 ) # Thicker lines   # EXAMPLE 14: Comparing Models  # Fit competing models model_kw <- gkwreg(y ~ x1 | x2, data = df, family = \"kw\") model_beta <- gkwreg(y ~ x1 | x2, data = df, family = \"beta\")  # Compare diagnostics side-by-side par(mfrow = c(2, 2))  # Kumaraswamy model plot(model_kw, which = 5, main = \"Kumaraswamy - Half-Normal\") #> Simulating envelope ( 100 iterations): .......... Done! plot(model_kw, which = 6, main = \"Kumaraswamy - Pred vs Obs\")  # Beta model plot(model_beta, which = 5, main = \"Beta - Half-Normal\") #> Simulating envelope ( 100 iterations): .......... Done! plot(model_beta, which = 6, main = \"Beta - Pred vs Obs\")   par(mfrow = c(1, 1)) # }"},{"path":"https://evandeilton.github.io/gkwreg/reference/predict.gkwreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Predictions from a Fitted Generalized Kumaraswamy Regression Model ‚Äî predict.gkwreg","title":"Predictions from a Fitted Generalized Kumaraswamy Regression Model ‚Äî predict.gkwreg","text":"Computes predictions related quantities fitted Generalized Kumaraswamy (GKw) regression model object. method can extract fitted values, predicted means, linear predictors, parameter values, variances, densities, probabilities, quantiles based estimated model. Predictions can made new data original data used fit model.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/predict.gkwreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predictions from a Fitted Generalized Kumaraswamy Regression Model ‚Äî predict.gkwreg","text":"","code":"# S3 method for class 'gkwreg' predict(   object,   newdata = NULL,   type = \"response\",   na.action = stats::na.pass,   at = 0.5,   elementwise = NULL,   family = NULL,   ... )"},{"path":"https://evandeilton.github.io/gkwreg/reference/predict.gkwreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predictions from a Fitted Generalized Kumaraswamy Regression Model ‚Äî predict.gkwreg","text":"object object class \"gkwreg\", typically result call gkwreg. newdata optional data frame containing variables needed prediction. omitted, predictions made data used fit model. type character string specifying type prediction. Options : \"response\" \"mean\" Predicted mean response (default). \"link\" Linear predictors parameter applying inverse link functions. \"parameter\" Parameter values original scale (applying inverse link functions). \"alpha\", \"beta\", \"gamma\", \"delta\", \"lambda\" Values specific distribution parameter. \"variance\" Predicted variance response. \"density\" \"pdf\" Density function values points specified . \"probability\" \"cdf\" Cumulative distribution function values points specified . \"quantile\" Quantiles corresponding probabilities specified . na.action Function determining handle missing values newdata. Default stats::na.pass, returns NA cases missing predictors. Numeric vector values evaluate densities, probabilities, compute quantiles, depending type. Required type = \"density\", type = \"probability\", type = \"quantile\". Defaults 0.5. elementwise Logical. TRUE length number observations, applies value corresponding observation. FALSE (default), applies values observation, returning matrix. family Character string specifying distribution family use calculations. NULL (default), uses family fitted model. Options match gkwreg: \"gkw\", \"bkw\", \"kkw\", \"ekw\", \"mc\", \"kw\", \"beta\". ... Additional arguments (currently used).","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/predict.gkwreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predictions from a Fitted Generalized Kumaraswamy Regression Model ‚Äî predict.gkwreg","text":"return value depends type argument: type = \"response\", type = \"variance\", individual parameters (type = \"alpha\", etc.): numeric vector length equal number rows newdata (original data). type = \"link\" type = \"parameter\": data frame columns parameter rows corresponding observations. type = \"density\", type = \"probability\", type = \"quantile\": elementwise = TRUE: numeric vector length equal number rows newdata (original data). elementwise = FALSE: matrix rows correspond observations columns correspond values .","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/predict.gkwreg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Predictions from a Fitted Generalized Kumaraswamy Regression Model ‚Äî predict.gkwreg","text":"predict.gkwreg function provides flexible framework obtaining predictions inference fitted Generalized Kumaraswamy regression models. handles subfamilies GKw distributions respects parametrization link functions specified original model.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/predict.gkwreg.html","id":"prediction-types","dir":"Reference","previous_headings":"","what":"Prediction Types","title":"Predictions from a Fitted Generalized Kumaraswamy Regression Model ‚Äî predict.gkwreg","text":"function supports several types predictions: Response/Mean: Computes expected value response variable based model parameters. GKw family distributions, requires numerical integration special formulas. Link: Returns linear predictors parameter without applying inverse link functions. values \\(\\eta_j = X\\beta_j\\) parameter \\(j\\). Parameter: Computes distribution parameter values original scale applying appropriate inverse link functions linear predictors. example, alpha uses log link, \\(\\alpha = \\exp(X\\beta_\\alpha)\\). Individual Parameters: Extract specific parameter values (alpha, beta, gamma, delta, lambda) original scale. Variance: Estimates variance response based model parameters. distributions, analytical formulas used; others, numerical approximations employed. Density/PDF: Evaluates probability density function specified points given model parameters. Probability/CDF: Computes cumulative distribution function specified points given model parameters. Quantile: Calculates quantiles corresponding specified probabilities given model parameters.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/predict.gkwreg.html","id":"link-functions","dir":"Reference","previous_headings":"","what":"Link Functions","title":"Predictions from a Fitted Generalized Kumaraswamy Regression Model ‚Äî predict.gkwreg","text":"function respects link functions specified original model parameter. supported link functions : \"log\": \\(g(\\mu) = \\log(\\mu)\\), \\(g^{-1}(\\eta) = \\exp(\\eta)\\) \"logit\": \\(g(\\mu) = \\log(\\mu/(1-\\mu))\\), \\(g^{-1}(\\eta) = 1/(1+\\exp(-\\eta))\\) \"probit\": \\(g(\\mu) = \\Phi^{-1}(\\mu)\\), \\(g^{-1}(\\eta) = \\Phi(\\eta)\\) \"cauchy\": \\(g(\\mu) = \\tan(\\pi*(\\mu-0.5))\\), \\(g^{-1}(\\eta) = 0.5 + (1/\\pi) \\arctan(\\eta)\\) \"cloglog\": \\(g(\\mu) = \\log(-\\log(1-\\mu))\\), \\(g^{-1}(\\eta) = 1 - \\exp(-\\exp(\\eta))\\) \"identity\": \\(g(\\mu) = \\mu\\), \\(g^{-1}(\\eta) = \\eta\\) \"sqrt\": \\(g(\\mu) = \\sqrt{\\mu}\\), \\(g^{-1}(\\eta) = \\eta^2\\) \"inverse\": \\(g(\\mu) = 1/\\mu\\), \\(g^{-1}(\\eta) = 1/\\eta\\) \"inverse-square\": \\(g(\\mu) = 1/\\sqrt{\\mu}\\), \\(g^{-1}(\\eta) = 1/\\eta^2\\)","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/predict.gkwreg.html","id":"family-specific-constraints","dir":"Reference","previous_headings":"","what":"Family-Specific Constraints","title":"Predictions from a Fitted Generalized Kumaraswamy Regression Model ‚Äî predict.gkwreg","text":"function enforces appropriate constraints distribution family: \"gkw\": 5 parameters (\\(\\alpha, \\beta, \\gamma, \\delta, \\lambda\\)) used. \"bkw\": \\(\\lambda = 1\\) fixed. \"kkw\": \\(\\gamma = 1\\) fixed. \"ekw\": \\(\\gamma = 1, \\delta = 0\\) fixed. \"mc\": \\(\\alpha = 1, \\beta = 1\\) fixed. \"kw\": \\(\\gamma = 1, \\delta = 0, \\lambda = 1\\) fixed. \"beta\": \\(\\alpha = 1, \\beta = 1, \\lambda = 1\\) fixed.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/predict.gkwreg.html","id":"parameter-bounds","dir":"Reference","previous_headings":"","what":"Parameter Bounds","title":"Predictions from a Fitted Generalized Kumaraswamy Regression Model ‚Äî predict.gkwreg","text":"parameters constrained valid ranges: \\(\\alpha, \\beta, \\gamma, \\lambda > 0\\) \\(0 < \\delta < 1\\)","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/predict.gkwreg.html","id":"using-with-new-data","dir":"Reference","previous_headings":"","what":"Using with New Data","title":"Predictions from a Fitted Generalized Kumaraswamy Regression Model ‚Äî predict.gkwreg","text":"providing newdata, ensure contains variables used model's formula. function extracts terms parameter's model matrix applies appropriate link functions calculate predictions. variables missing, function attempt substitute reasonable defaults raise error critical variables absent.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/predict.gkwreg.html","id":"using-for-model-evaluation","dir":"Reference","previous_headings":"","what":"Using for Model Evaluation","title":"Predictions from a Fitted Generalized Kumaraswamy Regression Model ‚Äî predict.gkwreg","text":"function useful model checking, generating predicted values plotting, evaluating fit different distribution families. specifying family parameter, can compare predictions different distributional assumptions.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/predict.gkwreg.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Predictions from a Fitted Generalized Kumaraswamy Regression Model ‚Äî predict.gkwreg","text":"Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation, 81(7), 883-898. Kumaraswamy, P. (1980). generalized probability density function double-bounded random processes. Journal Hydrology, 46(1-2), 79-88. Ferrari, S. L. P., & Cribari-Neto, F. (2004). Beta regression modelling rates proportions. Journal Applied Statistics, 31(7), 799-815. Jones, M. C. (2009). Kumaraswamy's distribution: beta-type distribution tractability advantages. Statistical Methodology, 6(1), 70-81.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwreg/reference/predict.gkwreg.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Predictions from a Fitted Generalized Kumaraswamy Regression Model ‚Äî predict.gkwreg","text":"Lopes, J. E. contributors","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/predict.gkwreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predictions from a Fitted Generalized Kumaraswamy Regression Model ‚Äî predict.gkwreg","text":"","code":"# \\donttest{ # Generate a sample dataset (n = 1000) library(gkwdist) set.seed(123) n <- 1000  # Create predictors x1 <- runif(n, -2, 2) x2 <- rnorm(n) x3 <- factor(rbinom(n, 1, 0.4))  # Simulate Kumaraswamy distributed data # True parameters with specific relationships to predictors true_alpha <- exp(0.7 + 0.3 * x1) true_beta <- exp(1.2 - 0.2 * x2 + 0.4 * (x3 == \"1\"))  # Generate random responses y <- rkw(n, alpha = true_alpha, beta = true_beta)  # Ensure responses are strictly in (0, 1) y <- pmax(pmin(y, 1 - 1e-7), 1e-7)  # Create data frame df <- data.frame(y = y, x1 = x1, x2 = x2, x3 = x3)  # Split into training and test sets set.seed(456) train_idx <- sample(n, 800) train_data <- df[train_idx, ] test_data <- df[-train_idx, ]  # ==================================================================== # Example 1: Basic usage - Fit a Kumaraswamy model and make predictions # ====================================================================  # Fit the model kw_model <- gkwreg(y ~ x1 | x2 + x3, data = train_data, family = \"kw\")  # Predict mean response for test data pred_mean <- predict(kw_model, newdata = test_data, type = \"response\")  # Calculate prediction error mse <- mean((test_data$y - pred_mean)^2) cat(\"Mean Squared Error:\", mse, \"\\n\") #> Mean Squared Error: 0.02982227   # ==================================================================== # Example 2: Different prediction types # ====================================================================  # Create a grid of values for visualization x1_grid <- seq(-2, 2, length.out = 100) grid_data <- data.frame(x1 = x1_grid, x2 = 0, x3 = 0)  # Predict different quantities pred_mean <- predict(kw_model, newdata = grid_data, type = \"response\") pred_var <- predict(kw_model, newdata = grid_data, type = \"variance\") pred_params <- predict(kw_model, newdata = grid_data, type = \"parameter\") pred_alpha <- predict(kw_model, newdata = grid_data, type = \"alpha\") pred_beta <- predict(kw_model, newdata = grid_data, type = \"beta\")  # Plot predicted mean and parameters against x1 plot(x1_grid, pred_mean,   type = \"l\", col = \"blue\",   xlab = \"x1\", ylab = \"Predicted Mean\", main = \"Mean Response vs x1\" )  plot(x1_grid, pred_var,   type = \"l\", col = \"red\",   xlab = \"x1\", ylab = \"Predicted Variance\", main = \"Response Variance vs x1\" )  plot(x1_grid, pred_alpha,   type = \"l\", col = \"purple\",   xlab = \"x1\", ylab = \"Alpha\", main = \"Alpha Parameter vs x1\" )  plot(x1_grid, pred_beta,   type = \"l\", col = \"green\",   xlab = \"x1\", ylab = \"Beta\", main = \"Beta Parameter vs x1\" )   # ==================================================================== # Example 3: Computing densities, CDFs, and quantiles # ====================================================================  # Select a single observation obs_data <- test_data[1, ]  # Create a sequence of y values for plotting y_seq <- seq(0.01, 0.99, length.out = 100)  # Compute density at each y value dens_values <- predict(kw_model,   newdata = obs_data,   type = \"density\", at = y_seq, elementwise = FALSE )  # Compute CDF at each y value cdf_values <- predict(kw_model,   newdata = obs_data,   type = \"probability\", at = y_seq, elementwise = FALSE )  # Compute quantiles for a sequence of probabilities prob_seq <- seq(0.1, 0.9, by = 0.1) quant_values <- predict(kw_model,   newdata = obs_data,   type = \"quantile\", at = prob_seq, elementwise = FALSE )  # Plot density and CDF plot(y_seq, dens_values,   type = \"l\", col = \"blue\",   xlab = \"y\", ylab = \"Density\", main = \"Predicted PDF\" )  plot(y_seq, cdf_values,   type = \"l\", col = \"red\",   xlab = \"y\", ylab = \"Cumulative Probability\", main = \"Predicted CDF\" )   # ==================================================================== # Example 4: Prediction under different distributional assumptions # ====================================================================  # Fit models with different families beta_model <- gkwreg(y ~ x1 | x2 + x3, data = train_data, family = \"beta\") gkw_model <- gkwreg(y ~ x1 | x2 + x3 | 1 | 1 | x3, data = train_data, family = \"gkw\")  # Predict means using different families pred_kw <- predict(kw_model, newdata = test_data, type = \"response\") pred_beta <- predict(beta_model, newdata = test_data, type = \"response\") pred_gkw <- predict(gkw_model, newdata = test_data, type = \"response\")  # Calculate MSE for each family mse_kw <- mean((test_data$y - pred_kw)^2) mse_beta <- mean((test_data$y - pred_beta)^2) mse_gkw <- mean((test_data$y - pred_gkw)^2)  cat(\"MSE by family:\\n\") #> MSE by family: cat(\"Kumaraswamy:\", mse_kw, \"\\n\") #> Kumaraswamy: 0.02982227  cat(\"Beta:\", mse_beta, \"\\n\") #> Beta: 0.06684878  cat(\"GKw:\", mse_gkw, \"\\n\") #> GKw: 0.0290125   # Compare predictions from different families visually plot(test_data$y, pred_kw,   col = \"blue\", pch = 16,   xlab = \"Observed\", ylab = \"Predicted\", main = \"Predicted vs Observed\" ) points(test_data$y, pred_beta, col = \"red\", pch = 17) points(test_data$y, pred_gkw, col = \"green\", pch = 18) abline(0, 1, lty = 2) legend(\"topleft\",   legend = c(\"Kumaraswamy\", \"Beta\", \"GKw\"),   col = c(\"blue\", \"red\", \"green\"), pch = c(16, 17, 18) )   # ==================================================================== # Example 5: Working with linear predictors and link functions # ====================================================================  # Extract linear predictors and parameter values lp <- predict(kw_model, newdata = test_data, type = \"link\") params <- predict(kw_model, newdata = test_data, type = \"parameter\")  # Verify that inverse link transformation works correctly # For Kumaraswamy model, alpha and beta use log links by default alpha_from_lp <- exp(lp$alpha) beta_from_lp <- exp(lp$beta)  # Compare with direct parameter predictions cat(\"Manual inverse link vs direct parameter prediction:\\n\") #> Manual inverse link vs direct parameter prediction: cat(\"Alpha difference:\", max(abs(alpha_from_lp - params$alpha)), \"\\n\") #> Alpha difference: 0  cat(\"Beta difference:\", max(abs(beta_from_lp - params$beta)), \"\\n\") #> Beta difference: 0   # ==================================================================== # Example 6: Elementwise calculations # ====================================================================  # Generate probabilities specific to each observation probs <- runif(nrow(test_data), 0.1, 0.9)  # Calculate quantiles for each observation at its own probability level quant_elementwise <- predict(kw_model,   newdata = test_data,   type = \"quantile\", at = probs, elementwise = TRUE )  # Calculate probabilities at each observation's actual value prob_at_y <- predict(kw_model,   newdata = test_data,   type = \"probability\", at = test_data$y, elementwise = TRUE )  # Create Q-Q plot plot(sort(prob_at_y), seq(0, 1, length.out = length(prob_at_y)),   xlab = \"Empirical Probability\", ylab = \"Theoretical Probability\",   main = \"P-P Plot\", type = \"l\" ) abline(0, 1, lty = 2, col = \"red\")   # ==================================================================== # Example 7: Predicting for the original data # ====================================================================  # Fit a model with original data full_model <- gkwreg(y ~ x1 + x2 + x3 | x1 + x2 + x3, data = df, family = \"kw\")  # Get fitted values using predict and compare with model's fitted.values fitted_from_predict <- predict(full_model, type = \"response\") fitted_from_model <- full_model$fitted.values  # Compare results cat(   \"Max difference between predict() and fitted.values:\",   max(abs(fitted_from_predict - fitted_from_model)), \"\\n\" ) #> Max difference between predict() and fitted.values: 0   # ==================================================================== # Example 8: Handling missing data # ====================================================================  # Create test data with some missing values test_missing <- test_data test_missing$x1[1:5] <- NA test_missing$x2[6:10] <- NA  # Predict with different na.action options pred_na_pass <- tryCatch(   predict(kw_model, newdata = test_missing, na.action = na.pass),   error = function(e) rep(NA, nrow(test_missing)) ) pred_na_omit <- tryCatch(   predict(kw_model, newdata = test_missing, na.action = na.omit),   error = function(e) rep(NA, nrow(test_missing)) )  # Show which positions have NAs cat(\"Rows with missing predictors:\", which(is.na(pred_na_pass)), \"\\n\") #> Rows with missing predictors:   cat(\"Length after na.omit:\", length(pred_na_omit), \"\\n\") #> Length after na.omit: 195  # }"},{"path":"https://evandeilton.github.io/gkwreg/reference/print.anova.gkwreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Method for ANOVA of GKw Models ‚Äî print.anova.gkwreg","title":"Print Method for ANOVA of GKw Models ‚Äî print.anova.gkwreg","text":"Print method analysis deviance tables produced anova.gkwreg.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/print.anova.gkwreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Method for ANOVA of GKw Models ‚Äî print.anova.gkwreg","text":"","code":"# S3 method for class 'anova.gkwreg' print(   x,   digits = max(getOption(\"digits\") - 2L, 3L),   signif.stars = getOption(\"show.signif.stars\", TRUE),   dig.tst = digits,   ... )"},{"path":"https://evandeilton.github.io/gkwreg/reference/print.anova.gkwreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Method for ANOVA of GKw Models ‚Äî print.anova.gkwreg","text":"x object class \"anova.gkwreg\" anova.gkwreg. digits Minimum number significant digits print. Default max(getOption(\"digits\") - 2, 3). signif.stars Logical; TRUE (default), significance stars printed alongside p-values. Can controlled globally via options(show.signif.stars = FALSE). dig.tst Number digits test statistics. Default digits. ... Additional arguments (currently ignored).","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/print.anova.gkwreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print Method for ANOVA of GKw Models ‚Äî print.anova.gkwreg","text":"object x, invisibly.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwreg/reference/print.anova.gkwreg.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print Method for ANOVA of GKw Models ‚Äî print.anova.gkwreg","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/print.gkwreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Method for Generalized Kumaraswamy Regression Models ‚Äî print.gkwreg","title":"Print Method for Generalized Kumaraswamy Regression Models ‚Äî print.gkwreg","text":"Print method objects class \"gkwreg\". Provides concise summary fitted model following style print.lm.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/print.gkwreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Method for Generalized Kumaraswamy Regression Models ‚Äî print.gkwreg","text":"","code":"# S3 method for class 'gkwreg' print(x, digits = max(3, getOption(\"digits\") - 3), ...)"},{"path":"https://evandeilton.github.io/gkwreg/reference/print.gkwreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Method for Generalized Kumaraswamy Regression Models ‚Äî print.gkwreg","text":"x object class \"gkwreg\", typically obtained gkwreg. digits Minimum number significant digits print. Default max(3, getOption(\"digits\") - 3). ... Additional arguments passed methods.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/print.gkwreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print Method for Generalized Kumaraswamy Regression Models ‚Äî print.gkwreg","text":"object x, invisibly.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/print.gkwreg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Print Method for Generalized Kumaraswamy Regression Models ‚Äî print.gkwreg","text":"print method provides concise overview fitted model, showing: call, deviance residuals summary, coefficient estimates, link functions, basic fit statistics. detailed output including standard errors significance tests, use summary.gkwreg.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwreg/reference/print.gkwreg.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print Method for Generalized Kumaraswamy Regression Models ‚Äî print.gkwreg","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/print.gkwreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print Method for Generalized Kumaraswamy Regression Models ‚Äî print.gkwreg","text":"","code":"# \\donttest{ data(GasolineYield) fit <- gkwreg(yield ~ batch + temp, data = GasolineYield, family = \"kw\") #> Warning: NaNs produced print(fit) #>  #> Call:  gkwreg(formula = yield ~ batch + temp, data = GasolineYield,  #>     family = \"kw\") #>  #> Deviance Residuals:  #>       Min        1Q    Median        3Q       Max  #> -0.028057 -0.002998  0.003669  0.009988  0.017351  #>  #> Coefficients: #> alpha:(Intercept)      alpha:batch1      alpha:batch2      alpha:batch3  #>          0.669355          0.838130          0.591274          0.710287  #>      alpha:batch4      alpha:batch5      alpha:batch6      alpha:batch7  #>          0.466756          0.520260          0.449785          0.224769  #>      alpha:batch8      alpha:batch9        alpha:temp  beta:(Intercept)  #>          0.203183          0.141845          0.005282         28.881698  #>  #> Link functions:  alpha = log, beta = log #>  #> Degrees of Freedom: 31 Total (i.e. Null);  20 Residual #> Residual Deviance: -193.9\tAIC: -169.9 #> Log-Lik: 96.97,  BIC: -152.3  #> R-squared: 0.9856,  RMSE: 0.01266  #>  #> Number of Fisher Scoring iterations: 68 #>   # With more digits print(fit, digits = 5) #>  #> Call:  gkwreg(formula = yield ~ batch + temp, data = GasolineYield,  #>     family = \"kw\") #>  #> Deviance Residuals:  #>        Min         1Q     Median         3Q        Max  #> -0.0280573 -0.0029985  0.0036691  0.0099881  0.0173508  #>  #> Coefficients: #> alpha:(Intercept)      alpha:batch1      alpha:batch2      alpha:batch3  #>         0.6693546         0.8381300         0.5912742         0.7102867  #>      alpha:batch4      alpha:batch5      alpha:batch6      alpha:batch7  #>         0.4667565         0.5202601         0.4497854         0.2247689  #>      alpha:batch8      alpha:batch9        alpha:temp  beta:(Intercept)  #>         0.2031834         0.1418454         0.0052823        28.8816975  #>  #> Link functions:  alpha = log, beta = log #>  #> Degrees of Freedom: 31 Total (i.e. Null);  20 Residual #> Residual Deviance: -193.94\tAIC: -169.94 #> Log-Lik: 96.969,  BIC: -152.35  #> R-squared: 0.98561,  RMSE: 0.01266  #>  #> Number of Fisher Scoring iterations: 68 #>  # }"},{"path":"https://evandeilton.github.io/gkwreg/reference/print.summary.gkwreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Method for Generalized Kumaraswamy Regression Summaries ‚Äî print.summary.gkwreg","title":"Print Method for Generalized Kumaraswamy Regression Summaries ‚Äî print.summary.gkwreg","text":"Formats prints summary output fitted Generalized Kumaraswamy (GKw) regression model (objects class \"summary.gkwreg\").","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/print.summary.gkwreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Method for Generalized Kumaraswamy Regression Summaries ‚Äî print.summary.gkwreg","text":"","code":"# S3 method for class 'summary.gkwreg' print(   x,   digits = max(3, getOption(\"digits\") - 3),   signif.stars = getOption(\"show.signif.stars\"),   ... )"},{"path":"https://evandeilton.github.io/gkwreg/reference/print.summary.gkwreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Method for Generalized Kumaraswamy Regression Summaries ‚Äî print.summary.gkwreg","text":"x object class \"summary.gkwreg\", typically result call summary.gkwreg. digits Integer, controlling number significant digits print. Defaults max(3, getOption(\"digits\") - 3). signif.stars Logical. TRUE, significance stars printed next p-values coefficient table. Defaults value getOption(\"show.signif.stars\"). ... Additional arguments, currently ignored method.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/print.summary.gkwreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print Method for Generalized Kumaraswamy Regression Summaries ‚Äî print.summary.gkwreg","text":"Invisibly returns original input object x. allows output print() assigned, primarily prints formatted summary console.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/print.summary.gkwreg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Print Method for Generalized Kumaraswamy Regression Summaries ‚Äî print.summary.gkwreg","text":"print method objects created summary.gkwreg. formats summary information display console. typically invoked automatically print() called summary.gkwreg object, simply typing name summary object interactive R session. output includes: Model family original function call. Summary statistics residuals. coefficient table estimates, standard errors, z-values, p-values, optionally marked significance stars (using printCoefmat). Confidence intervals coefficients (available). Link functions used parameter. Mean values fitted distribution parameters. Key model fit statistics (LogLik, AIC, BIC, RMSE, R^2, etc.). Convergence status number iterations.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwreg/reference/print.summary.gkwreg.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print Method for Generalized Kumaraswamy Regression Summaries ‚Äî print.summary.gkwreg","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/residuals.gkwreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Residuals from a Generalized Kumaraswamy Regression Model ‚Äî residuals.gkwreg","title":"Extract Residuals from a Generalized Kumaraswamy Regression Model ‚Äî residuals.gkwreg","text":"Extracts calculates various types residuals fitted Generalized Kumaraswamy (GKw) regression model object class \"gkwreg\", useful model diagnostics.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/residuals.gkwreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Residuals from a Generalized Kumaraswamy Regression Model ‚Äî residuals.gkwreg","text":"","code":"# S3 method for class 'gkwreg' residuals(   object,   type = c(\"response\", \"pearson\", \"deviance\", \"quantile\", \"modified.deviance\",     \"cox-snell\", \"score\", \"partial\"),   covariate_idx = 1,   parameter = \"alpha\",   family = NULL,   ... )"},{"path":"https://evandeilton.github.io/gkwreg/reference/residuals.gkwreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Residuals from a Generalized Kumaraswamy Regression Model ‚Äî residuals.gkwreg","text":"object object class \"gkwreg\", typically result call gkwreg. type Character string specifying type residuals compute. Available options : \"response\": (Default) Raw response residuals: \\(y - \\mu\\), \\(\\mu\\) fitted mean. \"pearson\": Pearson residuals: \\((y - \\mu) / \\sqrt{V(\\mu)}\\), \\(V(\\mu)\\) variance function specified family. \"deviance\": Deviance residuals: Signed square root unit deviances. Sum squares equals total deviance. \"quantile\": Randomized quantile residuals (Dunn & Smyth, 1996). Transformed via model's CDF standard normal quantile function. approximate standard normal distribution model correct. \"modified.deviance\": (typically implemented, placeholder) Standardized deviance residuals, potentially adjusted leverage. \"cox-snell\": Cox-Snell residuals: \\(-\\log(1 - F(y))\\), \\(F(y)\\) model's CDF. approximate standard exponential distribution model correct. \"score\": (typically implemented, placeholder) Score residuals, related derivative log-likelihood. \"partial\": Partial residuals specific predictor one parameter's linear model: \\(eta_p + \\beta_{pk} x_{ik}\\), \\(eta_p\\) partial linear predictor \\(\\beta_{pk} x_{ik}\\) component associated k-th covariate -th observation. Requires parameter covariate_idx. covariate_idx Integer. used type = \"partial\". Specifies index (column number corresponding model matrix) covariate compute partial residuals. parameter Character string. used type = \"partial\". Specifies distribution parameter (\"alpha\", \"beta\", \"gamma\", \"delta\", \"lambda\") whose linear predictor contains covariate interest. family Character string specifying distribution family assumptions use calculating residuals (especially types involving variance, deviance, CDF, etc.). NULL (default), family stored within fitted object used. Specifying different family may useful diagnostic comparisons. Available options match gkwreg: \"gkw\", \"bkw\", \"kkw\", \"ekw\", \"mc\", \"kw\", \"beta\". ... Additional arguments, currently ignored method.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/residuals.gkwreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Residuals from a Generalized Kumaraswamy Regression Model ‚Äî residuals.gkwreg","text":"numeric vector containing requested type residuals. length corresponds number observations used model fit.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/residuals.gkwreg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract Residuals from a Generalized Kumaraswamy Regression Model ‚Äî residuals.gkwreg","text":"function calculates various types residuals useful diagnosing adequacy fitted GKw regression model. Response residuals (type=\"response\") simplest, showing raw differences observed fitted mean values. Pearson residuals (type=\"pearson\") account mean-variance relationship specified model family. Constant variance plotted fitted values suggests variance function appropriate. Deviance residuals (type=\"deviance\") related log-likelihood contribution observation. sum squares equals total model deviance. often symmetric distributions Pearson residuals. Quantile residuals (type=\"quantile\") particularly useful non-standard distributions always approximately standard normal assumed distribution model structure correct. Deviations normality QQ-plot indicate model misspecification. Cox-Snell residuals (type=\"cox-snell\") provide another check overall distributional fit. plot sorted residuals theoretical exponential quantiles approximate straight line origin slope 1. Partial residuals (type=\"partial\") help visualize marginal relationship specific predictor response scale linear predictor chosen parameter, adjusted predictors. Calculations involving distribution's properties (variance, CDF, PDF) depend heavily specified family. function relies internal helper functions (potentially implemented C++ efficiency) compute based fitted parameters observation.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/residuals.gkwreg.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Extract Residuals from a Generalized Kumaraswamy Regression Model ‚Äî residuals.gkwreg","text":"Dunn, P. K., & Smyth, G. K. (1996). Randomized Quantile Residuals. Journal Computational Graphical Statistics, 5(3), 236-244. Cox, D. R., & Snell, E. J. (1968). General Definition Residuals. Journal Royal Statistical Society, Series B (Methodological), 30(2), 248-275. McCullagh, P., & Nelder, J. . (1989). Generalized Linear Models (2nd ed.). Chapman Hall/CRC.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwreg/reference/residuals.gkwreg.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract Residuals from a Generalized Kumaraswamy Regression Model ‚Äî residuals.gkwreg","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/residuals.gkwreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Residuals from a Generalized Kumaraswamy Regression Model ‚Äî residuals.gkwreg","text":"","code":"# \\donttest{ require(gkwreg) require(gkwdist)  # Example 1: Comprehensive residual analysis for FoodExpenditure data(FoodExpenditure) FoodExpenditure$prop <- FoodExpenditure$food / FoodExpenditure$income  fit_kw <- gkwreg(   prop ~ income + persons | income + persons,   data = FoodExpenditure,   family = \"kw\" )  # Extract different types of residuals res_response <- residuals(fit_kw, type = \"response\") res_pearson <- residuals(fit_kw, type = \"pearson\") res_deviance <- residuals(fit_kw, type = \"deviance\") res_quantile <- residuals(fit_kw, type = \"quantile\") res_coxsnell <- residuals(fit_kw, type = \"cox-snell\")  # Summary statistics residual_summary <- data.frame(   Type = c(\"Response\", \"Pearson\", \"Deviance\", \"Quantile\", \"Cox-Snell\"),   Mean = c(     mean(res_response), mean(res_pearson),     mean(res_deviance), mean(res_quantile),     mean(res_coxsnell)   ),   SD = c(     sd(res_response), sd(res_pearson),     sd(res_deviance), sd(res_quantile),     sd(res_coxsnell)   ),   Min = c(     min(res_response), min(res_pearson),     min(res_deviance), min(res_quantile),     min(res_coxsnell)   ),   Max = c(     max(res_response), max(res_pearson),     max(res_deviance), max(res_quantile),     max(res_coxsnell)   ) ) print(residual_summary) #>        Type          Mean         SD          Min       Max #> 1  Response  0.0001978698 0.07082919 -0.173565885 0.1546289 #> 2   Pearson -0.0026546844 2.43576048 -6.277689197 5.7524532 #> 3  Deviance  0.2017937920 1.71709988 -2.169734396 2.1909681 #> 4  Quantile -0.0052189130 1.02816180 -2.448661750 2.5380310 #> 5 Cox-Snell  0.9964306145 0.97984715  0.007195225 5.1896594  # Example 2: Diagnostic plots for model assessment data(GasolineYield)  fit_ekw <- gkwreg(   yield ~ batch + temp | temp | batch,   data = GasolineYield,   family = \"ekw\" )  # Set up plotting grid par(mfrow = c(2, 3))  # Plot 1: Residuals vs Fitted fitted_vals <- fitted(fit_ekw) res_pears <- residuals(fit_ekw, type = \"pearson\") plot(fitted_vals, res_pears,   xlab = \"Fitted Values\", ylab = \"Pearson Residuals\",   main = \"Residuals vs Fitted\",   pch = 19, col = rgb(0, 0, 1, 0.5) ) abline(h = 0, col = \"red\", lwd = 2, lty = 2) lines(lowess(fitted_vals, res_pears), col = \"blue\", lwd = 2)  # Plot 2: Normal QQ-plot (Quantile Residuals) res_quant <- residuals(fit_ekw, type = \"quantile\") qqnorm(res_quant,   main = \"Normal Q-Q Plot (Quantile Residuals)\",   pch = 19, col = rgb(0, 0, 1, 0.5) ) qqline(res_quant, col = \"red\", lwd = 2)  # Plot 3: Scale-Location (sqrt of standardized residuals) plot(fitted_vals, sqrt(abs(res_pears)),   xlab = \"Fitted Values\", ylab = expression(sqrt(\"|Std. Residuals|\")),   main = \"Scale-Location\",   pch = 19, col = rgb(0, 0, 1, 0.5) ) lines(lowess(fitted_vals, sqrt(abs(res_pears))), col = \"red\", lwd = 2)  # Plot 4: Histogram of Quantile Residuals hist(res_quant,   breaks = 15, probability = TRUE,   xlab = \"Quantile Residuals\",   main = \"Histogram with Normal Overlay\",   col = \"lightblue\", border = \"white\" ) curve(dnorm(x, mean(res_quant), sd(res_quant)),   add = TRUE, col = \"red\", lwd = 2 )  # Plot 5: Cox-Snell Residual Plot res_cs <- residuals(fit_ekw, type = \"cox-snell\") plot(qexp(ppoints(length(res_cs))), sort(res_cs),   xlab = \"Theoretical Exponential Quantiles\",   ylab = \"Ordered Cox-Snell Residuals\",   main = \"Cox-Snell Residual Plot\",   pch = 19, col = rgb(0, 0, 1, 0.5) ) abline(0, 1, col = \"red\", lwd = 2)  # Plot 6: Residuals vs Index plot(seq_along(res_pears), res_pears,   xlab = \"Observation Index\", ylab = \"Pearson Residuals\",   main = \"Residuals vs Index\",   pch = 19, col = rgb(0, 0, 1, 0.5) ) abline(h = 0, col = \"red\", lwd = 2, lty = 2)   par(mfrow = c(1, 1))  # Example 3: Partial residual plots for covariate effects data(ReadingSkills)  fit_interact <- gkwreg(   accuracy ~ dyslexia * iq | dyslexia + iq,   data = ReadingSkills,   family = \"kw\" )  # Partial residuals for IQ effect on alpha parameter X_alpha <- fit_interact$model_matrices$alpha iq_col_alpha <- which(colnames(X_alpha) == \"iq\")  if (length(iq_col_alpha) > 0) {   res_partial_alpha <- residuals(fit_interact,     type = \"partial\",     parameter = \"alpha\",     covariate_idx = iq_col_alpha   )    par(mfrow = c(1, 2))    # Partial residual plot for alpha   plot(ReadingSkills$iq, res_partial_alpha,     xlab = \"IQ (z-scores)\",     ylab = \"Partial Residual (alpha)\",     main = \"Effect of IQ on Mean (alpha)\",     pch = 19, col = ReadingSkills$dyslexia   )   lines(lowess(ReadingSkills$iq, res_partial_alpha),     col = \"blue\", lwd = 2   )   legend(\"topleft\",     legend = c(\"Control\", \"Dyslexic\"),     col = c(\"black\", \"red\"), pch = 19   )    # Partial residuals for IQ effect on beta parameter   X_beta <- fit_interact$model_matrices$beta   iq_col_beta <- which(colnames(X_beta) == \"iq\")    if (length(iq_col_beta) > 0) {     res_partial_beta <- residuals(fit_interact,       type = \"partial\",       parameter = \"beta\",       covariate_idx = iq_col_beta     )      plot(ReadingSkills$iq, res_partial_beta,       xlab = \"IQ (z-scores)\",       ylab = \"Partial Residual (beta)\",       main = \"Effect of IQ on Precision (beta)\",       pch = 19, col = ReadingSkills$dyslexia     )     lines(lowess(ReadingSkills$iq, res_partial_beta),       col = \"blue\", lwd = 2     )   }    par(mfrow = c(1, 1)) }  # Example 4: Comparing residuals across different families data(StressAnxiety)  fit_kw_stress <- gkwreg(   anxiety ~ stress | stress,   data = StressAnxiety,   family = \"kw\" )  # Quantile residuals under different family assumptions res_quant_kw <- residuals(fit_kw_stress, type = \"quantile\", family = \"kw\") res_quant_beta <- residuals(fit_kw_stress, type = \"quantile\", family = \"beta\") #> Using different family (beta) than what was used to fit the model (kw). #> Using different family (beta) than what was used to fit the model (kw). Recalculating fitted values...  # Compare normality par(mfrow = c(1, 2))  qqnorm(res_quant_kw,   main = \"QQ-Plot: Kumaraswamy Residuals\",   pch = 19, col = rgb(0, 0, 1, 0.5) ) qqline(res_quant_kw, col = \"red\", lwd = 2)  qqnorm(res_quant_beta,   main = \"QQ-Plot: Beta Residuals\",   pch = 19, col = rgb(0, 0.5, 0, 0.5) ) qqline(res_quant_beta, col = \"red\", lwd = 2)   par(mfrow = c(1, 1))  # Formal normality tests shapiro_kw <- shapiro.test(res_quant_kw) shapiro_beta <- shapiro.test(res_quant_beta)  cat(\"\\nShapiro-Wilk Test Results:\\n\") #>  #> Shapiro-Wilk Test Results: cat(   \"Kumaraswamy:  W =\", round(shapiro_kw$statistic, 4),   \", p-value =\", round(shapiro_kw$p.value, 4), \"\\n\" ) #> Kumaraswamy:  W = 0.9638 , p-value = 3e-04  cat(   \"Beta:         W =\", round(shapiro_beta$statistic, 4),   \", p-value =\", round(shapiro_beta$p.value, 4), \"\\n\" ) #> Beta:         W = 0.811 , p-value = 0   # Example 5: Outlier detection using standardized residuals data(MockJurors)  fit_mc <- gkwreg(   confidence ~ verdict * conflict | verdict + conflict,   data = MockJurors,   family = \"mc\" )  res_dev <- residuals(fit_mc, type = \"deviance\") res_quant <- residuals(fit_mc, type = \"quantile\")  # Identify potential outliers (|z| > 2.5) outlier_idx <- which(abs(res_quant) > 2.5)  if (length(outlier_idx) > 0) {   cat(\"\\nPotential outliers detected at indices:\", outlier_idx, \"\\n\")    # Display outlier information   outlier_data <- data.frame(     Index = outlier_idx,     Confidence = MockJurors$confidence[outlier_idx],     Verdict = MockJurors$verdict[outlier_idx],     Conflict = MockJurors$conflict[outlier_idx],     Quantile_Residual = round(res_quant[outlier_idx], 3),     Deviance_Residual = round(res_dev[outlier_idx], 3)   )   print(outlier_data)    # Influence plot   plot(seq_along(res_quant), res_quant,     xlab = \"Observation Index\",     ylab = \"Quantile Residual\",     main = \"Outlier Detection: Mock Jurors\",     pch = 19, col = rgb(0, 0, 1, 0.5)   )   points(outlier_idx, res_quant[outlier_idx],     col = \"red\", pch = 19, cex = 1.5   )   abline(     h = c(-2.5, 0, 2.5), col = c(\"orange\", \"black\", \"orange\"),     lty = c(2, 1, 2), lwd = 2   )   legend(\"topright\",     legend = c(\"Normal\", \"Outlier\", \"¬±2.5 SD\"),     col = c(rgb(0, 0, 1, 0.5), \"red\", \"orange\"),     pch = c(19, 19, NA),     lty = c(NA, NA, 2),     lwd = c(NA, NA, 2)   ) } else {   cat(\"\\nNo extreme outliers detected (|z| > 2.5)\\n\") } #>  #> Potential outliers detected at indices: 21 23 39 44 54  #>   Index Confidence      Verdict Conflict Quantile_Residual Deviance_Residual #> 1    21      0.995   two-option      yes             2.609             0.588 #> 2    23      0.995   two-option      yes             2.609             0.588 #> 3    39      0.005 three-option      yes            -3.052        141421.356 #> 4    44      0.005 three-option      yes            -3.052        141421.356 #> 5    54      0.995   two-option       no             2.641             0.288  # }"},{"path":"https://evandeilton.github.io/gkwreg/reference/response.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Response Variable from GKw Regression Model ‚Äî response","title":"Extract Response Variable from GKw Regression Model ‚Äî response","text":"Extracts response variable fitted Generalized Kumaraswamy regression model object.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/response.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Response Variable from GKw Regression Model ‚Äî response","text":"","code":"response(object, ...)  # S3 method for class 'gkwreg' response(object, ...)"},{"path":"https://evandeilton.github.io/gkwreg/reference/response.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Response Variable from GKw Regression Model ‚Äî response","text":"object object class \"gkwreg\". ... Currently used.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/response.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Response Variable from GKw Regression Model ‚Äî response","text":"numeric vector containing response variable values.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwreg/reference/response.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract Response Variable from GKw Regression Model ‚Äî response","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/response.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Response Variable from GKw Regression Model ‚Äî response","text":"","code":"# \\donttest{ data(GasolineYield) fit <- gkwreg(yield ~ batch + temp, data = GasolineYield, family = \"kw\") #> Warning: NaNs produced y <- response(fit) head(y) #>     1     2     3     4     5     6  #> 0.122 0.223 0.347 0.457 0.080 0.131  # }"},{"path":"https://evandeilton.github.io/gkwreg/reference/retinal.html","id":null,"dir":"Reference","previous_headings":"","what":"Intraocular Gas Decay in Retinal Surgery ‚Äî retinal","title":"Intraocular Gas Decay in Retinal Surgery ‚Äî retinal","text":"Longitudinal data recorded decay intraocular gas (perfluoropropane) complex retinal surgeries. dataset tracks proportion gas remaining time following vitrectomy procedures.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/retinal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Intraocular Gas Decay in Retinal Surgery ‚Äî retinal","text":"","code":"retinal"},{"path":"https://evandeilton.github.io/gkwreg/reference/retinal.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Intraocular Gas Decay in Retinal Surgery ‚Äî retinal","text":"data frame 40 observations 7 variables: ID integer. Patient identification number longitudinal tracking. Gas numeric. Proportion intraocular gas remaining (0-1 scale). Response variable measuring fraction perfluoropropane gas still present vitreous cavity. Time numeric. Time point measurement (days weeks post-surgery). LogT numeric. Logarithm time, log(Time). Used linearize exponential decay pattern. LogT2 numeric. Squared logarithm time, (log(Time))^2. Captures nonlinear decay patterns. Level factor. Initial gas concentration level time injection. Different starting concentrations affect decay kinetics.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/retinal.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Intraocular Gas Decay in Retinal Surgery ‚Äî retinal","text":"Based clinical data vitreoretinal surgery patients. Originally analyzed Song Tan (2000).","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/retinal.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Intraocular Gas Decay in Retinal Surgery ‚Äî retinal","text":"longitudinal dataset comes study gas decay following vitreoretinal surgery. Perfluoropropane (C3F8) commonly used temporary tamponade agent retinal detachment repair complex vitreoretinal procedures. Clinical background: vitrectomy retinal detachment, gas bubbles injected vitreous cavity help reattach retina providing internal tamponade. gas gradually absorbs dissipates time. Understanding decay rate important : Predicting patients can resume normal activities (esp. air travel) Assessing treatment efficacy Planning follow-examinations Decay kinetics: Gas decay typically follows nonlinear pattern can approximated exponential power-law functions. log transformation (LogT, LogT2) helps linearize relationships regression modeling. Data structure: longitudinal/panel dataset repeated measurements patients time. Correlation structures (exchangeable, AR(1), etc.) considered modeling. proportional nature gas variable (bounded 0 1) makes dataset ideal : Simplex marginal models (original application Song & Tan 2000) Beta regression longitudinal correlation structures Kumaraswamy regression heteroscedastic errors","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/retinal.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Intraocular Gas Decay in Retinal Surgery ‚Äî retinal","text":"Meyers, S.M., Ambler, J.S., Tan, M., Werner, J.C., Huang, S.S. (1992). Variation Perfluoropropane Disappearance Vitrectomy. Retina, 12, 359‚Äì363. Song, P.X.-K., Tan, M. (2000). Marginal Models Longitudinal Continuous Proportional Data. Biometrics, 56, 496‚Äì502. doi:10.1111/j.0006-341x.2000.00496.x Song, P.X.-K., Qiu, Z., Tan, M. (2004). Modelling Heterogeneous Dispersion Marginal Models Longitudinal Proportional Data. Biometrical Journal, 46, 540‚Äì553. Qiu, Z., Song, P.X.-K., Tan, M. (2008). Simplex Mixed-Effects Models Longitudinal Proportional Data. Scandinavian Journal Statistics, 35, 577‚Äì596. doi:10.1111/j.1467-9469.2008.00603.x Zhang, P., Qiu, Z., Shi, C. (2016). simplexreg: R Package Regression Analysis Proportional Data Using Simplex Distribution. Journal Statistical Software, 71(11), 1‚Äì21. doi:10.18637/jss.v071.i11","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/retinal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Intraocular Gas Decay in Retinal Surgery ‚Äî retinal","text":"","code":"# \\donttest{ require(gkwreg) require(gkwdist)  data(retinal)  # Example 1: Nonlinear time decay with level effects # Model gas decay as quadratic function of log-time # Allow precision to vary by initial gas concentration fit_kw <- gkwreg(   Gas ~ LogT + LogT2 + Level |     Level,   data = retinal,   family = \"kw\" ) summary(fit_kw) #>  #> Generalized Kumaraswamy Regression Model Summary #>  #> Family: kw  #>  #> Call: #> gkwreg(formula = Gas ~ LogT + LogT2 + Level | Level, data = retinal,  #>     family = \"kw\") #>  #> Residuals: #>     Min  Q1.25%  Median    Mean  Q3.75%     Max  #> -0.5665 -0.2076  0.0087 -0.0436  0.0971  0.4073  #>  #> Coefficients: #>                   Estimate Std. Error z value Pr(>|z|)     #> alpha:(Intercept)  1.69138    0.22256   7.600 2.97e-14 *** #> alpha:LogT        -0.25598    0.25054  -1.022  0.30693     #> alpha:LogT2       -0.12019    0.06061  -1.983  0.04737 *   #> alpha:Level        0.51892    0.15828   3.279  0.00104 **  #> beta:(Intercept)  -0.40918    0.09481  -4.316 1.59e-05 *** #> beta:Level         0.08475    0.13199   0.642  0.52084     #> --- #> Signif. codes:  0 ‚Äò***‚Äô 0.001 ‚Äò**‚Äô 0.01 ‚Äò*‚Äô 0.05 ‚Äò.‚Äô 0.1 ‚Äò ‚Äô 1 #>  #> Confidence intervals (95%): #>                        3%     98% #> alpha:(Intercept)  1.2552  2.1276 #> alpha:LogT        -0.7470  0.2351 #> alpha:LogT2       -0.2390 -0.0014 #> alpha:Level        0.2087  0.8291 #> beta:(Intercept)  -0.5950 -0.2233 #> beta:Level        -0.1740  0.3434 #>  #> Link functions: #> alpha: log #> beta: log #>  #> Fitted parameter means: #> alpha: 2.672 #> beta: 0.6776 #> gamma: 1 #> delta: 0 #> lambda: 1 #>  #> Model fit statistics: #> Number of observations: 181  #> Number of parameters: 6  #> Residual degrees of freedom: 175  #> Log-likelihood: 103.7  #> AIC: -195.4  #> BIC: -176.2  #> RMSE: 0.2194  #> Efron's R2: 0.4994  #> Mean Absolute Error: 0.177  #>  #> Convergence status: Successful  #> Iterations: 21  #>   # Interpretation: # - Alpha: Decay curve shape varies by initial gas concentration #   LogT + LogT2 capture nonlinear exponential-like decay # - Beta: Precision differs by concentration level #   Higher concentration may produce more/less variable decay  # Example 2: Heteroscedastic model # Variability in gas proportion may change over time fit_kw_hetero <- gkwreg(   Gas ~ LogT + LogT2 + Level |     Level + LogT,   data = retinal,   family = \"kw\" ) summary(fit_kw_hetero) #>  #> Generalized Kumaraswamy Regression Model Summary #>  #> Family: kw  #>  #> Call: #> gkwreg(formula = Gas ~ LogT + LogT2 + Level | Level + LogT, data = retinal,  #>     family = \"kw\") #>  #> Residuals: #>     Min  Q1.25%  Median    Mean  Q3.75%     Max  #> -0.5261 -0.1223  0.0192 -0.0081  0.1092  0.5323  #>  #> Coefficients: #>                   Estimate Std. Error z value Pr(>|z|)     #> alpha:(Intercept)  0.90707    0.34706   2.614  0.00896 **  #> alpha:LogT         0.40385    0.29920   1.350  0.17710     #> alpha:LogT2       -0.19493    0.05992  -3.253  0.00114 **  #> alpha:Level        0.41066    0.13956   2.943  0.00326 **  #> beta:(Intercept)  -1.25839    0.18008  -6.988 2.79e-12 *** #> beta:Level         0.10830    0.13838   0.783  0.43384     #> beta:LogT          0.51739    0.08071   6.410 1.45e-10 *** #> --- #> Signif. codes:  0 ‚Äò***‚Äô 0.001 ‚Äò**‚Äô 0.01 ‚Äò*‚Äô 0.05 ‚Äò.‚Äô 0.1 ‚Äò ‚Äô 1 #>  #> Confidence intervals (95%): #>                        3%     98% #> alpha:(Intercept)  0.2268  1.5873 #> alpha:LogT        -0.1826  0.9903 #> alpha:LogT2       -0.3124 -0.0775 #> alpha:Level        0.1371  0.6842 #> beta:(Intercept)  -1.6113 -0.9054 #> beta:Level        -0.1629  0.3795 #> beta:LogT          0.3592  0.6756 #>  #> Link functions: #> alpha: log #> beta: log #>  #> Fitted parameter means: #> alpha: 2.25 #> beta: 1.06 #> gamma: 1 #> delta: 0 #> lambda: 1 #>  #> Model fit statistics: #> Number of observations: 181  #> Number of parameters: 7  #> Residual degrees of freedom: 174  #> Log-likelihood: 125.4  #> AIC: -236.8  #> BIC: -214.4  #> RMSE: 0.2059  #> Efron's R2: 0.5592  #> Mean Absolute Error: 0.1566  #>  #> Convergence status: Successful  #> Iterations: 29  #>   # Interpretation: # - Beta: Precision varies with both level and time #   Early measurements may be more variable than late measurements  # Test heteroscedasticity anova(fit_kw, fit_kw_hetero) #> Analysis of Deviance Table #>  #> Model 1: Gas ~ LogT + LogT2 + Level | Level #> Model 2: Gas ~ LogT + LogT2 + Level | Level + LogT #>  #>               Resid. Df Resid. Dev Df Deviance Pr(>Chi)     #> fit_kw        175.00000 -207.36034                          #> fit_kw_hetero 174.00000 -250.75874  1 43.39840  < 1e-04 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1  # Example 3: Exponentiated Kumaraswamy for decay tails # Gas decay may show different tail behavior at extreme time points # (very fast initial decay or very slow residual decay) fit_ekw <- gkwreg(   Gas ~ LogT + LogT2 + Level | # alpha: decay curve     Level + LogT | # beta: heteroscedasticity     Level, # lambda: tail heaviness by level   data = retinal,   family = \"ekw\" ) summary(fit_ekw) #>  #> Generalized Kumaraswamy Regression Model Summary #>  #> Family: ekw  #>  #> Call: #> gkwreg(formula = Gas ~ LogT + LogT2 + Level | Level + LogT |  #>     Level, data = retinal, family = \"ekw\") #>  #> Residuals: #>     Min  Q1.25%  Median    Mean  Q3.75%     Max  #> -0.4958 -0.0799  0.0651  0.0446  0.1693  0.5107  #>  #> Coefficients: #>                    Estimate Std. Error z value Pr(>|z|)     #> alpha:(Intercept)   1.36711    1.11962   1.221  0.22207     #> alpha:LogT          0.27552    0.32922   0.837  0.40267     #> alpha:LogT2        -0.16545    0.05963  -2.775  0.00553 **  #> alpha:Level        -0.38899    0.39384  -0.988  0.32330     #> beta:(Intercept)   -1.36470    0.34796  -3.922 8.78e-05 *** #> beta:Level          0.25158    0.19003   1.324  0.18555     #> beta:LogT           0.54369    0.12922   4.207 2.58e-05 *** #> lambda:(Intercept) -0.32755    0.76219  -0.430  0.66738     #> lambda:Level        0.92335    0.39316   2.349  0.01885 *   #> --- #> Signif. codes:  0 ‚Äò***‚Äô 0.001 ‚Äò**‚Äô 0.01 ‚Äò*‚Äô 0.05 ‚Äò.‚Äô 0.1 ‚Äò ‚Äô 1 #>  #> Confidence intervals (95%): #>                         3%     98% #> alpha:(Intercept)  -0.8273  3.5615 #> alpha:LogT         -0.3698  0.9208 #> alpha:LogT2        -0.2823 -0.0486 #> alpha:Level        -1.1609  0.3829 #> beta:(Intercept)   -2.0467 -0.6827 #> beta:Level         -0.1209  0.6240 #> beta:LogT           0.2904  0.7970 #> lambda:(Intercept) -1.8214  1.1663 #> lambda:Level        0.1528  1.6939 #>  #> Link functions: #> alpha: log #> beta: log #> lambda: log #>  #> Fitted parameter means: #> alpha: 2.771 #> beta: 1.082 #> gamma: 1 #> delta: 0 #> lambda: 1.08 #>  #> Model fit statistics: #> Number of observations: 181  #> Number of parameters: 9  #> Residual degrees of freedom: 172  #> Log-likelihood: 129.2  #> AIC: -240.3  #> BIC: -211.5  #> RMSE: 0.209  #> Efron's R2: 0.5458  #> Mean Absolute Error: 0.1644  #>  #> Convergence status: Successful  #> Iterations: 37  #>   # Interpretation: # - Lambda varies by level: Different initial concentrations may have #   different rates of extreme decay (very fast or very slow residual gas) # - Important for predicting complete absorption time  # Example 4: McDonald distribution for asymmetric decay # Alternative parameterization for skewed decay patterns fit_mc <- gkwreg(   Gas ~ LogT + LogT2 + Level | # gamma     LogT + Level | # delta     Level, # lambda   data = retinal,   family = \"mc\",   control = gkw_control(     method = \"BFGS\",     maxit = 1500,     reltol = 1e-8   ) ) #> Warning: NaNs produced summary(fit_mc) #>  #> Generalized Kumaraswamy Regression Model Summary #>  #> Family: mc  #>  #> Call: #> gkwreg(formula = Gas ~ LogT + LogT2 + Level | LogT + Level |  #>     Level, data = retinal, family = \"mc\", control = gkw_control(method = \"BFGS\",  #>     maxit = 1500, reltol = 1e-08)) #>  #> Residuals: #>     Min  Q1.25%  Median    Mean  Q3.75%     Max  #> -0.5652 -0.1159  0.0034 -0.0098  0.1214  0.5185  #>  #> Coefficients: #>                    Estimate Std. Error z value Pr(>|z|)     #> gamma:(Intercept)   0.99232    1.85227   0.536    0.592     #> gamma:LogT          1.11127    0.23830   4.663 3.11e-06 *** #> gamma:LogT2        -0.44693    0.05657  -7.900 2.79e-15 *** #> gamma:Level         0.28447    1.38833   0.205    0.838     #> delta:(Intercept)  -6.27067    0.70158  -8.938  < 2e-16 *** #> delta:LogT          0.17905        NaN     NaN      NaN     #> delta:Level        -0.38972        NaN     NaN      NaN     #> lambda:(Intercept)  0.29057    1.83059   0.159    0.874     #> lambda:Level       -0.07583    1.42998  -0.053    0.958     #> --- #> Signif. codes:  0 ‚Äò***‚Äô 0.001 ‚Äò**‚Äô 0.01 ‚Äò*‚Äô 0.05 ‚Äò.‚Äô 0.1 ‚Äò ‚Äô 1 #>  #> Confidence intervals (95%): #>                         3%     98% #> gamma:(Intercept)  -2.6381  4.6227 #> gamma:LogT          0.6442  1.5783 #> gamma:LogT2        -0.5578 -0.3360 #> gamma:Level        -2.4366  3.0055 #> delta:(Intercept)  -7.6458 -4.8956 #> delta:LogT             NaN     NaN #> delta:Level            NaN     NaN #> lambda:(Intercept) -3.2973  3.8785 #> lambda:Level       -2.8785  2.7269 #>  #> Link functions: #> gamma: log #> delta: logit #> lambda: log #>  #> Fitted parameter means: #> alpha: 1 #> beta: 1 #> gamma: 2.848 #> delta: 0.0269 #> lambda: 1.317 #>  #> Model fit statistics: #> Number of observations: 181  #> Number of parameters: 9  #> Residual degrees of freedom: 172  #> Log-likelihood: 66.48  #> AIC: -115  #> BIC: -86.18  #> RMSE: 0.2145  #> Efron's R2: 0.5216  #> Mean Absolute Error: 0.1631  #>  #> Convergence status: Successful  #> Iterations: 26  #>   # Model comparison AIC(fit_kw, fit_kw_hetero, fit_ekw, fit_mc) #>               df       AIC #> fit_kw         6 -195.3603 #> fit_kw_hetero  7 -236.7587 #> fit_ekw        9 -240.3186 #> fit_mc         9 -114.9668 # }"},{"path":"https://evandeilton.github.io/gkwreg/reference/sdac.html","id":null,"dir":"Reference","previous_headings":"","what":"Autologous Peripheral Blood Stem Cell Transplants Data ‚Äî sdac","title":"Autologous Peripheral Blood Stem Cell Transplants Data ‚Äî sdac","text":"Data Autologous Peripheral Blood Stem Cell Transplants Stem Cell Lab Cross Cancer Institute, Alberta Health Services. dataset examines recovery rates CD34+ cells peripheral blood stem cell (PBSC) transplants.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/sdac.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Autologous Peripheral Blood Stem Cell Transplants Data ‚Äî sdac","text":"","code":"sdac"},{"path":"https://evandeilton.github.io/gkwreg/reference/sdac.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Autologous Peripheral Blood Stem Cell Transplants Data ‚Äî sdac","text":"data frame 60 observations 5 variables: rcd numeric. Recovery rate CD34+ cells (proportion (0, 1)). Response variable measuring proportion CD34+ cells recovered PBSC transplant. age numeric. Patient age years (range: 18-71 years). ageadj numeric. Age-adjusted covariate. Centered scaled version age improved numerical stability regression models. chemo factor. Type chemotherapy protocol used stem cell mobilization. Levels include: 1-day, 3-day, G-CSF , . gender factor. Patient gender. patients study male.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/sdac.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Autologous Peripheral Blood Stem Cell Transplants Data ‚Äî sdac","text":"Stem Cell Lab, Cross Cancer Institute, Alberta Health Services, Canada.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/sdac.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Autologous Peripheral Blood Stem Cell Transplants Data ‚Äî sdac","text":"dataset contains clinical data autologous peripheral blood stem cell (PBSC) transplant patients treated Cross Cancer Institute, Alberta Health Services. CD34+ cells hematopoietic stem progenitor cells critical successful transplantation hematopoietic recovery. Clinical context: Autologous PBSC transplantation used treat various hematological malignancies including multiple myeloma, non-Hodgkin's lymphoma, acute leukemia, solid tumors. recovery rate CD34+ cells crucial predictor engraftment success patient outcomes. Chemotherapy protocols: 1-day protocol: Single-day high-dose chemotherapy mobilization 3-day protocol: Multi-day chemotherapy regimen G-CSF : Granulocyte colony-stimulating factor without chemotherapy : Alternative combined protocols proportion recovered CD34+ cells naturally falls interval (0, 1), making ideal proportional data regression modeling. Age effects particularly important older patients may show different recovery patterns. dataset particularly suitable : Simplex regression (original application Zhang et al. 2016) Beta regression variable dispersion Kumaraswamy regression flexible distributional modeling","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/sdac.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Autologous Peripheral Blood Stem Cell Transplants Data ‚Äî sdac","text":"Zhang, P., Qiu, Z., Shi, C. (2016). simplexreg: R Package Regression Analysis Proportional Data Using Simplex Distribution. Journal Statistical Software, 71(11), 1‚Äì21. doi:10.18637/jss.v071.i11","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/sdac.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Autologous Peripheral Blood Stem Cell Transplants Data ‚Äî sdac","text":"","code":"# \\donttest{ require(gkwreg) require(gkwdist)  data(sdac)  # Example 1: Basic Kumaraswamy regression # Mean recovery depends on age and chemotherapy protocol # Precision varies with age (older patients more variable) fit_kw <- gkwreg(   rcd ~ ageadj + chemo |     age,   data = sdac,   family = \"kw\" ) summary(fit_kw) #>  #> Generalized Kumaraswamy Regression Model Summary #>  #> Family: kw  #>  #> Call: #> gkwreg(formula = rcd ~ ageadj + chemo | age, data = sdac, family = \"kw\") #>  #> Residuals: #>     Min  Q1.25%  Median    Mean  Q3.75%     Max  #> -0.3947 -0.0679  0.0046 -0.0053  0.0733  0.2092  #>  #> Coefficients: #>                   Estimate Std. Error z value Pr(>|z|)     #> alpha:(Intercept) 1.571402   0.134370  11.695  < 2e-16 *** #> alpha:ageadj      0.019100   0.006771   2.821  0.00479 **  #> alpha:chemo       0.207250   0.101033   2.051  0.04024 *   #> beta:(Intercept)  0.636173   0.362393   1.755  0.07918 .   #> beta:age          0.005695   0.006862   0.830  0.40656     #> --- #> Signif. codes:  0 ‚Äò***‚Äô 0.001 ‚Äò**‚Äô 0.01 ‚Äò*‚Äô 0.05 ‚Äò.‚Äô 0.1 ‚Äò ‚Äô 1 #>  #> Confidence intervals (95%): #>                        3%    98% #> alpha:(Intercept)  1.3080 1.8348 #> alpha:ageadj       0.0058 0.0324 #> alpha:chemo        0.0092 0.4053 #> beta:(Intercept)  -0.0741 1.3464 #> beta:age          -0.0078 0.0191 #>  #> Link functions: #> alpha: log #> beta: log #>  #> Fitted parameter means: #> alpha: 6.967 #> beta: 2.412 #> gamma: 1 #> delta: 0 #> lambda: 1 #>  #> Model fit statistics: #> Number of observations: 239  #> Number of parameters: 5  #> Residual degrees of freedom: 234  #> Log-likelihood: 195.7  #> AIC: -381.5  #> BIC: -364.1  #> RMSE: 0.1113  #> Efron's R2: 0.04391  #> Mean Absolute Error: 0.08571  #>  #> Convergence status: Successful  #> Iterations: 19  #>   # Interpretation: # - Alpha (mean recovery): Depends on age-adjusted covariate and chemo protocol #   Different protocols show different baseline recovery rates #   G-CSF-only may differ from multi-day chemotherapy protocols # - Beta (precision): Raw age affects recovery variability #   Hypothesis: Older patients show more heterogeneous responses  # Example 2: Include gender effects # Gender may influence stem cell recovery rates fit_kw_gender <- gkwreg(   rcd ~ ageadj + chemo + gender |     age + gender,   data = sdac,   family = \"kw\" ) summary(fit_kw_gender) #>  #> Generalized Kumaraswamy Regression Model Summary #>  #> Family: kw  #>  #> Call: #> gkwreg(formula = rcd ~ ageadj + chemo + gender | age + gender,  #>     data = sdac, family = \"kw\") #>  #> Residuals: #>     Min  Q1.25%  Median    Mean  Q3.75%     Max  #> -0.3938 -0.0616  0.0086 -0.0007  0.0773  0.2216  #>  #> Coefficients: #>                    Estimate Std. Error z value Pr(>|z|)     #> alpha:(Intercept)  1.517624   0.167580   9.056  < 2e-16 *** #> alpha:ageadj       0.019192   0.006794   2.825  0.00473 **  #> alpha:chemo        0.204847   0.100938   2.029  0.04241 *   #> alpha:genderM      0.079423   0.147338   0.539  0.58985     #> beta:(Intercept)   0.632507   0.377828   1.674  0.09412 .   #> beta:age           0.005895   0.006950   0.848  0.39629     #> beta:genderM      -0.005010   0.220384  -0.023  0.98186     #> --- #> Signif. codes:  0 ‚Äò***‚Äô 0.001 ‚Äò**‚Äô 0.01 ‚Äò*‚Äô 0.05 ‚Äò.‚Äô 0.1 ‚Äò ‚Äô 1 #>  #> Confidence intervals (95%): #>                        3%    98% #> alpha:(Intercept)  1.1892 1.8461 #> alpha:ageadj       0.0059 0.0325 #> alpha:chemo        0.0070 0.4027 #> alpha:genderM     -0.2094 0.3682 #> beta:(Intercept)  -0.1080 1.3730 #> beta:age          -0.0077 0.0195 #> beta:genderM      -0.4370 0.4269 #>  #> Link functions: #> alpha: log #> beta: log #>  #> Fitted parameter means: #> alpha: 6.989 #> beta: 2.549 #> gamma: 1 #> delta: 0 #> lambda: 1 #>  #> Model fit statistics: #> Number of observations: 239  #> Number of parameters: 7  #> Residual degrees of freedom: 232  #> Log-likelihood: 196.1  #> AIC: -378.2  #> BIC: -353.9  #> RMSE: 0.111  #> Efron's R2: 0.04818  #> Mean Absolute Error: 0.08604  #>  #> Convergence status: Successful  #> Iterations: 22  #>   # Interpretation: # - Gender effects in both mean and precision # - Precision may differ between males and females  # Test gender significance anova(fit_kw, fit_kw_gender) #> Analysis of Deviance Table #>  #> Model 1: rcd ~ ageadj + chemo | age #> Model 2: rcd ~ ageadj + chemo + gender | age + gender #>  #>               Resid. Df Resid. Dev Df Deviance Pr(>Chi)   #> fit_kw        234.00000 -391.48936                        #> fit_kw_gender 232.00000 -392.23401  2  0.74464  0.68913   #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1  # Example 3: Exponentiated Kumaraswamy for extreme recovery patterns # Some patients show unusually high or low recovery (outliers) # Lambda parameter captures tail heaviness fit_ekw <- gkwreg(   rcd ~ ageadj + chemo + gender | # alpha: mean model     age + chemo | # beta: precision varies with age and protocol     chemo, # lambda: protocol affects extremity   data = sdac,   family = \"ekw\" ) #> Warning: NaNs produced summary(fit_ekw) #>  #> Generalized Kumaraswamy Regression Model Summary #>  #> Family: ekw  #>  #> Call: #> gkwreg(formula = rcd ~ ageadj + chemo + gender | age + chemo |  #>     chemo, data = sdac, family = \"ekw\") #>  #> Residuals: #>     Min  Q1.25%  Median    Mean  Q3.75%     Max  #> -0.3924  0.0076  0.1464  0.3648  0.7999  0.9899  #>  #> Coefficients: #>                      Estimate Std. Error z value Pr(>|z|)     #> alpha:(Intercept)   1.059e+00  7.485e-01   1.414    0.157     #> alpha:ageadj        1.432e-02        NaN     NaN      NaN     #> alpha:chemo        -3.245e+01  7.154e-01 -45.358  < 2e-16 *** #> alpha:genderM       9.128e-02  6.306e-02   1.448    0.148     #> beta:(Intercept)    7.965e-01  1.814e-01   4.391 1.13e-05 *** #> beta:age           -4.334e-04        NaN     NaN      NaN     #> beta:chemo         -2.306e-01  1.812e-01  -1.272    0.203     #> lambda:(Intercept)  6.693e-01  9.808e-01   0.682    0.495     #> lambda:chemo        5.661e+01  9.354e-01  60.525  < 2e-16 *** #> --- #> Signif. codes:  0 ‚Äò***‚Äô 0.001 ‚Äò**‚Äô 0.01 ‚Äò*‚Äô 0.05 ‚Äò.‚Äô 0.1 ‚Äò ‚Äô 1 #>  #> Confidence intervals (95%): #>                          3%      98% #> alpha:(Intercept)   -0.4083   2.5257 #> alpha:ageadj            NaN      NaN #> alpha:chemo        -33.8498 -31.0456 #> alpha:genderM       -0.0323   0.2149 #> beta:(Intercept)     0.4410   1.1519 #> beta:age                NaN      NaN #> beta:chemo          -0.5858   0.1247 #> lambda:(Intercept)  -1.2531   2.5918 #> lambda:chemo        54.7807  58.4473 #>  #> Link functions: #> alpha: log #> beta: log #> lambda: log #>  #> Fitted parameter means: #> alpha: 2.185 #> beta: 1.964 #> gamma: 1 #> delta: 0 #> lambda: 3.439e+24 #>  #> Model fit statistics: #> Number of observations: 239  #> Number of parameters: 9  #> Residual degrees of freedom: 230  #> Log-likelihood: 423.6  #> AIC: -829.1  #> BIC: -797.8  #> RMSE: 0.5497  #> Efron's R2: -22.33  #> Mean Absolute Error: 0.4138  #>  #> Convergence status: Failed  #> Iterations: 65  #>   # Clinical interpretation: # - Lambda varies by chemotherapy protocol: Some protocols produce more #   extreme recovery patterns (very high or very low CD34+ counts) # - G-CSF-only vs multi-day protocols may differ in tail behavior # - Important for risk stratification and clinical decision-making  # Test if extreme patterns differ by protocol anova(fit_kw_gender, fit_ekw) #> Analysis of Deviance Table #>  #> Model 1: rcd ~ ageadj + chemo + gender | age + gender #> Model 2: rcd ~ ageadj + chemo + gender | age + chemo | chemo #>  #>               Resid. Df Resid. Dev Df  Deviance Pr(>Chi)     #> fit_kw_gender 232.00000 -392.23401                           #> fit_ekw       230.00000 -847.12446  2 454.89045  < 1e-04 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1  # Example 4: Interaction between age and protocol # Protocol effectiveness may vary with patient age fit_kw_interact <- gkwreg(   rcd ~ ageadj * chemo |     age * chemo,   data = sdac,   family = \"kw\" ) summary(fit_kw_interact) #>  #> Generalized Kumaraswamy Regression Model Summary #>  #> Family: kw  #>  #> Call: #> gkwreg(formula = rcd ~ ageadj * chemo | age * chemo, data = sdac,  #>     family = \"kw\") #>  #> Residuals: #>     Min  Q1.25%  Median    Mean  Q3.75%     Max  #> -0.3898 -0.0624  0.0073 -0.0021  0.0729  0.2113  #>  #> Coefficients: #>                     Estimate Std. Error z value Pr(>|z|)     #> alpha:(Intercept)   1.659107   0.220086   7.538 4.76e-14 *** #> alpha:ageadj        0.013918   0.011255   1.237    0.216     #> alpha:chemo         0.138996   0.256543   0.542    0.588     #> alpha:ageadj:chemo  0.004748   0.015016   0.316    0.752     #> beta:(Intercept)    1.686154   1.036463   1.627    0.104     #> beta:age           -0.012553   0.017666  -0.711    0.477     #> beta:chemo         -1.234435   1.122370  -1.100    0.271     #> beta:age:chemo      0.023055   0.020005   1.152    0.249     #> --- #> Signif. codes:  0 ‚Äò***‚Äô 0.001 ‚Äò**‚Äô 0.01 ‚Äò*‚Äô 0.05 ‚Äò.‚Äô 0.1 ‚Äò ‚Äô 1 #>  #> Confidence intervals (95%): #>                         3%    98% #> alpha:(Intercept)   1.2277 2.0905 #> alpha:ageadj       -0.0081 0.0360 #> alpha:chemo        -0.3638 0.6418 #> alpha:ageadj:chemo -0.0247 0.0342 #> beta:(Intercept)   -0.3453 3.7176 #> beta:age           -0.0472 0.0221 #> beta:chemo         -3.4342 0.9654 #> beta:age:chemo     -0.0162 0.0623 #>  #> Link functions: #> alpha: log #> beta: log #>  #> Fitted parameter means: #> alpha: 6.971 #> beta: 2.524 #> gamma: 1 #> delta: 0 #> lambda: 1 #>  #> Model fit statistics: #> Number of observations: 239  #> Number of parameters: 8  #> Residual degrees of freedom: 231  #> Log-likelihood: 196.7  #> AIC: -377.4  #> BIC: -349.6  #> RMSE: 0.111  #> Efron's R2: 0.04886  #> Mean Absolute Error: 0.08551  #>  #> Convergence status: Successful  #> Iterations: 46  #>   # Interpretation: # - Interaction: Does protocol effectiveness decline with age? # - Critical for personalized treatment selection # }"},{"path":"https://evandeilton.github.io/gkwreg/reference/summary.gkwreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary Method for Generalized Kumaraswamy Regression Models ‚Äî summary.gkwreg","title":"Summary Method for Generalized Kumaraswamy Regression Models ‚Äî summary.gkwreg","text":"Computes returns detailed statistical summary fitted Generalized Kumaraswamy (GKw) regression model object class \"gkwreg\".","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/summary.gkwreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary Method for Generalized Kumaraswamy Regression Models ‚Äî summary.gkwreg","text":"","code":"# S3 method for class 'gkwreg' summary(object, conf.level = 0.95, ...)"},{"path":"https://evandeilton.github.io/gkwreg/reference/summary.gkwreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary Method for Generalized Kumaraswamy Regression Models ‚Äî summary.gkwreg","text":"object object class \"gkwreg\", typically result call gkwreg. conf.level Numeric. desired confidence level constructing confidence intervals regression coefficients. Default 0.95. ... Additional arguments, currently ignored method.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/summary.gkwreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary Method for Generalized Kumaraswamy Regression Models ‚Äî summary.gkwreg","text":"object class \"summary.gkwreg\", list containing following components: call original function call created object. family Character string specifying distribution family. coefficients data frame (matrix) containing coefficient estimates, standard errors, z-values, p-values. conf.int matrix containing lower upper bounds confidence intervals coefficients (standard errors available). link list character strings specifying link functions used. fitted_parameters list containing mean values estimated distribution parameters. residuals named numeric vector containing summary statistics response residuals. nobs Number observations used fit. npar Total number estimated regression coefficients. df.residual Residual degrees freedom. loglik maximized log-likelihood value. aic Akaike Information Criterion. bic Bayesian Information Criterion. rmse Root Mean Squared Error residuals. efron_r2 Efron's pseudo-R-squared value. mean_absolute_error Mean Absolute Error residuals. convergence Convergence code optimizer. iterations Number iterations reported optimizer. conf.level confidence level used calculating intervals.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/summary.gkwreg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summary Method for Generalized Kumaraswamy Regression Models ‚Äî summary.gkwreg","text":"method provides comprehensive summary fitted gkwreg model. calculates z-values p-values regression coefficients based estimated standard errors (available) computes confidence intervals specified conf.level. summary includes: model call. distribution family used. table coefficients including estimates, standard errors, z-values, p-values. Note: Significance stars typically added corresponding print.summary.gkwreg method. Confidence intervals coefficients. Link functions used parameter. Mean values fitted distribution parameters (\\(\\alpha, \\beta, \\gamma, \\delta, \\lambda\\)). five-number summary (Min, Q1, Median, Q3, Max) plus mean response residuals. Key model fit statistics (Log-likelihood, AIC, BIC, RMSE, Efron's R^2). Information model convergence optimizer iterations. standard errors computed (e.g., hessian = FALSE original gkwreg call), coefficient table contain estimates, confidence intervals available.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwreg/reference/summary.gkwreg.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Summary Method for Generalized Kumaraswamy Regression Models ‚Äî summary.gkwreg","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/summary.gkwreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary Method for Generalized Kumaraswamy Regression Models ‚Äî summary.gkwreg","text":"","code":"# \\donttest{ set.seed(123) n <- 100 x1 <- runif(n, -2, 2) x2 <- rnorm(n) alpha_coef <- c(0.8, 0.3, -0.2) beta_coef <- c(1.2, -0.4, 0.1) eta_alpha <- alpha_coef[1] + alpha_coef[2] * x1 + alpha_coef[3] * x2 eta_beta <- beta_coef[1] + beta_coef[2] * x1 + beta_coef[3] * x2 alpha_true <- exp(eta_alpha) beta_true <- exp(eta_beta) # Use stats::rbeta as a placeholder if rkw is unavailable y <- stats::rbeta(n, shape1 = alpha_true, shape2 = beta_true) y <- pmax(pmin(y, 1 - 1e-7), 1e-7) df <- data.frame(y = y, x1 = x1, x2 = x2)  # Fit a Kumaraswamy regression model kw_reg <- gkwreg(y ~ x1 + x2 | x1 + x2, data = df, family = \"kw\")  # Generate detailed summary using the summary method summary_kw <- summary(kw_reg)  # Print the summary object (uses print.summary.gkwreg) print(summary_kw) #>  #> Generalized Kumaraswamy Regression Model Summary #>  #> Family: kw  #>  #> Call: #> gkwreg(formula = y ~ x1 + x2 | x1 + x2, data = df, family = \"kw\") #>  #> Residuals: #>     Min  Q1.25%  Median    Mean  Q3.75%     Max  #> -0.4910 -0.0942  0.0028  0.0042  0.1329  0.5094  #>  #> Coefficients: #>                   Estimate Std. Error z value Pr(>|z|)     #> alpha:(Intercept)  0.73589    0.10135   7.261 3.85e-13 *** #> alpha:x1           0.25878    0.08860   2.921  0.00349 **  #> alpha:x2          -0.12441    0.08825  -1.410  0.15863     #> beta:(Intercept)   1.45325    0.17992   8.077 6.64e-16 *** #> beta:x1           -0.52161    0.17460  -2.987  0.00281 **  #> beta:x2            0.03766    0.18694   0.201  0.84034     #> --- #> Signif. codes:  0 ‚Äò***‚Äô 0.001 ‚Äò**‚Äô 0.01 ‚Äò*‚Äô 0.05 ‚Äò.‚Äô 0.1 ‚Äò ‚Äô 1 #>  #> Confidence intervals (95%): #>                        3%     98% #> alpha:(Intercept)  0.5372  0.9345 #> alpha:x1           0.0851  0.4324 #> alpha:x2          -0.2974  0.0486 #> beta:(Intercept)   1.1006  1.8059 #> beta:x1           -0.8638 -0.1794 #> beta:x2           -0.3287  0.4041 #>  #> Link functions: #> alpha: log #> beta: log #>  #> Fitted parameter means: #> alpha: 2.207 #> beta: 5.072 #> gamma: 1 #> delta: 0 #> lambda: 1 #>  #> Model fit statistics: #> Number of observations: 100  #> Number of parameters: 6  #> Residual degrees of freedom: 94  #> Log-likelihood: 46.13  #> AIC: -80.27  #> BIC: -64.63  #> RMSE: 0.1728  #> Efron's R2: 0.5496  #> Mean Absolute Error: 0.1365  #>  #> Convergence status: Successful  #> Iterations: 27  #>   # Extract coefficient table directly from the summary object coef_table <- coef(summary_kw) # Equivalent to summary_kw$coefficients print(coef_table) #>                      Estimate Std. Error    z value     Pr(>|z|) #> alpha:(Intercept)  0.73589120 0.10135318  7.2606619 3.852007e-13 #> alpha:x1           0.25877630 0.08860253  2.9206422 3.493107e-03 #> alpha:x2          -0.12440703 0.08825176 -1.4096833 1.586332e-01 #> beta:(Intercept)   1.45324717 0.17992343  8.0770311 6.636262e-16 #> beta:x1           -0.52161306 0.17460352 -2.9874143 2.813482e-03 #> beta:x2            0.03766118 0.18693698  0.2014646 8.403353e-01 # }"},{"path":"https://evandeilton.github.io/gkwreg/reference/terms.gkwreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Terms from GKw Regression Model ‚Äî terms.gkwreg","title":"Extract Terms from GKw Regression Model ‚Äî terms.gkwreg","text":"Extracts terms object fitted Generalized Kumaraswamy regression model.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/terms.gkwreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Terms from GKw Regression Model ‚Äî terms.gkwreg","text":"","code":"# S3 method for class 'gkwreg' terms(x, ...)"},{"path":"https://evandeilton.github.io/gkwreg/reference/terms.gkwreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Terms from GKw Regression Model ‚Äî terms.gkwreg","text":"x object class \"gkwreg\". ... Currently used.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/terms.gkwreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Terms from GKw Regression Model ‚Äî terms.gkwreg","text":"terms object.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwreg/reference/terms.gkwreg.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract Terms from GKw Regression Model ‚Äî terms.gkwreg","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/terms.gkwreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Terms from GKw Regression Model ‚Äî terms.gkwreg","text":"","code":"# \\donttest{ data(GasolineYield) fit <- gkwreg(yield ~ batch + temp, data = GasolineYield, family = \"kw\") #> Warning: NaNs produced terms(fit) #> yield ~ batch + temp #> attr(,\"variables\") #> list(yield, batch, temp) #> attr(,\"factors\") #>       batch temp #> yield     0    0 #> batch     1    0 #> temp      0    1 #> attr(,\"term.labels\") #> [1] \"batch\" \"temp\"  #> attr(,\"order\") #> [1] 1 1 #> attr(,\"intercept\") #> [1] 1 #> attr(,\"response\") #> [1] 1 #> attr(,\".Environment\") #> <environment: 0x56407639cf18> #> attr(,\"predvars\") #> list(yield, batch, temp) #> attr(,\"dataClasses\") #>     yield     batch      temp  #> \"numeric\"  \"factor\" \"numeric\"  # }"},{"path":"https://evandeilton.github.io/gkwreg/reference/update.gkwreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Update and Re-fit a GKw Regression Model ‚Äî update.gkwreg","title":"Update and Re-fit a GKw Regression Model ‚Äî update.gkwreg","text":"Updates (default) re-fits Generalized Kumaraswamy regression model. method allows modification model formula, data, arguments without completely re-specify model call. Supports formulas 5 parts (alpha, beta, gamma, delta, lambda) using Formula package.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/update.gkwreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update and Re-fit a GKw Regression Model ‚Äî update.gkwreg","text":"","code":"# S3 method for class 'gkwreg' update(object, formula., ..., data. = NULL, evaluate = TRUE)"},{"path":"https://evandeilton.github.io/gkwreg/reference/update.gkwreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update and Re-fit a GKw Regression Model ‚Äî update.gkwreg","text":"object object class \"gkwreg\", typically obtained gkwreg. formula. Changes formula. formula . refers corresponding part old formula. multi-part formulas (e.g., y ~ x1 | x2 | x3), can update part separately using | separator. ... Additional arguments call, arguments changed values. Use name = NULL remove argument. data. Optional. new data frame evaluate updated model. omitted, original data used. evaluate Logical. TRUE (default), updated model fitted. FALSE, updated call returned without fitting.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/update.gkwreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Update and Re-fit a GKw Regression Model ‚Äî update.gkwreg","text":"evaluate = TRUE, new fitted model object class \"gkwreg\". evaluate = FALSE, updated call.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/update.gkwreg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Update and Re-fit a GKw Regression Model ‚Äî update.gkwreg","text":"update method allows modify fitted model re-fit changes. GKw regression model supports formulas 5 parts: y ~ model_alpha | model_beta | model_gamma | model_delta | model_lambda part can updated independently using . refer current specification: . ~ . + x | . | . | . | . - Add x alpha . ~ . | . + x | . | . | . - Add x beta . ~ . | . | . + x | . | . - Add x gamma . ~ . + x | . + x | . | . | . - Add x alpha beta . ~ . - x | . | . | . | . - Remove x alpha Omitting parts end allowed (default .): . ~ . + x | . equivalent . ~ . + x | . | . | . | . . ~ . | . + x equivalent . ~ . | . + x | . | . | .","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwreg/reference/update.gkwreg.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Update and Re-fit a GKw Regression Model ‚Äî update.gkwreg","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/update.gkwreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Update and Re-fit a GKw Regression Model ‚Äî update.gkwreg","text":"","code":"# \\donttest{ # Load example data require(gkwreg)  data(GasolineYield)  # EXAMPLE 1: Simple formulas (1 part - alpha only)  m1_0 <- gkwreg(yield ~ 1, data = GasolineYield, family = \"kw\") m1_1 <- update(m1_0, . ~ . + temp) m1_2 <- update(m1_1, . ~ . + batch) #> Warning: NaNs produced m1_3 <- update(m1_2, . ~ . - temp)  anova(m1_0, m1_1, m1_2) #> Analysis of Deviance Table #>  #> Model 1: yield ~ 1 #> Model 2: yield ~ temp #> Model 3: yield ~ temp + batch #>  #>      Resid. Df Resid. Dev Df  Deviance Pr(>Chi)     #> m1_0  30.00000  -57.02258                           #> m1_1  29.00000  -80.90259  1  23.88001  < 1e-04 *** #> m1_2  20.00000 -193.93742  9 113.03483  < 1e-04 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 AIC(m1_0, m1_1, m1_2, m1_3) #>      df        AIC #> m1_0  2  -53.02258 #> m1_1  3  -74.90259 #> m1_2 12 -169.93742 #> m1_3 11  -42.93436 BIC(m1_0, m1_1, m1_2, m1_3) #>      df        BIC #> m1_0  2  -50.09111 #> m1_1  3  -70.50538 #> m1_2 12 -152.34859 #> m1_3 11  -26.81126  # EXAMPLE 2: Two-part formulas (alpha | beta)  # Start with intercept-only for both m2_0 <- gkwreg(yield ~ 1 | 1, data = GasolineYield, family = \"kw\")  # Add temp to alpha m2_1 <- update(m2_0, . ~ . + temp | .)  # Add batch to beta m2_2 <- update(m2_1, . ~ . | . + batch) #> Warning: NaNs produced  # Add batch to alpha too m2_3 <- update(m2_2, . ~ . + batch | .)  anova(m2_0, m2_1, m2_2, m2_3) #> Analysis of Deviance Table #>  #> Model 1: yield ~ 1 | 1 #> Model 2: yield ~ temp #> Model 3: yield ~ temp | batch #> Model 4: yield ~ temp + batch | batch #>  #>      Resid. Df Resid. Dev Df  Deviance   Pr(>Chi)     #> m2_0  30.00000  -57.02258                             #> m2_1  29.00000  -80.90259  1  23.88001    < 1e-04 *** #> m2_2  20.00000 -183.27483  9 102.37224    < 1e-04 *** #> m2_3  11.00000 -215.08643  9  31.81161 0.00021462 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 AIC(m2_0, m2_1, m2_2, m2_3) #>      df        AIC #> m2_0  2  -53.02258 #> m2_1  3  -74.90259 #> m2_2 12 -159.27483 #> m2_3 21 -173.08643  # EXAMPLE 3: Three-part formulas (alpha | beta | gamma)  m3_0 <- gkwreg(yield ~ 1,                data = GasolineYield,                family = \"gkw\",                control = gkw_control(method = \"BFGS\", maxit = 2000)) #> Warning: NaNs produced  m3_1 <- update(m3_0, . ~ . + temp | . | .) #> Warning: NaNs produced m3_2 <- update(m3_1, . ~ . | . + batch | .) #> Warning: NaNs produced m3_3 <- update(m3_2, . ~ . | . | . + temp) #> Warning: NaNs produced  anova(m3_0, m3_1, m3_2, m3_3) #> Warning: negative deviance change detected; models may not be nested #> Warning: negative deviance change detected; models may not be nested #> Analysis of Deviance Table #>  #> Model 1: yield ~ 1 #> Model 2: yield ~ temp #> Model 3: yield ~ temp | batch #> Model 4: yield ~ temp | batch | temp #>  #>      Resid. Df Resid. Dev Df Deviance Pr(>Chi)   #> m3_0  27.00000  -48.98863                        #> m3_1  26.00000  -52.38707  1  3.39844 0.065258 . #> m3_2  17.00000  -52.38706  9  0.00000            #> m3_3  16.00000  -43.00466  1 -9.38240            #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1  # EXAMPLE 4: Practical nested model comparison  # Null model fit0 <- gkwreg(yield ~ 1,                data = GasolineYield,                family = \"kw\",                control = gkw_control(method = \"BFGS\", maxit = 2000) )  # Add main effects to alpha fit1 <- update(fit0, . ~ . + temp) fit2 <- update(fit1, . ~ . + batch)  # Model beta parameter fit3 <- update(fit2, . ~ . | temp) fit4 <- update(fit3, . ~ . | . + batch)  # Full comparison anova(fit0, fit1, fit2, fit3, fit4) #> Warning: negative deviance change detected; models may not be nested #> Analysis of Deviance Table #>  #> Model 1: yield ~ 1 #> Model 2: yield ~ temp #> Model 3: yield ~ temp + batch #> Model 4: yield ~ temp + batch | temp #> Model 5: yield ~ temp + batch | temp + batch #>  #>      Resid. Df Resid. Dev Df Deviance  Pr(>Chi)    #> fit0  30.00000  -16.60035                          #> fit1  29.00000   -8.36052  1 -8.23983              #> fit2  20.00000   -8.36052  9    1e-05         1    #> fit3  19.00000  -18.17449  1  9.81397 0.0017319 ** #> fit4  10.00000  -18.17450  9    1e-05         1    #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 AIC(fit0, fit1, fit2, fit3, fit4) #>      df        AIC #> fit0  2 -12.600346 #> fit1  3  -2.360515 #> fit2 12  15.639476 #> fit3 13   7.825509 #> fit4 22  25.825501 BIC(fit0, fit1, fit2, fit3, fit4) #>      df       BIC #> fit0  2 -9.668874 #> fit1  3  2.036692 #> fit2 12 33.228307 #> fit3 13 26.880076 #> fit4 22 58.071691  # EXAMPLE 5: Changing other parameters  # Change family fit_gkw <- update(fit2, family = \"gkw\") #> Warning: NaNs produced  # Change link function fit_logit <- update(fit2, link = list(alpha = \"logit\"))  # View call without fitting update(fit2, . ~ . | . + temp, evaluate = FALSE) #> gkwreg(formula = yield ~ temp + batch | temp, data = GasolineYield,  #>     family = \"kw\", control = gkw_control(method = \"BFGS\", maxit = 2000)) # }"},{"path":"https://evandeilton.github.io/gkwreg/reference/vcov.gkwreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Variance-Covariance Matrix from a Generalized Kumaraswamy Regression Model ‚Äî vcov.gkwreg","title":"Extract Variance-Covariance Matrix from a Generalized Kumaraswamy Regression Model ‚Äî vcov.gkwreg","text":"function extracts variance-covariance matrix estimated parameters fitted Generalized Kumaraswamy regression model. variance-covariance matrix essential statistical inference, including hypothesis testing confidence interval calculation.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/vcov.gkwreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Variance-Covariance Matrix from a Generalized Kumaraswamy Regression Model ‚Äî vcov.gkwreg","text":"","code":"# S3 method for class 'gkwreg' vcov(object, complete = TRUE, ...)"},{"path":"https://evandeilton.github.io/gkwreg/reference/vcov.gkwreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Variance-Covariance Matrix from a Generalized Kumaraswamy Regression Model ‚Äî vcov.gkwreg","text":"object object class \"gkwreg\", typically result call gkwreg. complete Logical indicating whether complete variance-covariance matrix returned case coefficients omitted original fit. Currently ignored gkwreg objects. ... Additional arguments (currently used).","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/vcov.gkwreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Variance-Covariance Matrix from a Generalized Kumaraswamy Regression Model ‚Äî vcov.gkwreg","text":"square matrix row column names corresponding coefficients model. variance-covariance matrix available (example, model fitted hessian = FALSE), function returns NULL warning.","code":""},{"path":"https://evandeilton.github.io/gkwreg/reference/vcov.gkwreg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract Variance-Covariance Matrix from a Generalized Kumaraswamy Regression Model ‚Äî vcov.gkwreg","text":"variance-covariance matrix estimated based observed information matrix, derived second derivatives log-likelihood function respect model parameters. gkwreg objects, matrix typically computed using TMB (Template Model Builder) automatic differentiation framework model fitting. diagonal elements variance-covariance matrix correspond squared standard errors parameter estimates, -diagonal elements represent covariances pairs parameters.","code":""},{"path":[]},{"path":[]},{"path":[]},{"path":"https://evandeilton.github.io/gkwreg/news/index.html","id":"comparative-testing-2-1-0","dir":"Changelog","previous_headings":"","what":"Comparative Testing","title":"gkwreg 2.1.0","text":"Introduced dedicated comparative test suite validate gkwreg‚Äôs beta family implementation reference betareg package, ensuring numerical accuracy reliability. Confirmed statistical equivalence despite different internal parameterizations. Tests demonstrate gkwreg‚Äôs shape-based (gamma, delta+1) approach produces equivalent statistical models betareg‚Äôs mean-precision (mu, phi) approach. Validated key outputs, showing log-likelihood, AIC/BIC, fitted values, predictions virtually identical two packages fitting beta regression model. Successfully benchmarked gkwreg family = \"beta\" robust reliable alternative beta regression, yielding inferential conclusions established betareg package. Verified consistency across multiple scenarios, including controlled simulations known parameters real-world datasets (GasolineYield, FoodExpenditure), ensuring robust performance diverse modeling contexts.","code":""},{"path":[]},{"path":[]},{"path":"https://evandeilton.github.io/gkwreg/news/index.html","id":"package-restructuring-2-0-0","dir":"Changelog","previous_headings":"Major Changes","what":"Package Restructuring","title":"gkwreg 2.0.0","text":"Complete package reformulation following JOSS reviewer feedback reduce complexity improve maintainability. Distribution functions moved separate package gkwdist: d*, p*, q*, r* density/CDF/quantile/random generation functions extracted companion package gkwdist cleaner namespace reduced dependencies. gkwreg package now focuses exclusively regression modeling. Univariate fitting functions removed: gkwfit(), gkwgof(), gkwfitall() removed maintain package focus regression. Users needing univariate distribution fitting use gkwdist package directly standard MLE approaches.","code":""},{"path":"https://evandeilton.github.io/gkwreg/news/index.html","id":"simplified-interface-2-0-0","dir":"Changelog","previous_headings":"Major Changes","what":"Simplified Interface","title":"gkwreg 2.0.0","text":"Introduced gkw_control(): technical/optimization parameters (method, start, fixed, hessian, maxit, tolerances, etc.) now consolidated dedicated control function following glm.control() design pattern. dramatically simplifies main gkwreg() interface. Removed arguments violating separation concerns gkwreg(): plot argument removed (use plot() method instead) conf.level argument removed (use confint() method instead) profile, submodels, npoints arguments removed (focused functionality) Streamlined gkwreg() signature: Reduced 15+ arguments ~12 core arguments, technical options delegated control.","code":""},{"path":"https://evandeilton.github.io/gkwreg/news/index.html","id":"complete-s3-method-implementation-2-0-0","dir":"Changelog","previous_headings":"Major Changes","what":"Complete S3 Method Implementation","title":"gkwreg 2.0.0","text":"print.gkwreg(), summary.gkwreg(), print.summary.gkwreg() coef.gkwreg(), vcov.gkwreg(), fitted.gkwreg() logLik.gkwreg(), AIC.gkwreg(), BIC.gkwreg(), nobs.gkwreg() confint.gkwreg(), residuals.gkwreg(), predict.gkwreg() anova.gkwreg(), print.anova.gkwreg(), lrtest()","code":""},{"path":"https://evandeilton.github.io/gkwreg/news/index.html","id":"enhanced-diagnostics-2-0-0","dir":"Changelog","previous_headings":"Major Changes","what":"Enhanced Diagnostics","title":"gkwreg 2.0.0","text":"Comprehensive plot.gkwreg() method 6 diagnostic plot types: Residuals vs Observation Indices Cook‚Äôs Distance Generalized Leverage vs Fitted Values Residuals vs Linear Predictor Half-Normal Plot Simulated Envelope Predicted vs Observed Values Dual graphics system support: Base R graphics (default) ggplot2 automatic grid arrangement via gridExtra/ggpubr. Advanced customization: Named-list interface plot captions (partial customization without repeating titles), theme control, sampling large datasets.","code":""},{"path":"https://evandeilton.github.io/gkwreg/news/index.html","id":"powerful-prediction-2-0-0","dir":"Changelog","previous_headings":"Major Changes","what":"Powerful Prediction","title":"gkwreg 2.0.0","text":"\"response\", \"variance\", \"link\", \"parameter\" Individual parameters: \"alpha\", \"beta\", \"gamma\", \"delta\", \"lambda\" Distribution functions: \"density\", \"probability\", \"quantile\" Element-wise vectorized modes: Flexible evaluation via elementwise argument CDF/PDF/quantile calculations.","code":""},{"path":"https://evandeilton.github.io/gkwreg/news/index.html","id":"model-comparison-tools-2-0-0","dir":"Changelog","previous_headings":"Major Changes","what":"Model Comparison Tools","title":"gkwreg 2.0.0","text":"Likelihood ratio tests: anova.gkwreg() comparing nested models automatic ordering chi-squared tests; dedicated lrtest() function pairwise comparisons. Information criteria: AIC.gkwreg() BIC.gkwreg() multi-model comparison support returning data frames.","code":""},{"path":"https://evandeilton.github.io/gkwreg/news/index.html","id":"documentation-improvements-2-0-0","dir":"Changelog","previous_headings":"Major Changes","what":"Documentation Improvements","title":"gkwreg 2.0.0","text":"Extensive Roxygen documentation exported functions detailed examples, mathematical formulas, usage guidance. Updated README.md comprehensive feature overview, quick start guide, advanced examples, ecosystem comparison table. NULL default intelligent behavior: Several arguments default NULL triggering smart auto-configuration (e.g., sub.caption, ask, theme_fn plot.gkwreg()).","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwreg/news/index.html","id":"comprehensive-test-suite-added-2-0-0","dir":"Changelog","previous_headings":"Testing Framework","what":"Comprehensive Test Suite Added","title":"gkwreg 2.0.0","text":"package now includes robust testing framework 1000+ unit tests covering major functionalities:","code":""},{"path":"https://evandeilton.github.io/gkwreg/news/index.html","id":"core-function-testing-2-0-0","dir":"Changelog","previous_headings":"Testing Framework > Comprehensive Test Suite Added","what":"Core Function Testing","title":"gkwreg 2.0.0","text":"gkwreg(): 20 tests model fitting, parameter estimation, formula handling, distribution families, link functions, convergence predict.gkwreg(): 10 tests predictions, including response means, densities, CDFs, quantiles, parameter extraction residuals.gkwreg(): 10 tests residual types (response, Pearson, deviance, quantile, standardized, working, partial) fitted.gkwreg(): 10 tests fitted value extraction validation","code":""},{"path":"https://evandeilton.github.io/gkwreg/news/index.html","id":"s3-methods-testing-2-0-0","dir":"Changelog","previous_headings":"Testing Framework > Comprehensive Test Suite Added","what":"S3 Methods Testing","title":"gkwreg 2.0.0","text":"anova.gkwreg(): 45 tests model comparisons, likelihood ratio tests, nested model hierarchies Print methods: Tests print.gkwreg() print.summary.gkwreg() Accessor methods: Tests coef(), vcov(), nobs(), confint() Summary method: Tests summary.gkwreg() including coefficient tables, confidence intervals, fit statistics","code":""},{"path":"https://evandeilton.github.io/gkwreg/news/index.html","id":"test-coverage-includes-2-0-0","dir":"Changelog","previous_headings":"Testing Framework > Comprehensive Test Suite Added","what":"Test Coverage Includes","title":"gkwreg 2.0.0","text":"ll 7 distribution families (GKw, BKw, KKw, EKw, MC, Kw, Beta) Different link functions scales Edge cases boundary conditions Missing data handling (NA) Subset weight specifications Large dataset performance Error handling input validation Statistical correctness verification Numerical accuracy checks","code":""},{"path":"https://evandeilton.github.io/gkwreg/news/index.html","id":"testing-framework-2-0-0-1","dir":"Changelog","previous_headings":"Testing Framework > Comprehensive Test Suite Added","what":"Testing Framework","title":"gkwreg 2.0.0","text":"Built testthat package Uses simulated data gkwdist package Tests real datasets (GasolineYield, FoodExpenditure) Reproducible fixed random seeds","code":""},{"path":"https://evandeilton.github.io/gkwreg/news/index.html","id":"minor-improvements-2-0-0","dir":"Changelog","previous_headings":"","what":"Minor Improvements","title":"gkwreg 2.0.0","text":"Link scaling support: Added link_scale argument gkwreg() controlling transformation intensity. Performance optimizations: Intelligent caching, sampling support diagnostics large datasets, optional Hessian computation. Breaking Changes: Version 2.0.0 introduces breaking changes. Code using gkwfit(), gkwgof(), gkwfitall(), distribution functions (dgkw(), etc.) must updated use gkwdist package new gkwreg() interface gkw_control().","code":""}]
