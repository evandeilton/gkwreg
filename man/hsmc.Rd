% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/RcppExports.R
\name{hsmc}
\alias{hsmc}
\title{Hessian Matrix Function for Beta Power (McDonald) Log-Likelihood}
\usage{
hsmc(par, data)
}
\arguments{
\item{par}{NumericVector of length 3 containing parameters (γ, δ, λ) in that order.
All parameters must be positive.}

\item{data}{NumericVector of observations, where all values must be in the open interval (0,1).}
}
\value{
NumericMatrix of dimensions 3x3 containing the Hessian components (second derivatives)
of the negative log-likelihood with respect to each parameter pair (γ, δ, λ).
Returns a matrix of NaN values if any parameters or data values are invalid.
}
\description{
Calculates the Hessian matrix (second-order partial derivatives) of the negative log-likelihood
function for the Beta Power (BP) distribution, also known as McDonald distribution.
This function provides the exact Hessian needed for efficient optimization in maximum likelihood
estimation and for asymptotic inference. The BP is a submodel of GKw with α = 1 and β = 1 fixed.
}
\details{
The Hessian matrix contains the following second derivatives of the negative log-likelihood:

\deqn{
\frac{\partial^2 \ell}{\partial \gamma^2} = -n[\psi'(\gamma+\delta+1) - \psi'(\gamma)]
}

\deqn{
\frac{\partial^2 \ell}{\partial \gamma \partial \delta} = -n\psi'(\gamma+\delta+1)
}

\deqn{
\frac{\partial^2 \ell}{\partial \gamma \partial \lambda} = -\sum_{i=1}^{n}\log(x_i)
}

\deqn{
\frac{\partial^2 \ell}{\partial \delta^2} = -n[\psi'(\gamma+\delta+1) - \psi'(\delta+1)]
}

\deqn{
\frac{\partial^2 \ell}{\partial \delta \partial \lambda} = \sum_{i=1}^{n}\frac{x_i^{\lambda}\log(x_i)}{1-x_i^{\lambda}}
}

\deqn{
\frac{\partial^2 \ell}{\partial \lambda^2} = \frac{n}{\lambda^2} + \gamma^2\sum_{i=1}^{n}[\log(x_i)]^2 +
\delta\sum_{i=1}^{n}\frac{x_i^{\lambda}[\log(x_i)]^2}{1-x_i^{\lambda}}\left(1 + \frac{x_i^{\lambda}}{1-x_i^{\lambda}}\right)
}

where:
\itemize{
\item \deqn{\psi'} is the trigamma function (second derivative of the log-gamma function)
}

The implementation includes several numerical safeguards:
\itemize{
\item Parameter and data validation with appropriate error handling
\item Clamping of intermediate values to avoid numerical underflow/overflow
\item Symmetry of the Hessian matrix is guaranteed by construction
\item Efficient vector operations using Armadillo C++ library
}

The returned Hessian is negated to align with minimization of negative log-likelihood
in optimization routines.
}
\examples{
\dontrun{
# Generate sample data from a BP distribution
set.seed(123)
x <- rmc(100, 2, 3, 0.5)
hist(x, breaks = 20, main = "BP(2, 3, 0.5) Sample")

# Use in optimization with Hessian-based methods
result <- optim(c(0.5, 0.5, 0.5), llmc, method = "BFGS",
                hessian = TRUE, data = x)

# Compare numerical and analytical derivatives
num_grad <- numDeriv::grad(llmc, x = result$par, data = x)
num_hess <- numDeriv::hessian(llmc, x = result$par, data = x)

ana_grad <- grmc(result$par, data = x)
ana_hess <- hsmc(result$par, data = x)

# Check differences (should be very small)
round(num_grad - ana_grad, 4)
round(num_hess - ana_hess, 4)
}

}
\references{
McDonald, J. B. (1984). Some generalized functions for the size distribution of income.
Econometrica, 52(3), 647-665.

Cordeiro, G. M., & de Castro, M. (2011). A new family of generalized distributions.
Journal of Statistical Computation and Simulation, 81(7), 883-898.
}
\seealso{
\code{\link[gkwreg]{llmc}} for the negative log-likelihood function,
\code{\link[gkwreg]{grmc}} for the gradient of the BP log-likelihood,
\code{\link[gkwreg]{dmc}} for the BP density function,
}
