% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/RcppExports.R
\name{grbeta}
\alias{grbeta}
\title{Gradient Function for Beta Log-Likelihood}
\usage{
grbeta(par, data)
}
\arguments{
\item{par}{NumericVector of length 2 containing parameters (γ, δ) in that order.
All parameters must be positive.}

\item{data}{NumericVector of observations, where all values must be in the open interval (0,1).}
}
\value{
NumericVector of length 2 containing the gradient components (partial derivatives)
of the negative log-likelihood with respect to each parameter (γ, δ).
Returns a vector of NaN values if any parameters or data values are invalid.
}
\description{
Calculates the gradient vector (partial derivatives) of the negative log-likelihood
function for the Beta distribution. This function provides the exact gradient needed
for efficient optimization in maximum likelihood estimation.
The Beta is a submodel of GKw with α = 1, β = 1, and λ = 1 fixed.
}
\details{
The gradient vector contains the following partial derivatives of the negative log-likelihood:

\deqn{
\frac{\partial \ell}{\partial \gamma} = n[\psi(\gamma+\delta+1) - \psi(\gamma)] -
\sum_{i=1}^{n}\log(x_i)
}

\deqn{
\frac{\partial \ell}{\partial \delta} = n[\psi(\gamma+\delta+1) - \psi(\delta+1)] -
\sum_{i=1}^{n}\log(1-x_i)
}

where:
\itemize{
\item \deqn{\psi} is the digamma function (derivative of the log-gamma function)
}

Note that this implementation works with the GKw family parameterization of the Beta
distribution where shape1=γ and shape2=δ+1 in standard statistical notation.

The implementation includes several numerical safeguards:
\itemize{
\item Parameter and data validation with appropriate error handling
\item Efficient vector operations using Armadillo C++ library
}

The returned gradient is for the negative log-likelihood to align with minimization
in optimization routines.
}
\examples{
\dontrun{
# Generate sample data from a Beta distribution
set.seed(123)
x <- rbeta_(100, 2, 3)
hist(x, breaks = 20, main = "Beta(2, 3) Sample")

# Use in optimization with Hessian-based methods
result <- optim(c(0.5, 0.5), llbeta, method = "BFGS",
                hessian = TRUE, data = x)

# Compare numerical and analytical derivatives
num_grad <- numDeriv::grad(llbeta, x = result$par, data = x)
ana_grad <- grbeta(result$par, data = x)
round(num_grad - ana_grad, 4)
}

}
